// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: StorageClusterStatusMessage.proto

package org.apache.hadoop.hbase.rest.protobuf.generated;

public final class StorageClusterStatusMessage {
  private StorageClusterStatusMessage() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface StorageClusterStatusOrBuilder extends
      // @@protoc_insertion_point(interface_extends:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> 
        getLiveNodesList();
    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node getLiveNodes(int index);
    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    int getLiveNodesCount();
    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder> 
        getLiveNodesOrBuilderList();
    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder getLiveNodesOrBuilder(
        int index);

    /**
     * <code>repeated string deadNodes = 2;</code>
     * @return A list containing the deadNodes.
     */
    java.util.List<java.lang.String>
        getDeadNodesList();
    /**
     * <code>repeated string deadNodes = 2;</code>
     * @return The count of deadNodes.
     */
    int getDeadNodesCount();
    /**
     * <code>repeated string deadNodes = 2;</code>
     * @param index The index of the element to return.
     * @return The deadNodes at the given index.
     */
    java.lang.String getDeadNodes(int index);
    /**
     * <code>repeated string deadNodes = 2;</code>
     * @param index The index of the value to return.
     * @return The bytes of the deadNodes at the given index.
     */
    com.google.protobuf.ByteString
        getDeadNodesBytes(int index);

    /**
     * <pre>
     * summary statistics
     * </pre>
     *
     * <code>optional int32 regions = 3;</code>
     * @return Whether the regions field is set.
     */
    boolean hasRegions();
    /**
     * <pre>
     * summary statistics
     * </pre>
     *
     * <code>optional int32 regions = 3;</code>
     * @return The regions.
     */
    int getRegions();

    /**
     * <code>optional int64 requests = 4;</code>
     * @return Whether the requests field is set.
     */
    boolean hasRequests();
    /**
     * <code>optional int64 requests = 4;</code>
     * @return The requests.
     */
    long getRequests();

    /**
     * <code>optional double averageLoad = 5;</code>
     * @return Whether the averageLoad field is set.
     */
    boolean hasAverageLoad();
    /**
     * <code>optional double averageLoad = 5;</code>
     * @return The averageLoad.
     */
    double getAverageLoad();
  }
  /**
   * Protobuf type {@code org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus}
   */
  public  static final class StorageClusterStatus extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus)
      StorageClusterStatusOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StorageClusterStatus.newBuilder() to construct.
    private StorageClusterStatus(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StorageClusterStatus() {
      liveNodes_ = java.util.Collections.emptyList();
      deadNodes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new StorageClusterStatus();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StorageClusterStatus(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                liveNodes_ = new java.util.ArrayList<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node>();
                mutable_bitField0_ |= 0x00000001;
              }
              liveNodes_.add(
                  input.readMessage(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                deadNodes_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              deadNodes_.add(bs);
              break;
            }
            case 24: {
              bitField0_ |= 0x00000001;
              regions_ = input.readInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000002;
              requests_ = input.readInt64();
              break;
            }
            case 41: {
              bitField0_ |= 0x00000004;
              averageLoad_ = input.readDouble();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          liveNodes_ = java.util.Collections.unmodifiableList(liveNodes_);
        }
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          deadNodes_ = deadNodes_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.class, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Builder.class);
    }

    public interface RegionOrBuilder extends
        // @@protoc_insertion_point(interface_extends:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <code>required bytes name = 1;</code>
       * @return Whether the name field is set.
       */
      boolean hasName();
      /**
       * <code>required bytes name = 1;</code>
       * @return The name.
       */
      com.google.protobuf.ByteString getName();

      /**
       * <code>optional int32 stores = 2;</code>
       * @return Whether the stores field is set.
       */
      boolean hasStores();
      /**
       * <code>optional int32 stores = 2;</code>
       * @return The stores.
       */
      int getStores();

      /**
       * <code>optional int32 storefiles = 3;</code>
       * @return Whether the storefiles field is set.
       */
      boolean hasStorefiles();
      /**
       * <code>optional int32 storefiles = 3;</code>
       * @return The storefiles.
       */
      int getStorefiles();

      /**
       * <code>optional int32 storefileSizeMB = 4;</code>
       * @return Whether the storefileSizeMB field is set.
       */
      boolean hasStorefileSizeMB();
      /**
       * <code>optional int32 storefileSizeMB = 4;</code>
       * @return The storefileSizeMB.
       */
      int getStorefileSizeMB();

      /**
       * <code>optional int32 memstoreSizeMB = 5;</code>
       * @return Whether the memstoreSizeMB field is set.
       */
      boolean hasMemstoreSizeMB();
      /**
       * <code>optional int32 memstoreSizeMB = 5;</code>
       * @return The memstoreSizeMB.
       */
      int getMemstoreSizeMB();

      /**
       * <code>optional int32 storefileIndexSizeMB = 6;</code>
       * @return Whether the storefileIndexSizeMB field is set.
       */
      boolean hasStorefileIndexSizeMB();
      /**
       * <code>optional int32 storefileIndexSizeMB = 6;</code>
       * @return The storefileIndexSizeMB.
       */
      int getStorefileIndexSizeMB();

      /**
       * <code>optional int64 readRequestsCount = 7;</code>
       * @return Whether the readRequestsCount field is set.
       */
      boolean hasReadRequestsCount();
      /**
       * <code>optional int64 readRequestsCount = 7;</code>
       * @return The readRequestsCount.
       */
      long getReadRequestsCount();

      /**
       * <code>optional int64 writeRequestsCount = 8;</code>
       * @return Whether the writeRequestsCount field is set.
       */
      boolean hasWriteRequestsCount();
      /**
       * <code>optional int64 writeRequestsCount = 8;</code>
       * @return The writeRequestsCount.
       */
      long getWriteRequestsCount();

      /**
       * <code>optional int32 rootIndexSizeKB = 9;</code>
       * @return Whether the rootIndexSizeKB field is set.
       */
      boolean hasRootIndexSizeKB();
      /**
       * <code>optional int32 rootIndexSizeKB = 9;</code>
       * @return The rootIndexSizeKB.
       */
      int getRootIndexSizeKB();

      /**
       * <code>optional int32 totalStaticIndexSizeKB = 10;</code>
       * @return Whether the totalStaticIndexSizeKB field is set.
       */
      boolean hasTotalStaticIndexSizeKB();
      /**
       * <code>optional int32 totalStaticIndexSizeKB = 10;</code>
       * @return The totalStaticIndexSizeKB.
       */
      int getTotalStaticIndexSizeKB();

      /**
       * <code>optional int32 totalStaticBloomSizeKB = 11;</code>
       * @return Whether the totalStaticBloomSizeKB field is set.
       */
      boolean hasTotalStaticBloomSizeKB();
      /**
       * <code>optional int32 totalStaticBloomSizeKB = 11;</code>
       * @return The totalStaticBloomSizeKB.
       */
      int getTotalStaticBloomSizeKB();

      /**
       * <code>optional int64 totalCompactingKVs = 12;</code>
       * @return Whether the totalCompactingKVs field is set.
       */
      boolean hasTotalCompactingKVs();
      /**
       * <code>optional int64 totalCompactingKVs = 12;</code>
       * @return The totalCompactingKVs.
       */
      long getTotalCompactingKVs();

      /**
       * <code>optional int64 currentCompactedKVs = 13;</code>
       * @return Whether the currentCompactedKVs field is set.
       */
      boolean hasCurrentCompactedKVs();
      /**
       * <code>optional int64 currentCompactedKVs = 13;</code>
       * @return The currentCompactedKVs.
       */
      long getCurrentCompactedKVs();
    }
    /**
     * Protobuf type {@code org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region}
     */
    public  static final class Region extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region)
        RegionOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use Region.newBuilder() to construct.
      private Region(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Region() {
        name_ = com.google.protobuf.ByteString.EMPTY;
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new Region();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private Region(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                bitField0_ |= 0x00000001;
                name_ = input.readBytes();
                break;
              }
              case 16: {
                bitField0_ |= 0x00000002;
                stores_ = input.readInt32();
                break;
              }
              case 24: {
                bitField0_ |= 0x00000004;
                storefiles_ = input.readInt32();
                break;
              }
              case 32: {
                bitField0_ |= 0x00000008;
                storefileSizeMB_ = input.readInt32();
                break;
              }
              case 40: {
                bitField0_ |= 0x00000010;
                memstoreSizeMB_ = input.readInt32();
                break;
              }
              case 48: {
                bitField0_ |= 0x00000020;
                storefileIndexSizeMB_ = input.readInt32();
                break;
              }
              case 56: {
                bitField0_ |= 0x00000040;
                readRequestsCount_ = input.readInt64();
                break;
              }
              case 64: {
                bitField0_ |= 0x00000080;
                writeRequestsCount_ = input.readInt64();
                break;
              }
              case 72: {
                bitField0_ |= 0x00000100;
                rootIndexSizeKB_ = input.readInt32();
                break;
              }
              case 80: {
                bitField0_ |= 0x00000200;
                totalStaticIndexSizeKB_ = input.readInt32();
                break;
              }
              case 88: {
                bitField0_ |= 0x00000400;
                totalStaticBloomSizeKB_ = input.readInt32();
                break;
              }
              case 96: {
                bitField0_ |= 0x00000800;
                totalCompactingKVs_ = input.readInt64();
                break;
              }
              case 104: {
                bitField0_ |= 0x00001000;
                currentCompactedKVs_ = input.readInt64();
                break;
              }
              default: {
                if (!parseUnknownField(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.class, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder.class);
      }

      private int bitField0_;
      public static final int NAME_FIELD_NUMBER = 1;
      private com.google.protobuf.ByteString name_;
      /**
       * <code>required bytes name = 1;</code>
       * @return Whether the name field is set.
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required bytes name = 1;</code>
       * @return The name.
       */
      public com.google.protobuf.ByteString getName() {
        return name_;
      }

      public static final int STORES_FIELD_NUMBER = 2;
      private int stores_;
      /**
       * <code>optional int32 stores = 2;</code>
       * @return Whether the stores field is set.
       */
      public boolean hasStores() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional int32 stores = 2;</code>
       * @return The stores.
       */
      public int getStores() {
        return stores_;
      }

      public static final int STOREFILES_FIELD_NUMBER = 3;
      private int storefiles_;
      /**
       * <code>optional int32 storefiles = 3;</code>
       * @return Whether the storefiles field is set.
       */
      public boolean hasStorefiles() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional int32 storefiles = 3;</code>
       * @return The storefiles.
       */
      public int getStorefiles() {
        return storefiles_;
      }

      public static final int STOREFILESIZEMB_FIELD_NUMBER = 4;
      private int storefileSizeMB_;
      /**
       * <code>optional int32 storefileSizeMB = 4;</code>
       * @return Whether the storefileSizeMB field is set.
       */
      public boolean hasStorefileSizeMB() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional int32 storefileSizeMB = 4;</code>
       * @return The storefileSizeMB.
       */
      public int getStorefileSizeMB() {
        return storefileSizeMB_;
      }

      public static final int MEMSTORESIZEMB_FIELD_NUMBER = 5;
      private int memstoreSizeMB_;
      /**
       * <code>optional int32 memstoreSizeMB = 5;</code>
       * @return Whether the memstoreSizeMB field is set.
       */
      public boolean hasMemstoreSizeMB() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional int32 memstoreSizeMB = 5;</code>
       * @return The memstoreSizeMB.
       */
      public int getMemstoreSizeMB() {
        return memstoreSizeMB_;
      }

      public static final int STOREFILEINDEXSIZEMB_FIELD_NUMBER = 6;
      private int storefileIndexSizeMB_;
      /**
       * <code>optional int32 storefileIndexSizeMB = 6;</code>
       * @return Whether the storefileIndexSizeMB field is set.
       */
      public boolean hasStorefileIndexSizeMB() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional int32 storefileIndexSizeMB = 6;</code>
       * @return The storefileIndexSizeMB.
       */
      public int getStorefileIndexSizeMB() {
        return storefileIndexSizeMB_;
      }

      public static final int READREQUESTSCOUNT_FIELD_NUMBER = 7;
      private long readRequestsCount_;
      /**
       * <code>optional int64 readRequestsCount = 7;</code>
       * @return Whether the readRequestsCount field is set.
       */
      public boolean hasReadRequestsCount() {
        return ((bitField0_ & 0x00000040) != 0);
      }
      /**
       * <code>optional int64 readRequestsCount = 7;</code>
       * @return The readRequestsCount.
       */
      public long getReadRequestsCount() {
        return readRequestsCount_;
      }

      public static final int WRITEREQUESTSCOUNT_FIELD_NUMBER = 8;
      private long writeRequestsCount_;
      /**
       * <code>optional int64 writeRequestsCount = 8;</code>
       * @return Whether the writeRequestsCount field is set.
       */
      public boolean hasWriteRequestsCount() {
        return ((bitField0_ & 0x00000080) != 0);
      }
      /**
       * <code>optional int64 writeRequestsCount = 8;</code>
       * @return The writeRequestsCount.
       */
      public long getWriteRequestsCount() {
        return writeRequestsCount_;
      }

      public static final int ROOTINDEXSIZEKB_FIELD_NUMBER = 9;
      private int rootIndexSizeKB_;
      /**
       * <code>optional int32 rootIndexSizeKB = 9;</code>
       * @return Whether the rootIndexSizeKB field is set.
       */
      public boolean hasRootIndexSizeKB() {
        return ((bitField0_ & 0x00000100) != 0);
      }
      /**
       * <code>optional int32 rootIndexSizeKB = 9;</code>
       * @return The rootIndexSizeKB.
       */
      public int getRootIndexSizeKB() {
        return rootIndexSizeKB_;
      }

      public static final int TOTALSTATICINDEXSIZEKB_FIELD_NUMBER = 10;
      private int totalStaticIndexSizeKB_;
      /**
       * <code>optional int32 totalStaticIndexSizeKB = 10;</code>
       * @return Whether the totalStaticIndexSizeKB field is set.
       */
      public boolean hasTotalStaticIndexSizeKB() {
        return ((bitField0_ & 0x00000200) != 0);
      }
      /**
       * <code>optional int32 totalStaticIndexSizeKB = 10;</code>
       * @return The totalStaticIndexSizeKB.
       */
      public int getTotalStaticIndexSizeKB() {
        return totalStaticIndexSizeKB_;
      }

      public static final int TOTALSTATICBLOOMSIZEKB_FIELD_NUMBER = 11;
      private int totalStaticBloomSizeKB_;
      /**
       * <code>optional int32 totalStaticBloomSizeKB = 11;</code>
       * @return Whether the totalStaticBloomSizeKB field is set.
       */
      public boolean hasTotalStaticBloomSizeKB() {
        return ((bitField0_ & 0x00000400) != 0);
      }
      /**
       * <code>optional int32 totalStaticBloomSizeKB = 11;</code>
       * @return The totalStaticBloomSizeKB.
       */
      public int getTotalStaticBloomSizeKB() {
        return totalStaticBloomSizeKB_;
      }

      public static final int TOTALCOMPACTINGKVS_FIELD_NUMBER = 12;
      private long totalCompactingKVs_;
      /**
       * <code>optional int64 totalCompactingKVs = 12;</code>
       * @return Whether the totalCompactingKVs field is set.
       */
      public boolean hasTotalCompactingKVs() {
        return ((bitField0_ & 0x00000800) != 0);
      }
      /**
       * <code>optional int64 totalCompactingKVs = 12;</code>
       * @return The totalCompactingKVs.
       */
      public long getTotalCompactingKVs() {
        return totalCompactingKVs_;
      }

      public static final int CURRENTCOMPACTEDKVS_FIELD_NUMBER = 13;
      private long currentCompactedKVs_;
      /**
       * <code>optional int64 currentCompactedKVs = 13;</code>
       * @return Whether the currentCompactedKVs field is set.
       */
      public boolean hasCurrentCompactedKVs() {
        return ((bitField0_ & 0x00001000) != 0);
      }
      /**
       * <code>optional int64 currentCompactedKVs = 13;</code>
       * @return The currentCompactedKVs.
       */
      public long getCurrentCompactedKVs() {
        return currentCompactedKVs_;
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        if (!hasName()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          output.writeBytes(1, name_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          output.writeInt32(2, stores_);
        }
        if (((bitField0_ & 0x00000004) != 0)) {
          output.writeInt32(3, storefiles_);
        }
        if (((bitField0_ & 0x00000008) != 0)) {
          output.writeInt32(4, storefileSizeMB_);
        }
        if (((bitField0_ & 0x00000010) != 0)) {
          output.writeInt32(5, memstoreSizeMB_);
        }
        if (((bitField0_ & 0x00000020) != 0)) {
          output.writeInt32(6, storefileIndexSizeMB_);
        }
        if (((bitField0_ & 0x00000040) != 0)) {
          output.writeInt64(7, readRequestsCount_);
        }
        if (((bitField0_ & 0x00000080) != 0)) {
          output.writeInt64(8, writeRequestsCount_);
        }
        if (((bitField0_ & 0x00000100) != 0)) {
          output.writeInt32(9, rootIndexSizeKB_);
        }
        if (((bitField0_ & 0x00000200) != 0)) {
          output.writeInt32(10, totalStaticIndexSizeKB_);
        }
        if (((bitField0_ & 0x00000400) != 0)) {
          output.writeInt32(11, totalStaticBloomSizeKB_);
        }
        if (((bitField0_ & 0x00000800) != 0)) {
          output.writeInt64(12, totalCompactingKVs_);
        }
        if (((bitField0_ & 0x00001000) != 0)) {
          output.writeInt64(13, currentCompactedKVs_);
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, name_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(2, stores_);
        }
        if (((bitField0_ & 0x00000004) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(3, storefiles_);
        }
        if (((bitField0_ & 0x00000008) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(4, storefileSizeMB_);
        }
        if (((bitField0_ & 0x00000010) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(5, memstoreSizeMB_);
        }
        if (((bitField0_ & 0x00000020) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(6, storefileIndexSizeMB_);
        }
        if (((bitField0_ & 0x00000040) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt64Size(7, readRequestsCount_);
        }
        if (((bitField0_ & 0x00000080) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt64Size(8, writeRequestsCount_);
        }
        if (((bitField0_ & 0x00000100) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(9, rootIndexSizeKB_);
        }
        if (((bitField0_ & 0x00000200) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(10, totalStaticIndexSizeKB_);
        }
        if (((bitField0_ & 0x00000400) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(11, totalStaticBloomSizeKB_);
        }
        if (((bitField0_ & 0x00000800) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt64Size(12, totalCompactingKVs_);
        }
        if (((bitField0_ & 0x00001000) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt64Size(13, currentCompactedKVs_);
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region other = (org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region) obj;

        if (hasName() != other.hasName()) return false;
        if (hasName()) {
          if (!getName()
              .equals(other.getName())) return false;
        }
        if (hasStores() != other.hasStores()) return false;
        if (hasStores()) {
          if (getStores()
              != other.getStores()) return false;
        }
        if (hasStorefiles() != other.hasStorefiles()) return false;
        if (hasStorefiles()) {
          if (getStorefiles()
              != other.getStorefiles()) return false;
        }
        if (hasStorefileSizeMB() != other.hasStorefileSizeMB()) return false;
        if (hasStorefileSizeMB()) {
          if (getStorefileSizeMB()
              != other.getStorefileSizeMB()) return false;
        }
        if (hasMemstoreSizeMB() != other.hasMemstoreSizeMB()) return false;
        if (hasMemstoreSizeMB()) {
          if (getMemstoreSizeMB()
              != other.getMemstoreSizeMB()) return false;
        }
        if (hasStorefileIndexSizeMB() != other.hasStorefileIndexSizeMB()) return false;
        if (hasStorefileIndexSizeMB()) {
          if (getStorefileIndexSizeMB()
              != other.getStorefileIndexSizeMB()) return false;
        }
        if (hasReadRequestsCount() != other.hasReadRequestsCount()) return false;
        if (hasReadRequestsCount()) {
          if (getReadRequestsCount()
              != other.getReadRequestsCount()) return false;
        }
        if (hasWriteRequestsCount() != other.hasWriteRequestsCount()) return false;
        if (hasWriteRequestsCount()) {
          if (getWriteRequestsCount()
              != other.getWriteRequestsCount()) return false;
        }
        if (hasRootIndexSizeKB() != other.hasRootIndexSizeKB()) return false;
        if (hasRootIndexSizeKB()) {
          if (getRootIndexSizeKB()
              != other.getRootIndexSizeKB()) return false;
        }
        if (hasTotalStaticIndexSizeKB() != other.hasTotalStaticIndexSizeKB()) return false;
        if (hasTotalStaticIndexSizeKB()) {
          if (getTotalStaticIndexSizeKB()
              != other.getTotalStaticIndexSizeKB()) return false;
        }
        if (hasTotalStaticBloomSizeKB() != other.hasTotalStaticBloomSizeKB()) return false;
        if (hasTotalStaticBloomSizeKB()) {
          if (getTotalStaticBloomSizeKB()
              != other.getTotalStaticBloomSizeKB()) return false;
        }
        if (hasTotalCompactingKVs() != other.hasTotalCompactingKVs()) return false;
        if (hasTotalCompactingKVs()) {
          if (getTotalCompactingKVs()
              != other.getTotalCompactingKVs()) return false;
        }
        if (hasCurrentCompactedKVs() != other.hasCurrentCompactedKVs()) return false;
        if (hasCurrentCompactedKVs()) {
          if (getCurrentCompactedKVs()
              != other.getCurrentCompactedKVs()) return false;
        }
        if (!unknownFields.equals(other.unknownFields)) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasName()) {
          hash = (37 * hash) + NAME_FIELD_NUMBER;
          hash = (53 * hash) + getName().hashCode();
        }
        if (hasStores()) {
          hash = (37 * hash) + STORES_FIELD_NUMBER;
          hash = (53 * hash) + getStores();
        }
        if (hasStorefiles()) {
          hash = (37 * hash) + STOREFILES_FIELD_NUMBER;
          hash = (53 * hash) + getStorefiles();
        }
        if (hasStorefileSizeMB()) {
          hash = (37 * hash) + STOREFILESIZEMB_FIELD_NUMBER;
          hash = (53 * hash) + getStorefileSizeMB();
        }
        if (hasMemstoreSizeMB()) {
          hash = (37 * hash) + MEMSTORESIZEMB_FIELD_NUMBER;
          hash = (53 * hash) + getMemstoreSizeMB();
        }
        if (hasStorefileIndexSizeMB()) {
          hash = (37 * hash) + STOREFILEINDEXSIZEMB_FIELD_NUMBER;
          hash = (53 * hash) + getStorefileIndexSizeMB();
        }
        if (hasReadRequestsCount()) {
          hash = (37 * hash) + READREQUESTSCOUNT_FIELD_NUMBER;
          hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
              getReadRequestsCount());
        }
        if (hasWriteRequestsCount()) {
          hash = (37 * hash) + WRITEREQUESTSCOUNT_FIELD_NUMBER;
          hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
              getWriteRequestsCount());
        }
        if (hasRootIndexSizeKB()) {
          hash = (37 * hash) + ROOTINDEXSIZEKB_FIELD_NUMBER;
          hash = (53 * hash) + getRootIndexSizeKB();
        }
        if (hasTotalStaticIndexSizeKB()) {
          hash = (37 * hash) + TOTALSTATICINDEXSIZEKB_FIELD_NUMBER;
          hash = (53 * hash) + getTotalStaticIndexSizeKB();
        }
        if (hasTotalStaticBloomSizeKB()) {
          hash = (37 * hash) + TOTALSTATICBLOOMSIZEKB_FIELD_NUMBER;
          hash = (53 * hash) + getTotalStaticBloomSizeKB();
        }
        if (hasTotalCompactingKVs()) {
          hash = (37 * hash) + TOTALCOMPACTINGKVS_FIELD_NUMBER;
          hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
              getTotalCompactingKVs());
        }
        if (hasCurrentCompactedKVs()) {
          hash = (37 * hash) + CURRENTCOMPACTEDKVS_FIELD_NUMBER;
          hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
              getCurrentCompactedKVs());
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region)
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.class, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          name_ = com.google.protobuf.ByteString.EMPTY;
          bitField0_ = (bitField0_ & ~0x00000001);
          stores_ = 0;
          bitField0_ = (bitField0_ & ~0x00000002);
          storefiles_ = 0;
          bitField0_ = (bitField0_ & ~0x00000004);
          storefileSizeMB_ = 0;
          bitField0_ = (bitField0_ & ~0x00000008);
          memstoreSizeMB_ = 0;
          bitField0_ = (bitField0_ & ~0x00000010);
          storefileIndexSizeMB_ = 0;
          bitField0_ = (bitField0_ & ~0x00000020);
          readRequestsCount_ = 0L;
          bitField0_ = (bitField0_ & ~0x00000040);
          writeRequestsCount_ = 0L;
          bitField0_ = (bitField0_ & ~0x00000080);
          rootIndexSizeKB_ = 0;
          bitField0_ = (bitField0_ & ~0x00000100);
          totalStaticIndexSizeKB_ = 0;
          bitField0_ = (bitField0_ & ~0x00000200);
          totalStaticBloomSizeKB_ = 0;
          bitField0_ = (bitField0_ & ~0x00000400);
          totalCompactingKVs_ = 0L;
          bitField0_ = (bitField0_ & ~0x00000800);
          currentCompactedKVs_ = 0L;
          bitField0_ = (bitField0_ & ~0x00001000);
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_descriptor;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.getDefaultInstance();
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region build() {
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region buildPartial() {
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region result = new org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            to_bitField0_ |= 0x00000001;
          }
          result.name_ = name_;
          if (((from_bitField0_ & 0x00000002) != 0)) {
            result.stores_ = stores_;
            to_bitField0_ |= 0x00000002;
          }
          if (((from_bitField0_ & 0x00000004) != 0)) {
            result.storefiles_ = storefiles_;
            to_bitField0_ |= 0x00000004;
          }
          if (((from_bitField0_ & 0x00000008) != 0)) {
            result.storefileSizeMB_ = storefileSizeMB_;
            to_bitField0_ |= 0x00000008;
          }
          if (((from_bitField0_ & 0x00000010) != 0)) {
            result.memstoreSizeMB_ = memstoreSizeMB_;
            to_bitField0_ |= 0x00000010;
          }
          if (((from_bitField0_ & 0x00000020) != 0)) {
            result.storefileIndexSizeMB_ = storefileIndexSizeMB_;
            to_bitField0_ |= 0x00000020;
          }
          if (((from_bitField0_ & 0x00000040) != 0)) {
            result.readRequestsCount_ = readRequestsCount_;
            to_bitField0_ |= 0x00000040;
          }
          if (((from_bitField0_ & 0x00000080) != 0)) {
            result.writeRequestsCount_ = writeRequestsCount_;
            to_bitField0_ |= 0x00000080;
          }
          if (((from_bitField0_ & 0x00000100) != 0)) {
            result.rootIndexSizeKB_ = rootIndexSizeKB_;
            to_bitField0_ |= 0x00000100;
          }
          if (((from_bitField0_ & 0x00000200) != 0)) {
            result.totalStaticIndexSizeKB_ = totalStaticIndexSizeKB_;
            to_bitField0_ |= 0x00000200;
          }
          if (((from_bitField0_ & 0x00000400) != 0)) {
            result.totalStaticBloomSizeKB_ = totalStaticBloomSizeKB_;
            to_bitField0_ |= 0x00000400;
          }
          if (((from_bitField0_ & 0x00000800) != 0)) {
            result.totalCompactingKVs_ = totalCompactingKVs_;
            to_bitField0_ |= 0x00000800;
          }
          if (((from_bitField0_ & 0x00001000) != 0)) {
            result.currentCompactedKVs_ = currentCompactedKVs_;
            to_bitField0_ |= 0x00001000;
          }
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region) {
            return mergeFrom((org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region other) {
          if (other == org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.getDefaultInstance()) return this;
          if (other.hasName()) {
            setName(other.getName());
          }
          if (other.hasStores()) {
            setStores(other.getStores());
          }
          if (other.hasStorefiles()) {
            setStorefiles(other.getStorefiles());
          }
          if (other.hasStorefileSizeMB()) {
            setStorefileSizeMB(other.getStorefileSizeMB());
          }
          if (other.hasMemstoreSizeMB()) {
            setMemstoreSizeMB(other.getMemstoreSizeMB());
          }
          if (other.hasStorefileIndexSizeMB()) {
            setStorefileIndexSizeMB(other.getStorefileIndexSizeMB());
          }
          if (other.hasReadRequestsCount()) {
            setReadRequestsCount(other.getReadRequestsCount());
          }
          if (other.hasWriteRequestsCount()) {
            setWriteRequestsCount(other.getWriteRequestsCount());
          }
          if (other.hasRootIndexSizeKB()) {
            setRootIndexSizeKB(other.getRootIndexSizeKB());
          }
          if (other.hasTotalStaticIndexSizeKB()) {
            setTotalStaticIndexSizeKB(other.getTotalStaticIndexSizeKB());
          }
          if (other.hasTotalStaticBloomSizeKB()) {
            setTotalStaticBloomSizeKB(other.getTotalStaticBloomSizeKB());
          }
          if (other.hasTotalCompactingKVs()) {
            setTotalCompactingKVs(other.getTotalCompactingKVs());
          }
          if (other.hasCurrentCompactedKVs()) {
            setCurrentCompactedKVs(other.getCurrentCompactedKVs());
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          if (!hasName()) {
            return false;
          }
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private com.google.protobuf.ByteString name_ = com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>required bytes name = 1;</code>
         * @return Whether the name field is set.
         */
        public boolean hasName() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <code>required bytes name = 1;</code>
         * @return The name.
         */
        public com.google.protobuf.ByteString getName() {
          return name_;
        }
        /**
         * <code>required bytes name = 1;</code>
         * @param value The name to set.
         * @return This builder for chaining.
         */
        public Builder setName(com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          name_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>required bytes name = 1;</code>
         * @return This builder for chaining.
         */
        public Builder clearName() {
          bitField0_ = (bitField0_ & ~0x00000001);
          name_ = getDefaultInstance().getName();
          onChanged();
          return this;
        }

        private int stores_ ;
        /**
         * <code>optional int32 stores = 2;</code>
         * @return Whether the stores field is set.
         */
        public boolean hasStores() {
          return ((bitField0_ & 0x00000002) != 0);
        }
        /**
         * <code>optional int32 stores = 2;</code>
         * @return The stores.
         */
        public int getStores() {
          return stores_;
        }
        /**
         * <code>optional int32 stores = 2;</code>
         * @param value The stores to set.
         * @return This builder for chaining.
         */
        public Builder setStores(int value) {
          bitField0_ |= 0x00000002;
          stores_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 stores = 2;</code>
         * @return This builder for chaining.
         */
        public Builder clearStores() {
          bitField0_ = (bitField0_ & ~0x00000002);
          stores_ = 0;
          onChanged();
          return this;
        }

        private int storefiles_ ;
        /**
         * <code>optional int32 storefiles = 3;</code>
         * @return Whether the storefiles field is set.
         */
        public boolean hasStorefiles() {
          return ((bitField0_ & 0x00000004) != 0);
        }
        /**
         * <code>optional int32 storefiles = 3;</code>
         * @return The storefiles.
         */
        public int getStorefiles() {
          return storefiles_;
        }
        /**
         * <code>optional int32 storefiles = 3;</code>
         * @param value The storefiles to set.
         * @return This builder for chaining.
         */
        public Builder setStorefiles(int value) {
          bitField0_ |= 0x00000004;
          storefiles_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 storefiles = 3;</code>
         * @return This builder for chaining.
         */
        public Builder clearStorefiles() {
          bitField0_ = (bitField0_ & ~0x00000004);
          storefiles_ = 0;
          onChanged();
          return this;
        }

        private int storefileSizeMB_ ;
        /**
         * <code>optional int32 storefileSizeMB = 4;</code>
         * @return Whether the storefileSizeMB field is set.
         */
        public boolean hasStorefileSizeMB() {
          return ((bitField0_ & 0x00000008) != 0);
        }
        /**
         * <code>optional int32 storefileSizeMB = 4;</code>
         * @return The storefileSizeMB.
         */
        public int getStorefileSizeMB() {
          return storefileSizeMB_;
        }
        /**
         * <code>optional int32 storefileSizeMB = 4;</code>
         * @param value The storefileSizeMB to set.
         * @return This builder for chaining.
         */
        public Builder setStorefileSizeMB(int value) {
          bitField0_ |= 0x00000008;
          storefileSizeMB_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 storefileSizeMB = 4;</code>
         * @return This builder for chaining.
         */
        public Builder clearStorefileSizeMB() {
          bitField0_ = (bitField0_ & ~0x00000008);
          storefileSizeMB_ = 0;
          onChanged();
          return this;
        }

        private int memstoreSizeMB_ ;
        /**
         * <code>optional int32 memstoreSizeMB = 5;</code>
         * @return Whether the memstoreSizeMB field is set.
         */
        public boolean hasMemstoreSizeMB() {
          return ((bitField0_ & 0x00000010) != 0);
        }
        /**
         * <code>optional int32 memstoreSizeMB = 5;</code>
         * @return The memstoreSizeMB.
         */
        public int getMemstoreSizeMB() {
          return memstoreSizeMB_;
        }
        /**
         * <code>optional int32 memstoreSizeMB = 5;</code>
         * @param value The memstoreSizeMB to set.
         * @return This builder for chaining.
         */
        public Builder setMemstoreSizeMB(int value) {
          bitField0_ |= 0x00000010;
          memstoreSizeMB_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 memstoreSizeMB = 5;</code>
         * @return This builder for chaining.
         */
        public Builder clearMemstoreSizeMB() {
          bitField0_ = (bitField0_ & ~0x00000010);
          memstoreSizeMB_ = 0;
          onChanged();
          return this;
        }

        private int storefileIndexSizeMB_ ;
        /**
         * <code>optional int32 storefileIndexSizeMB = 6;</code>
         * @return Whether the storefileIndexSizeMB field is set.
         */
        public boolean hasStorefileIndexSizeMB() {
          return ((bitField0_ & 0x00000020) != 0);
        }
        /**
         * <code>optional int32 storefileIndexSizeMB = 6;</code>
         * @return The storefileIndexSizeMB.
         */
        public int getStorefileIndexSizeMB() {
          return storefileIndexSizeMB_;
        }
        /**
         * <code>optional int32 storefileIndexSizeMB = 6;</code>
         * @param value The storefileIndexSizeMB to set.
         * @return This builder for chaining.
         */
        public Builder setStorefileIndexSizeMB(int value) {
          bitField0_ |= 0x00000020;
          storefileIndexSizeMB_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 storefileIndexSizeMB = 6;</code>
         * @return This builder for chaining.
         */
        public Builder clearStorefileIndexSizeMB() {
          bitField0_ = (bitField0_ & ~0x00000020);
          storefileIndexSizeMB_ = 0;
          onChanged();
          return this;
        }

        private long readRequestsCount_ ;
        /**
         * <code>optional int64 readRequestsCount = 7;</code>
         * @return Whether the readRequestsCount field is set.
         */
        public boolean hasReadRequestsCount() {
          return ((bitField0_ & 0x00000040) != 0);
        }
        /**
         * <code>optional int64 readRequestsCount = 7;</code>
         * @return The readRequestsCount.
         */
        public long getReadRequestsCount() {
          return readRequestsCount_;
        }
        /**
         * <code>optional int64 readRequestsCount = 7;</code>
         * @param value The readRequestsCount to set.
         * @return This builder for chaining.
         */
        public Builder setReadRequestsCount(long value) {
          bitField0_ |= 0x00000040;
          readRequestsCount_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int64 readRequestsCount = 7;</code>
         * @return This builder for chaining.
         */
        public Builder clearReadRequestsCount() {
          bitField0_ = (bitField0_ & ~0x00000040);
          readRequestsCount_ = 0L;
          onChanged();
          return this;
        }

        private long writeRequestsCount_ ;
        /**
         * <code>optional int64 writeRequestsCount = 8;</code>
         * @return Whether the writeRequestsCount field is set.
         */
        public boolean hasWriteRequestsCount() {
          return ((bitField0_ & 0x00000080) != 0);
        }
        /**
         * <code>optional int64 writeRequestsCount = 8;</code>
         * @return The writeRequestsCount.
         */
        public long getWriteRequestsCount() {
          return writeRequestsCount_;
        }
        /**
         * <code>optional int64 writeRequestsCount = 8;</code>
         * @param value The writeRequestsCount to set.
         * @return This builder for chaining.
         */
        public Builder setWriteRequestsCount(long value) {
          bitField0_ |= 0x00000080;
          writeRequestsCount_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int64 writeRequestsCount = 8;</code>
         * @return This builder for chaining.
         */
        public Builder clearWriteRequestsCount() {
          bitField0_ = (bitField0_ & ~0x00000080);
          writeRequestsCount_ = 0L;
          onChanged();
          return this;
        }

        private int rootIndexSizeKB_ ;
        /**
         * <code>optional int32 rootIndexSizeKB = 9;</code>
         * @return Whether the rootIndexSizeKB field is set.
         */
        public boolean hasRootIndexSizeKB() {
          return ((bitField0_ & 0x00000100) != 0);
        }
        /**
         * <code>optional int32 rootIndexSizeKB = 9;</code>
         * @return The rootIndexSizeKB.
         */
        public int getRootIndexSizeKB() {
          return rootIndexSizeKB_;
        }
        /**
         * <code>optional int32 rootIndexSizeKB = 9;</code>
         * @param value The rootIndexSizeKB to set.
         * @return This builder for chaining.
         */
        public Builder setRootIndexSizeKB(int value) {
          bitField0_ |= 0x00000100;
          rootIndexSizeKB_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 rootIndexSizeKB = 9;</code>
         * @return This builder for chaining.
         */
        public Builder clearRootIndexSizeKB() {
          bitField0_ = (bitField0_ & ~0x00000100);
          rootIndexSizeKB_ = 0;
          onChanged();
          return this;
        }

        private int totalStaticIndexSizeKB_ ;
        /**
         * <code>optional int32 totalStaticIndexSizeKB = 10;</code>
         * @return Whether the totalStaticIndexSizeKB field is set.
         */
        public boolean hasTotalStaticIndexSizeKB() {
          return ((bitField0_ & 0x00000200) != 0);
        }
        /**
         * <code>optional int32 totalStaticIndexSizeKB = 10;</code>
         * @return The totalStaticIndexSizeKB.
         */
        public int getTotalStaticIndexSizeKB() {
          return totalStaticIndexSizeKB_;
        }
        /**
         * <code>optional int32 totalStaticIndexSizeKB = 10;</code>
         * @param value The totalStaticIndexSizeKB to set.
         * @return This builder for chaining.
         */
        public Builder setTotalStaticIndexSizeKB(int value) {
          bitField0_ |= 0x00000200;
          totalStaticIndexSizeKB_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 totalStaticIndexSizeKB = 10;</code>
         * @return This builder for chaining.
         */
        public Builder clearTotalStaticIndexSizeKB() {
          bitField0_ = (bitField0_ & ~0x00000200);
          totalStaticIndexSizeKB_ = 0;
          onChanged();
          return this;
        }

        private int totalStaticBloomSizeKB_ ;
        /**
         * <code>optional int32 totalStaticBloomSizeKB = 11;</code>
         * @return Whether the totalStaticBloomSizeKB field is set.
         */
        public boolean hasTotalStaticBloomSizeKB() {
          return ((bitField0_ & 0x00000400) != 0);
        }
        /**
         * <code>optional int32 totalStaticBloomSizeKB = 11;</code>
         * @return The totalStaticBloomSizeKB.
         */
        public int getTotalStaticBloomSizeKB() {
          return totalStaticBloomSizeKB_;
        }
        /**
         * <code>optional int32 totalStaticBloomSizeKB = 11;</code>
         * @param value The totalStaticBloomSizeKB to set.
         * @return This builder for chaining.
         */
        public Builder setTotalStaticBloomSizeKB(int value) {
          bitField0_ |= 0x00000400;
          totalStaticBloomSizeKB_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 totalStaticBloomSizeKB = 11;</code>
         * @return This builder for chaining.
         */
        public Builder clearTotalStaticBloomSizeKB() {
          bitField0_ = (bitField0_ & ~0x00000400);
          totalStaticBloomSizeKB_ = 0;
          onChanged();
          return this;
        }

        private long totalCompactingKVs_ ;
        /**
         * <code>optional int64 totalCompactingKVs = 12;</code>
         * @return Whether the totalCompactingKVs field is set.
         */
        public boolean hasTotalCompactingKVs() {
          return ((bitField0_ & 0x00000800) != 0);
        }
        /**
         * <code>optional int64 totalCompactingKVs = 12;</code>
         * @return The totalCompactingKVs.
         */
        public long getTotalCompactingKVs() {
          return totalCompactingKVs_;
        }
        /**
         * <code>optional int64 totalCompactingKVs = 12;</code>
         * @param value The totalCompactingKVs to set.
         * @return This builder for chaining.
         */
        public Builder setTotalCompactingKVs(long value) {
          bitField0_ |= 0x00000800;
          totalCompactingKVs_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int64 totalCompactingKVs = 12;</code>
         * @return This builder for chaining.
         */
        public Builder clearTotalCompactingKVs() {
          bitField0_ = (bitField0_ & ~0x00000800);
          totalCompactingKVs_ = 0L;
          onChanged();
          return this;
        }

        private long currentCompactedKVs_ ;
        /**
         * <code>optional int64 currentCompactedKVs = 13;</code>
         * @return Whether the currentCompactedKVs field is set.
         */
        public boolean hasCurrentCompactedKVs() {
          return ((bitField0_ & 0x00001000) != 0);
        }
        /**
         * <code>optional int64 currentCompactedKVs = 13;</code>
         * @return The currentCompactedKVs.
         */
        public long getCurrentCompactedKVs() {
          return currentCompactedKVs_;
        }
        /**
         * <code>optional int64 currentCompactedKVs = 13;</code>
         * @param value The currentCompactedKVs to set.
         * @return This builder for chaining.
         */
        public Builder setCurrentCompactedKVs(long value) {
          bitField0_ |= 0x00001000;
          currentCompactedKVs_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int64 currentCompactedKVs = 13;</code>
         * @return This builder for chaining.
         */
        public Builder clearCurrentCompactedKVs() {
          bitField0_ = (bitField0_ & ~0x00001000);
          currentCompactedKVs_ = 0L;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region)
      }

      // @@protoc_insertion_point(class_scope:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region)
      private static final org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region();
      }

      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final com.google.protobuf.Parser<Region>
          PARSER = new com.google.protobuf.AbstractParser<Region>() {
        @java.lang.Override
        public Region parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new Region(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Region> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<Region> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface NodeOrBuilder extends
        // @@protoc_insertion_point(interface_extends:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       * name:port
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return Whether the name field is set.
       */
      boolean hasName();
      /**
       * <pre>
       * name:port
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return The name.
       */
      java.lang.String getName();
      /**
       * <pre>
       * name:port
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return The bytes for name.
       */
      com.google.protobuf.ByteString
          getNameBytes();

      /**
       * <code>optional int64 startCode = 2;</code>
       * @return Whether the startCode field is set.
       */
      boolean hasStartCode();
      /**
       * <code>optional int64 startCode = 2;</code>
       * @return The startCode.
       */
      long getStartCode();

      /**
       * <code>optional int64 requests = 3;</code>
       * @return Whether the requests field is set.
       */
      boolean hasRequests();
      /**
       * <code>optional int64 requests = 3;</code>
       * @return The requests.
       */
      long getRequests();

      /**
       * <code>optional int32 heapSizeMB = 4;</code>
       * @return Whether the heapSizeMB field is set.
       */
      boolean hasHeapSizeMB();
      /**
       * <code>optional int32 heapSizeMB = 4;</code>
       * @return The heapSizeMB.
       */
      int getHeapSizeMB();

      /**
       * <code>optional int32 maxHeapSizeMB = 5;</code>
       * @return Whether the maxHeapSizeMB field is set.
       */
      boolean hasMaxHeapSizeMB();
      /**
       * <code>optional int32 maxHeapSizeMB = 5;</code>
       * @return The maxHeapSizeMB.
       */
      int getMaxHeapSizeMB();

      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region> 
          getRegionsList();
      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region getRegions(int index);
      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      int getRegionsCount();
      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      java.util.List<? extends org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder> 
          getRegionsOrBuilderList();
      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder getRegionsOrBuilder(
          int index);
    }
    /**
     * Protobuf type {@code org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node}
     */
    public  static final class Node extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node)
        NodeOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use Node.newBuilder() to construct.
      private Node(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Node() {
        name_ = "";
        regions_ = java.util.Collections.emptyList();
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new Node();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private Node(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                com.google.protobuf.ByteString bs = input.readBytes();
                bitField0_ |= 0x00000001;
                name_ = bs;
                break;
              }
              case 16: {
                bitField0_ |= 0x00000002;
                startCode_ = input.readInt64();
                break;
              }
              case 24: {
                bitField0_ |= 0x00000004;
                requests_ = input.readInt64();
                break;
              }
              case 32: {
                bitField0_ |= 0x00000008;
                heapSizeMB_ = input.readInt32();
                break;
              }
              case 40: {
                bitField0_ |= 0x00000010;
                maxHeapSizeMB_ = input.readInt32();
                break;
              }
              case 50: {
                if (!((mutable_bitField0_ & 0x00000020) != 0)) {
                  regions_ = new java.util.ArrayList<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region>();
                  mutable_bitField0_ |= 0x00000020;
                }
                regions_.add(
                    input.readMessage(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.PARSER, extensionRegistry));
                break;
              }
              default: {
                if (!parseUnknownField(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000020) != 0)) {
            regions_ = java.util.Collections.unmodifiableList(regions_);
          }
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.class, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder.class);
      }

      private int bitField0_;
      public static final int NAME_FIELD_NUMBER = 1;
      private volatile java.lang.Object name_;
      /**
       * <pre>
       * name:port
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return Whether the name field is set.
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * name:port
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return The name.
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = 
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            name_ = s;
          }
          return s;
        }
      }
      /**
       * <pre>
       * name:port
       * </pre>
       *
       * <code>required string name = 1;</code>
       * @return The bytes for name.
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      public static final int STARTCODE_FIELD_NUMBER = 2;
      private long startCode_;
      /**
       * <code>optional int64 startCode = 2;</code>
       * @return Whether the startCode field is set.
       */
      public boolean hasStartCode() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional int64 startCode = 2;</code>
       * @return The startCode.
       */
      public long getStartCode() {
        return startCode_;
      }

      public static final int REQUESTS_FIELD_NUMBER = 3;
      private long requests_;
      /**
       * <code>optional int64 requests = 3;</code>
       * @return Whether the requests field is set.
       */
      public boolean hasRequests() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional int64 requests = 3;</code>
       * @return The requests.
       */
      public long getRequests() {
        return requests_;
      }

      public static final int HEAPSIZEMB_FIELD_NUMBER = 4;
      private int heapSizeMB_;
      /**
       * <code>optional int32 heapSizeMB = 4;</code>
       * @return Whether the heapSizeMB field is set.
       */
      public boolean hasHeapSizeMB() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional int32 heapSizeMB = 4;</code>
       * @return The heapSizeMB.
       */
      public int getHeapSizeMB() {
        return heapSizeMB_;
      }

      public static final int MAXHEAPSIZEMB_FIELD_NUMBER = 5;
      private int maxHeapSizeMB_;
      /**
       * <code>optional int32 maxHeapSizeMB = 5;</code>
       * @return Whether the maxHeapSizeMB field is set.
       */
      public boolean hasMaxHeapSizeMB() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional int32 maxHeapSizeMB = 5;</code>
       * @return The maxHeapSizeMB.
       */
      public int getMaxHeapSizeMB() {
        return maxHeapSizeMB_;
      }

      public static final int REGIONS_FIELD_NUMBER = 6;
      private java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region> regions_;
      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region> getRegionsList() {
        return regions_;
      }
      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder> 
          getRegionsOrBuilderList() {
        return regions_;
      }
      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      public int getRegionsCount() {
        return regions_.size();
      }
      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region getRegions(int index) {
        return regions_.get(index);
      }
      /**
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
       */
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder getRegionsOrBuilder(
          int index) {
        return regions_.get(index);
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        if (!hasName()) {
          memoizedIsInitialized = 0;
          return false;
        }
        for (int i = 0; i < getRegionsCount(); i++) {
          if (!getRegions(i).isInitialized()) {
            memoizedIsInitialized = 0;
            return false;
          }
        }
        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (((bitField0_ & 0x00000001) != 0)) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          output.writeInt64(2, startCode_);
        }
        if (((bitField0_ & 0x00000004) != 0)) {
          output.writeInt64(3, requests_);
        }
        if (((bitField0_ & 0x00000008) != 0)) {
          output.writeInt32(4, heapSizeMB_);
        }
        if (((bitField0_ & 0x00000010) != 0)) {
          output.writeInt32(5, maxHeapSizeMB_);
        }
        for (int i = 0; i < regions_.size(); i++) {
          output.writeMessage(6, regions_.get(i));
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) != 0)) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt64Size(2, startCode_);
        }
        if (((bitField0_ & 0x00000004) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt64Size(3, requests_);
        }
        if (((bitField0_ & 0x00000008) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(4, heapSizeMB_);
        }
        if (((bitField0_ & 0x00000010) != 0)) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(5, maxHeapSizeMB_);
        }
        for (int i = 0; i < regions_.size(); i++) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(6, regions_.get(i));
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node other = (org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node) obj;

        if (hasName() != other.hasName()) return false;
        if (hasName()) {
          if (!getName()
              .equals(other.getName())) return false;
        }
        if (hasStartCode() != other.hasStartCode()) return false;
        if (hasStartCode()) {
          if (getStartCode()
              != other.getStartCode()) return false;
        }
        if (hasRequests() != other.hasRequests()) return false;
        if (hasRequests()) {
          if (getRequests()
              != other.getRequests()) return false;
        }
        if (hasHeapSizeMB() != other.hasHeapSizeMB()) return false;
        if (hasHeapSizeMB()) {
          if (getHeapSizeMB()
              != other.getHeapSizeMB()) return false;
        }
        if (hasMaxHeapSizeMB() != other.hasMaxHeapSizeMB()) return false;
        if (hasMaxHeapSizeMB()) {
          if (getMaxHeapSizeMB()
              != other.getMaxHeapSizeMB()) return false;
        }
        if (!getRegionsList()
            .equals(other.getRegionsList())) return false;
        if (!unknownFields.equals(other.unknownFields)) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasName()) {
          hash = (37 * hash) + NAME_FIELD_NUMBER;
          hash = (53 * hash) + getName().hashCode();
        }
        if (hasStartCode()) {
          hash = (37 * hash) + STARTCODE_FIELD_NUMBER;
          hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
              getStartCode());
        }
        if (hasRequests()) {
          hash = (37 * hash) + REQUESTS_FIELD_NUMBER;
          hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
              getRequests());
        }
        if (hasHeapSizeMB()) {
          hash = (37 * hash) + HEAPSIZEMB_FIELD_NUMBER;
          hash = (53 * hash) + getHeapSizeMB();
        }
        if (hasMaxHeapSizeMB()) {
          hash = (37 * hash) + MAXHEAPSIZEMB_FIELD_NUMBER;
          hash = (53 * hash) + getMaxHeapSizeMB();
        }
        if (getRegionsCount() > 0) {
          hash = (37 * hash) + REGIONS_FIELD_NUMBER;
          hash = (53 * hash) + getRegionsList().hashCode();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node)
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.class, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
            getRegionsFieldBuilder();
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          name_ = "";
          bitField0_ = (bitField0_ & ~0x00000001);
          startCode_ = 0L;
          bitField0_ = (bitField0_ & ~0x00000002);
          requests_ = 0L;
          bitField0_ = (bitField0_ & ~0x00000004);
          heapSizeMB_ = 0;
          bitField0_ = (bitField0_ & ~0x00000008);
          maxHeapSizeMB_ = 0;
          bitField0_ = (bitField0_ & ~0x00000010);
          if (regionsBuilder_ == null) {
            regions_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000020);
          } else {
            regionsBuilder_.clear();
          }
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_descriptor;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.getDefaultInstance();
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node build() {
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node buildPartial() {
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node result = new org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            to_bitField0_ |= 0x00000001;
          }
          result.name_ = name_;
          if (((from_bitField0_ & 0x00000002) != 0)) {
            result.startCode_ = startCode_;
            to_bitField0_ |= 0x00000002;
          }
          if (((from_bitField0_ & 0x00000004) != 0)) {
            result.requests_ = requests_;
            to_bitField0_ |= 0x00000004;
          }
          if (((from_bitField0_ & 0x00000008) != 0)) {
            result.heapSizeMB_ = heapSizeMB_;
            to_bitField0_ |= 0x00000008;
          }
          if (((from_bitField0_ & 0x00000010) != 0)) {
            result.maxHeapSizeMB_ = maxHeapSizeMB_;
            to_bitField0_ |= 0x00000010;
          }
          if (regionsBuilder_ == null) {
            if (((bitField0_ & 0x00000020) != 0)) {
              regions_ = java.util.Collections.unmodifiableList(regions_);
              bitField0_ = (bitField0_ & ~0x00000020);
            }
            result.regions_ = regions_;
          } else {
            result.regions_ = regionsBuilder_.build();
          }
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node) {
            return mergeFrom((org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node other) {
          if (other == org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.getDefaultInstance()) return this;
          if (other.hasName()) {
            bitField0_ |= 0x00000001;
            name_ = other.name_;
            onChanged();
          }
          if (other.hasStartCode()) {
            setStartCode(other.getStartCode());
          }
          if (other.hasRequests()) {
            setRequests(other.getRequests());
          }
          if (other.hasHeapSizeMB()) {
            setHeapSizeMB(other.getHeapSizeMB());
          }
          if (other.hasMaxHeapSizeMB()) {
            setMaxHeapSizeMB(other.getMaxHeapSizeMB());
          }
          if (regionsBuilder_ == null) {
            if (!other.regions_.isEmpty()) {
              if (regions_.isEmpty()) {
                regions_ = other.regions_;
                bitField0_ = (bitField0_ & ~0x00000020);
              } else {
                ensureRegionsIsMutable();
                regions_.addAll(other.regions_);
              }
              onChanged();
            }
          } else {
            if (!other.regions_.isEmpty()) {
              if (regionsBuilder_.isEmpty()) {
                regionsBuilder_.dispose();
                regionsBuilder_ = null;
                regions_ = other.regions_;
                bitField0_ = (bitField0_ & ~0x00000020);
                regionsBuilder_ = 
                  com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                     getRegionsFieldBuilder() : null;
              } else {
                regionsBuilder_.addAllMessages(other.regions_);
              }
            }
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          if (!hasName()) {
            return false;
          }
          for (int i = 0; i < getRegionsCount(); i++) {
            if (!getRegions(i).isInitialized()) {
              return false;
            }
          }
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private java.lang.Object name_ = "";
        /**
         * <pre>
         * name:port
         * </pre>
         *
         * <code>required string name = 1;</code>
         * @return Whether the name field is set.
         */
        public boolean hasName() {
          return ((bitField0_ & 0x00000001) != 0);
        }
        /**
         * <pre>
         * name:port
         * </pre>
         *
         * <code>required string name = 1;</code>
         * @return The name.
         */
        public java.lang.String getName() {
          java.lang.Object ref = name_;
          if (!(ref instanceof java.lang.String)) {
            com.google.protobuf.ByteString bs =
                (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            if (bs.isValidUtf8()) {
              name_ = s;
            }
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         * <pre>
         * name:port
         * </pre>
         *
         * <code>required string name = 1;</code>
         * @return The bytes for name.
         */
        public com.google.protobuf.ByteString
            getNameBytes() {
          java.lang.Object ref = name_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b = 
                com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            name_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <pre>
         * name:port
         * </pre>
         *
         * <code>required string name = 1;</code>
         * @param value The name to set.
         * @return This builder for chaining.
         */
        public Builder setName(
            java.lang.String value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          name_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * name:port
         * </pre>
         *
         * <code>required string name = 1;</code>
         * @return This builder for chaining.
         */
        public Builder clearName() {
          bitField0_ = (bitField0_ & ~0x00000001);
          name_ = getDefaultInstance().getName();
          onChanged();
          return this;
        }
        /**
         * <pre>
         * name:port
         * </pre>
         *
         * <code>required string name = 1;</code>
         * @param value The bytes for name to set.
         * @return This builder for chaining.
         */
        public Builder setNameBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          name_ = value;
          onChanged();
          return this;
        }

        private long startCode_ ;
        /**
         * <code>optional int64 startCode = 2;</code>
         * @return Whether the startCode field is set.
         */
        public boolean hasStartCode() {
          return ((bitField0_ & 0x00000002) != 0);
        }
        /**
         * <code>optional int64 startCode = 2;</code>
         * @return The startCode.
         */
        public long getStartCode() {
          return startCode_;
        }
        /**
         * <code>optional int64 startCode = 2;</code>
         * @param value The startCode to set.
         * @return This builder for chaining.
         */
        public Builder setStartCode(long value) {
          bitField0_ |= 0x00000002;
          startCode_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int64 startCode = 2;</code>
         * @return This builder for chaining.
         */
        public Builder clearStartCode() {
          bitField0_ = (bitField0_ & ~0x00000002);
          startCode_ = 0L;
          onChanged();
          return this;
        }

        private long requests_ ;
        /**
         * <code>optional int64 requests = 3;</code>
         * @return Whether the requests field is set.
         */
        public boolean hasRequests() {
          return ((bitField0_ & 0x00000004) != 0);
        }
        /**
         * <code>optional int64 requests = 3;</code>
         * @return The requests.
         */
        public long getRequests() {
          return requests_;
        }
        /**
         * <code>optional int64 requests = 3;</code>
         * @param value The requests to set.
         * @return This builder for chaining.
         */
        public Builder setRequests(long value) {
          bitField0_ |= 0x00000004;
          requests_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int64 requests = 3;</code>
         * @return This builder for chaining.
         */
        public Builder clearRequests() {
          bitField0_ = (bitField0_ & ~0x00000004);
          requests_ = 0L;
          onChanged();
          return this;
        }

        private int heapSizeMB_ ;
        /**
         * <code>optional int32 heapSizeMB = 4;</code>
         * @return Whether the heapSizeMB field is set.
         */
        public boolean hasHeapSizeMB() {
          return ((bitField0_ & 0x00000008) != 0);
        }
        /**
         * <code>optional int32 heapSizeMB = 4;</code>
         * @return The heapSizeMB.
         */
        public int getHeapSizeMB() {
          return heapSizeMB_;
        }
        /**
         * <code>optional int32 heapSizeMB = 4;</code>
         * @param value The heapSizeMB to set.
         * @return This builder for chaining.
         */
        public Builder setHeapSizeMB(int value) {
          bitField0_ |= 0x00000008;
          heapSizeMB_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 heapSizeMB = 4;</code>
         * @return This builder for chaining.
         */
        public Builder clearHeapSizeMB() {
          bitField0_ = (bitField0_ & ~0x00000008);
          heapSizeMB_ = 0;
          onChanged();
          return this;
        }

        private int maxHeapSizeMB_ ;
        /**
         * <code>optional int32 maxHeapSizeMB = 5;</code>
         * @return Whether the maxHeapSizeMB field is set.
         */
        public boolean hasMaxHeapSizeMB() {
          return ((bitField0_ & 0x00000010) != 0);
        }
        /**
         * <code>optional int32 maxHeapSizeMB = 5;</code>
         * @return The maxHeapSizeMB.
         */
        public int getMaxHeapSizeMB() {
          return maxHeapSizeMB_;
        }
        /**
         * <code>optional int32 maxHeapSizeMB = 5;</code>
         * @param value The maxHeapSizeMB to set.
         * @return This builder for chaining.
         */
        public Builder setMaxHeapSizeMB(int value) {
          bitField0_ |= 0x00000010;
          maxHeapSizeMB_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>optional int32 maxHeapSizeMB = 5;</code>
         * @return This builder for chaining.
         */
        public Builder clearMaxHeapSizeMB() {
          bitField0_ = (bitField0_ & ~0x00000010);
          maxHeapSizeMB_ = 0;
          onChanged();
          return this;
        }

        private java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region> regions_ =
          java.util.Collections.emptyList();
        private void ensureRegionsIsMutable() {
          if (!((bitField0_ & 0x00000020) != 0)) {
            regions_ = new java.util.ArrayList<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region>(regions_);
            bitField0_ |= 0x00000020;
           }
        }

        private com.google.protobuf.RepeatedFieldBuilderV3<
            org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder> regionsBuilder_;

        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region> getRegionsList() {
          if (regionsBuilder_ == null) {
            return java.util.Collections.unmodifiableList(regions_);
          } else {
            return regionsBuilder_.getMessageList();
          }
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public int getRegionsCount() {
          if (regionsBuilder_ == null) {
            return regions_.size();
          } else {
            return regionsBuilder_.getCount();
          }
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region getRegions(int index) {
          if (regionsBuilder_ == null) {
            return regions_.get(index);
          } else {
            return regionsBuilder_.getMessage(index);
          }
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public Builder setRegions(
            int index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region value) {
          if (regionsBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureRegionsIsMutable();
            regions_.set(index, value);
            onChanged();
          } else {
            regionsBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public Builder setRegions(
            int index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder builderForValue) {
          if (regionsBuilder_ == null) {
            ensureRegionsIsMutable();
            regions_.set(index, builderForValue.build());
            onChanged();
          } else {
            regionsBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public Builder addRegions(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region value) {
          if (regionsBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureRegionsIsMutable();
            regions_.add(value);
            onChanged();
          } else {
            regionsBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public Builder addRegions(
            int index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region value) {
          if (regionsBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureRegionsIsMutable();
            regions_.add(index, value);
            onChanged();
          } else {
            regionsBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public Builder addRegions(
            org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder builderForValue) {
          if (regionsBuilder_ == null) {
            ensureRegionsIsMutable();
            regions_.add(builderForValue.build());
            onChanged();
          } else {
            regionsBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public Builder addRegions(
            int index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder builderForValue) {
          if (regionsBuilder_ == null) {
            ensureRegionsIsMutable();
            regions_.add(index, builderForValue.build());
            onChanged();
          } else {
            regionsBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public Builder addAllRegions(
            java.lang.Iterable<? extends org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region> values) {
          if (regionsBuilder_ == null) {
            ensureRegionsIsMutable();
            com.google.protobuf.AbstractMessageLite.Builder.addAll(
                values, regions_);
            onChanged();
          } else {
            regionsBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public Builder clearRegions() {
          if (regionsBuilder_ == null) {
            regions_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000020);
            onChanged();
          } else {
            regionsBuilder_.clear();
          }
          return this;
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public Builder removeRegions(int index) {
          if (regionsBuilder_ == null) {
            ensureRegionsIsMutable();
            regions_.remove(index);
            onChanged();
          } else {
            regionsBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder getRegionsBuilder(
            int index) {
          return getRegionsFieldBuilder().getBuilder(index);
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder getRegionsOrBuilder(
            int index) {
          if (regionsBuilder_ == null) {
            return regions_.get(index);  } else {
            return regionsBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public java.util.List<? extends org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder> 
             getRegionsOrBuilderList() {
          if (regionsBuilder_ != null) {
            return regionsBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(regions_);
          }
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder addRegionsBuilder() {
          return getRegionsFieldBuilder().addBuilder(
              org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.getDefaultInstance());
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder addRegionsBuilder(
            int index) {
          return getRegionsFieldBuilder().addBuilder(
              index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.getDefaultInstance());
        }
        /**
         * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Region regions = 6;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder> 
             getRegionsBuilderList() {
          return getRegionsFieldBuilder().getBuilderList();
        }
        private com.google.protobuf.RepeatedFieldBuilderV3<
            org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder> 
            getRegionsFieldBuilder() {
          if (regionsBuilder_ == null) {
            regionsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
                org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Region.Builder, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.RegionOrBuilder>(
                    regions_,
                    ((bitField0_ & 0x00000020) != 0),
                    getParentForChildren(),
                    isClean());
            regions_ = null;
          }
          return regionsBuilder_;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node)
      }

      // @@protoc_insertion_point(class_scope:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node)
      private static final org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node();
      }

      public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      @java.lang.Deprecated public static final com.google.protobuf.Parser<Node>
          PARSER = new com.google.protobuf.AbstractParser<Node>() {
        @java.lang.Override
        public Node parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new Node(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Node> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<Node> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int bitField0_;
    public static final int LIVENODES_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> liveNodes_;
    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> getLiveNodesList() {
      return liveNodes_;
    }
    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder> 
        getLiveNodesOrBuilderList() {
      return liveNodes_;
    }
    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    public int getLiveNodesCount() {
      return liveNodes_.size();
    }
    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node getLiveNodes(int index) {
      return liveNodes_.get(index);
    }
    /**
     * <pre>
     * node status
     * </pre>
     *
     * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
     */
    public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder getLiveNodesOrBuilder(
        int index) {
      return liveNodes_.get(index);
    }

    public static final int DEADNODES_FIELD_NUMBER = 2;
    private com.google.protobuf.LazyStringList deadNodes_;
    /**
     * <code>repeated string deadNodes = 2;</code>
     * @return A list containing the deadNodes.
     */
    public com.google.protobuf.ProtocolStringList
        getDeadNodesList() {
      return deadNodes_;
    }
    /**
     * <code>repeated string deadNodes = 2;</code>
     * @return The count of deadNodes.
     */
    public int getDeadNodesCount() {
      return deadNodes_.size();
    }
    /**
     * <code>repeated string deadNodes = 2;</code>
     * @param index The index of the element to return.
     * @return The deadNodes at the given index.
     */
    public java.lang.String getDeadNodes(int index) {
      return deadNodes_.get(index);
    }
    /**
     * <code>repeated string deadNodes = 2;</code>
     * @param index The index of the value to return.
     * @return The bytes of the deadNodes at the given index.
     */
    public com.google.protobuf.ByteString
        getDeadNodesBytes(int index) {
      return deadNodes_.getByteString(index);
    }

    public static final int REGIONS_FIELD_NUMBER = 3;
    private int regions_;
    /**
     * <pre>
     * summary statistics
     * </pre>
     *
     * <code>optional int32 regions = 3;</code>
     * @return Whether the regions field is set.
     */
    public boolean hasRegions() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * summary statistics
     * </pre>
     *
     * <code>optional int32 regions = 3;</code>
     * @return The regions.
     */
    public int getRegions() {
      return regions_;
    }

    public static final int REQUESTS_FIELD_NUMBER = 4;
    private long requests_;
    /**
     * <code>optional int64 requests = 4;</code>
     * @return Whether the requests field is set.
     */
    public boolean hasRequests() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional int64 requests = 4;</code>
     * @return The requests.
     */
    public long getRequests() {
      return requests_;
    }

    public static final int AVERAGELOAD_FIELD_NUMBER = 5;
    private double averageLoad_;
    /**
     * <code>optional double averageLoad = 5;</code>
     * @return Whether the averageLoad field is set.
     */
    public boolean hasAverageLoad() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional double averageLoad = 5;</code>
     * @return The averageLoad.
     */
    public double getAverageLoad() {
      return averageLoad_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getLiveNodesCount(); i++) {
        if (!getLiveNodes(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < liveNodes_.size(); i++) {
        output.writeMessage(1, liveNodes_.get(i));
      }
      for (int i = 0; i < deadNodes_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, deadNodes_.getRaw(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeInt32(3, regions_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeInt64(4, requests_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeDouble(5, averageLoad_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < liveNodes_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, liveNodes_.get(i));
      }
      {
        int dataSize = 0;
        for (int i = 0; i < deadNodes_.size(); i++) {
          dataSize += computeStringSizeNoTag(deadNodes_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getDeadNodesList().size();
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, regions_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, requests_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeDoubleSize(5, averageLoad_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus other = (org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus) obj;

      if (!getLiveNodesList()
          .equals(other.getLiveNodesList())) return false;
      if (!getDeadNodesList()
          .equals(other.getDeadNodesList())) return false;
      if (hasRegions() != other.hasRegions()) return false;
      if (hasRegions()) {
        if (getRegions()
            != other.getRegions()) return false;
      }
      if (hasRequests() != other.hasRequests()) return false;
      if (hasRequests()) {
        if (getRequests()
            != other.getRequests()) return false;
      }
      if (hasAverageLoad() != other.hasAverageLoad()) return false;
      if (hasAverageLoad()) {
        if (java.lang.Double.doubleToLongBits(getAverageLoad())
            != java.lang.Double.doubleToLongBits(
                other.getAverageLoad())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getLiveNodesCount() > 0) {
        hash = (37 * hash) + LIVENODES_FIELD_NUMBER;
        hash = (53 * hash) + getLiveNodesList().hashCode();
      }
      if (getDeadNodesCount() > 0) {
        hash = (37 * hash) + DEADNODES_FIELD_NUMBER;
        hash = (53 * hash) + getDeadNodesList().hashCode();
      }
      if (hasRegions()) {
        hash = (37 * hash) + REGIONS_FIELD_NUMBER;
        hash = (53 * hash) + getRegions();
      }
      if (hasRequests()) {
        hash = (37 * hash) + REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getRequests());
      }
      if (hasAverageLoad()) {
        hash = (37 * hash) + AVERAGELOAD_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            java.lang.Double.doubleToLongBits(getAverageLoad()));
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus)
        org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatusOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.class, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getLiveNodesFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (liveNodesBuilder_ == null) {
          liveNodes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          liveNodesBuilder_.clear();
        }
        deadNodes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        regions_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        requests_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        averageLoad_ = 0D;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus build() {
        org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus buildPartial() {
        org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus result = new org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (liveNodesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            liveNodes_ = java.util.Collections.unmodifiableList(liveNodes_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.liveNodes_ = liveNodes_;
        } else {
          result.liveNodes_ = liveNodesBuilder_.build();
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          deadNodes_ = deadNodes_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.deadNodes_ = deadNodes_;
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.regions_ = regions_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.requests_ = requests_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.averageLoad_ = averageLoad_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus) {
          return mergeFrom((org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus other) {
        if (other == org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.getDefaultInstance()) return this;
        if (liveNodesBuilder_ == null) {
          if (!other.liveNodes_.isEmpty()) {
            if (liveNodes_.isEmpty()) {
              liveNodes_ = other.liveNodes_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureLiveNodesIsMutable();
              liveNodes_.addAll(other.liveNodes_);
            }
            onChanged();
          }
        } else {
          if (!other.liveNodes_.isEmpty()) {
            if (liveNodesBuilder_.isEmpty()) {
              liveNodesBuilder_.dispose();
              liveNodesBuilder_ = null;
              liveNodes_ = other.liveNodes_;
              bitField0_ = (bitField0_ & ~0x00000001);
              liveNodesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getLiveNodesFieldBuilder() : null;
            } else {
              liveNodesBuilder_.addAllMessages(other.liveNodes_);
            }
          }
        }
        if (!other.deadNodes_.isEmpty()) {
          if (deadNodes_.isEmpty()) {
            deadNodes_ = other.deadNodes_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureDeadNodesIsMutable();
            deadNodes_.addAll(other.deadNodes_);
          }
          onChanged();
        }
        if (other.hasRegions()) {
          setRegions(other.getRegions());
        }
        if (other.hasRequests()) {
          setRequests(other.getRequests());
        }
        if (other.hasAverageLoad()) {
          setAverageLoad(other.getAverageLoad());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        for (int i = 0; i < getLiveNodesCount(); i++) {
          if (!getLiveNodes(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> liveNodes_ =
        java.util.Collections.emptyList();
      private void ensureLiveNodesIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          liveNodes_ = new java.util.ArrayList<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node>(liveNodes_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder> liveNodesBuilder_;

      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> getLiveNodesList() {
        if (liveNodesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(liveNodes_);
        } else {
          return liveNodesBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public int getLiveNodesCount() {
        if (liveNodesBuilder_ == null) {
          return liveNodes_.size();
        } else {
          return liveNodesBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node getLiveNodes(int index) {
        if (liveNodesBuilder_ == null) {
          return liveNodes_.get(index);
        } else {
          return liveNodesBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public Builder setLiveNodes(
          int index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node value) {
        if (liveNodesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLiveNodesIsMutable();
          liveNodes_.set(index, value);
          onChanged();
        } else {
          liveNodesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public Builder setLiveNodes(
          int index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder builderForValue) {
        if (liveNodesBuilder_ == null) {
          ensureLiveNodesIsMutable();
          liveNodes_.set(index, builderForValue.build());
          onChanged();
        } else {
          liveNodesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public Builder addLiveNodes(org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node value) {
        if (liveNodesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLiveNodesIsMutable();
          liveNodes_.add(value);
          onChanged();
        } else {
          liveNodesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public Builder addLiveNodes(
          int index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node value) {
        if (liveNodesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLiveNodesIsMutable();
          liveNodes_.add(index, value);
          onChanged();
        } else {
          liveNodesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public Builder addLiveNodes(
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder builderForValue) {
        if (liveNodesBuilder_ == null) {
          ensureLiveNodesIsMutable();
          liveNodes_.add(builderForValue.build());
          onChanged();
        } else {
          liveNodesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public Builder addLiveNodes(
          int index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder builderForValue) {
        if (liveNodesBuilder_ == null) {
          ensureLiveNodesIsMutable();
          liveNodes_.add(index, builderForValue.build());
          onChanged();
        } else {
          liveNodesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public Builder addAllLiveNodes(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> values) {
        if (liveNodesBuilder_ == null) {
          ensureLiveNodesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, liveNodes_);
          onChanged();
        } else {
          liveNodesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public Builder clearLiveNodes() {
        if (liveNodesBuilder_ == null) {
          liveNodes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          liveNodesBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public Builder removeLiveNodes(int index) {
        if (liveNodesBuilder_ == null) {
          ensureLiveNodesIsMutable();
          liveNodes_.remove(index);
          onChanged();
        } else {
          liveNodesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder getLiveNodesBuilder(
          int index) {
        return getLiveNodesFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder getLiveNodesOrBuilder(
          int index) {
        if (liveNodesBuilder_ == null) {
          return liveNodes_.get(index);  } else {
          return liveNodesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder> 
           getLiveNodesOrBuilderList() {
        if (liveNodesBuilder_ != null) {
          return liveNodesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(liveNodes_);
        }
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder addLiveNodesBuilder() {
        return getLiveNodesFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.getDefaultInstance());
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder addLiveNodesBuilder(
          int index) {
        return getLiveNodesFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.getDefaultInstance());
      }
      /**
       * <pre>
       * node status
       * </pre>
       *
       * <code>repeated .org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder> 
           getLiveNodesBuilderList() {
        return getLiveNodesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder> 
          getLiveNodesFieldBuilder() {
        if (liveNodesBuilder_ == null) {
          liveNodesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder, org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.NodeOrBuilder>(
                  liveNodes_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          liveNodes_ = null;
        }
        return liveNodesBuilder_;
      }

      private com.google.protobuf.LazyStringList deadNodes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureDeadNodesIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          deadNodes_ = new com.google.protobuf.LazyStringArrayList(deadNodes_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated string deadNodes = 2;</code>
       * @return A list containing the deadNodes.
       */
      public com.google.protobuf.ProtocolStringList
          getDeadNodesList() {
        return deadNodes_.getUnmodifiableView();
      }
      /**
       * <code>repeated string deadNodes = 2;</code>
       * @return The count of deadNodes.
       */
      public int getDeadNodesCount() {
        return deadNodes_.size();
      }
      /**
       * <code>repeated string deadNodes = 2;</code>
       * @param index The index of the element to return.
       * @return The deadNodes at the given index.
       */
      public java.lang.String getDeadNodes(int index) {
        return deadNodes_.get(index);
      }
      /**
       * <code>repeated string deadNodes = 2;</code>
       * @param index The index of the value to return.
       * @return The bytes of the deadNodes at the given index.
       */
      public com.google.protobuf.ByteString
          getDeadNodesBytes(int index) {
        return deadNodes_.getByteString(index);
      }
      /**
       * <code>repeated string deadNodes = 2;</code>
       * @param index The index to set the value at.
       * @param value The deadNodes to set.
       * @return This builder for chaining.
       */
      public Builder setDeadNodes(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureDeadNodesIsMutable();
        deadNodes_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string deadNodes = 2;</code>
       * @param value The deadNodes to add.
       * @return This builder for chaining.
       */
      public Builder addDeadNodes(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureDeadNodesIsMutable();
        deadNodes_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string deadNodes = 2;</code>
       * @param values The deadNodes to add.
       * @return This builder for chaining.
       */
      public Builder addAllDeadNodes(
          java.lang.Iterable<java.lang.String> values) {
        ensureDeadNodesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, deadNodes_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string deadNodes = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearDeadNodes() {
        deadNodes_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string deadNodes = 2;</code>
       * @param value The bytes of the deadNodes to add.
       * @return This builder for chaining.
       */
      public Builder addDeadNodesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureDeadNodesIsMutable();
        deadNodes_.add(value);
        onChanged();
        return this;
      }

      private int regions_ ;
      /**
       * <pre>
       * summary statistics
       * </pre>
       *
       * <code>optional int32 regions = 3;</code>
       * @return Whether the regions field is set.
       */
      public boolean hasRegions() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <pre>
       * summary statistics
       * </pre>
       *
       * <code>optional int32 regions = 3;</code>
       * @return The regions.
       */
      public int getRegions() {
        return regions_;
      }
      /**
       * <pre>
       * summary statistics
       * </pre>
       *
       * <code>optional int32 regions = 3;</code>
       * @param value The regions to set.
       * @return This builder for chaining.
       */
      public Builder setRegions(int value) {
        bitField0_ |= 0x00000004;
        regions_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * summary statistics
       * </pre>
       *
       * <code>optional int32 regions = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearRegions() {
        bitField0_ = (bitField0_ & ~0x00000004);
        regions_ = 0;
        onChanged();
        return this;
      }

      private long requests_ ;
      /**
       * <code>optional int64 requests = 4;</code>
       * @return Whether the requests field is set.
       */
      public boolean hasRequests() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional int64 requests = 4;</code>
       * @return The requests.
       */
      public long getRequests() {
        return requests_;
      }
      /**
       * <code>optional int64 requests = 4;</code>
       * @param value The requests to set.
       * @return This builder for chaining.
       */
      public Builder setRequests(long value) {
        bitField0_ |= 0x00000008;
        requests_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 requests = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearRequests() {
        bitField0_ = (bitField0_ & ~0x00000008);
        requests_ = 0L;
        onChanged();
        return this;
      }

      private double averageLoad_ ;
      /**
       * <code>optional double averageLoad = 5;</code>
       * @return Whether the averageLoad field is set.
       */
      public boolean hasAverageLoad() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional double averageLoad = 5;</code>
       * @return The averageLoad.
       */
      public double getAverageLoad() {
        return averageLoad_;
      }
      /**
       * <code>optional double averageLoad = 5;</code>
       * @param value The averageLoad to set.
       * @return This builder for chaining.
       */
      public Builder setAverageLoad(double value) {
        bitField0_ |= 0x00000010;
        averageLoad_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional double averageLoad = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearAverageLoad() {
        bitField0_ = (bitField0_ & ~0x00000010);
        averageLoad_ = 0D;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus)
    }

    // @@protoc_insertion_point(class_scope:org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatus)
    private static final org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus();
    }

    public static org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StorageClusterStatus>
        PARSER = new com.google.protobuf.AbstractParser<StorageClusterStatus>() {
      @java.lang.Override
      public StorageClusterStatus parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new StorageClusterStatus(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StorageClusterStatus> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StorageClusterStatus> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n!StorageClusterStatusMessage.proto\022/org" +
      ".apache.hadoop.hbase.rest.protobuf.gener" +
      "ated\"\333\005\n\024StorageClusterStatus\022]\n\tliveNod" +
      "es\030\001 \003(\0132J.org.apache.hadoop.hbase.rest." +
      "protobuf.generated.StorageClusterStatus." +
      "Node\022\021\n\tdeadNodes\030\002 \003(\t\022\017\n\007regions\030\003 \001(\005" +
      "\022\020\n\010requests\030\004 \001(\003\022\023\n\013averageLoad\030\005 \001(\001\032" +
      "\322\002\n\006Region\022\014\n\004name\030\001 \002(\014\022\016\n\006stores\030\002 \001(\005" +
      "\022\022\n\nstorefiles\030\003 \001(\005\022\027\n\017storefileSizeMB\030" +
      "\004 \001(\005\022\026\n\016memstoreSizeMB\030\005 \001(\005\022\034\n\024storefi" +
      "leIndexSizeMB\030\006 \001(\005\022\031\n\021readRequestsCount" +
      "\030\007 \001(\003\022\032\n\022writeRequestsCount\030\010 \001(\003\022\027\n\017ro" +
      "otIndexSizeKB\030\t \001(\005\022\036\n\026totalStaticIndexS" +
      "izeKB\030\n \001(\005\022\036\n\026totalStaticBloomSizeKB\030\013 " +
      "\001(\005\022\032\n\022totalCompactingKVs\030\014 \001(\003\022\033\n\023curre" +
      "ntCompactedKVs\030\r \001(\003\032\303\001\n\004Node\022\014\n\004name\030\001 " +
      "\002(\t\022\021\n\tstartCode\030\002 \001(\003\022\020\n\010requests\030\003 \001(\003" +
      "\022\022\n\nheapSizeMB\030\004 \001(\005\022\025\n\rmaxHeapSizeMB\030\005 " +
      "\001(\005\022]\n\007regions\030\006 \003(\0132L.org.apache.hadoop" +
      ".hbase.rest.protobuf.generated.StorageCl" +
      "usterStatus.Region"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        });
    internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_descriptor,
        new java.lang.String[] { "LiveNodes", "DeadNodes", "Regions", "Requests", "AverageLoad", });
    internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_descriptor =
      internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_descriptor.getNestedTypes().get(0);
    internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Region_descriptor,
        new java.lang.String[] { "Name", "Stores", "Storefiles", "StorefileSizeMB", "MemstoreSizeMB", "StorefileIndexSizeMB", "ReadRequestsCount", "WriteRequestsCount", "RootIndexSizeKB", "TotalStaticIndexSizeKB", "TotalStaticBloomSizeKB", "TotalCompactingKVs", "CurrentCompactedKVs", });
    internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_descriptor =
      internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_descriptor.getNestedTypes().get(1);
    internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_org_apache_hadoop_hbase_rest_protobuf_generated_StorageClusterStatus_Node_descriptor,
        new java.lang.String[] { "Name", "StartCode", "Requests", "HeapSizeMB", "MaxHeapSizeMB", "Regions", });
  }

  // @@protoc_insertion_point(outer_class_scope)
}
