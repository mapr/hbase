// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: MasterProcedure.proto

package org.apache.hadoop.hbase.protobuf.generated;

public final class MasterProcedureProtos {
  private MasterProcedureProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * Protobuf enum {@code hbase.pb.CreateTableState}
   */
  public enum CreateTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CREATE_TABLE_PRE_OPERATION = 1;</code>
     */
    CREATE_TABLE_PRE_OPERATION(1),
    /**
     * <code>CREATE_TABLE_WRITE_FS_LAYOUT = 2;</code>
     */
    CREATE_TABLE_WRITE_FS_LAYOUT(2),
    /**
     * <code>CREATE_TABLE_ADD_TO_META = 3;</code>
     */
    CREATE_TABLE_ADD_TO_META(3),
    /**
     * <code>CREATE_TABLE_ASSIGN_REGIONS = 4;</code>
     */
    CREATE_TABLE_ASSIGN_REGIONS(4),
    /**
     * <code>CREATE_TABLE_UPDATE_DESC_CACHE = 5;</code>
     */
    CREATE_TABLE_UPDATE_DESC_CACHE(5),
    /**
     * <code>CREATE_TABLE_POST_OPERATION = 6;</code>
     */
    CREATE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>CREATE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int CREATE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>CREATE_TABLE_WRITE_FS_LAYOUT = 2;</code>
     */
    public static final int CREATE_TABLE_WRITE_FS_LAYOUT_VALUE = 2;
    /**
     * <code>CREATE_TABLE_ADD_TO_META = 3;</code>
     */
    public static final int CREATE_TABLE_ADD_TO_META_VALUE = 3;
    /**
     * <code>CREATE_TABLE_ASSIGN_REGIONS = 4;</code>
     */
    public static final int CREATE_TABLE_ASSIGN_REGIONS_VALUE = 4;
    /**
     * <code>CREATE_TABLE_UPDATE_DESC_CACHE = 5;</code>
     */
    public static final int CREATE_TABLE_UPDATE_DESC_CACHE_VALUE = 5;
    /**
     * <code>CREATE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int CREATE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CreateTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static CreateTableState forNumber(int value) {
      switch (value) {
        case 1: return CREATE_TABLE_PRE_OPERATION;
        case 2: return CREATE_TABLE_WRITE_FS_LAYOUT;
        case 3: return CREATE_TABLE_ADD_TO_META;
        case 4: return CREATE_TABLE_ASSIGN_REGIONS;
        case 5: return CREATE_TABLE_UPDATE_DESC_CACHE;
        case 6: return CREATE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<CreateTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        CreateTableState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<CreateTableState>() {
            public CreateTableState findValueByNumber(int number) {
              return CreateTableState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final CreateTableState[] VALUES = values();

    public static CreateTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CreateTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CreateTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyTableState}
   */
  public enum ModifyTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_TABLE_PREPARE = 1;</code>
     */
    MODIFY_TABLE_PREPARE(1),
    /**
     * <code>MODIFY_TABLE_PRE_OPERATION = 2;</code>
     */
    MODIFY_TABLE_PRE_OPERATION(2),
    /**
     * <code>MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR(3),
    /**
     * <code>MODIFY_TABLE_REMOVE_REPLICA_COLUMN = 4;</code>
     */
    MODIFY_TABLE_REMOVE_REPLICA_COLUMN(4),
    /**
     * <code>MODIFY_TABLE_DELETE_FS_LAYOUT = 5;</code>
     */
    MODIFY_TABLE_DELETE_FS_LAYOUT(5),
    /**
     * <code>MODIFY_TABLE_POST_OPERATION = 6;</code>
     */
    MODIFY_TABLE_POST_OPERATION(6),
    /**
     * <code>MODIFY_TABLE_REOPEN_ALL_REGIONS = 7;</code>
     */
    MODIFY_TABLE_REOPEN_ALL_REGIONS(7),
    ;

    /**
     * <code>MODIFY_TABLE_PREPARE = 1;</code>
     */
    public static final int MODIFY_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int MODIFY_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>MODIFY_TABLE_REMOVE_REPLICA_COLUMN = 4;</code>
     */
    public static final int MODIFY_TABLE_REMOVE_REPLICA_COLUMN_VALUE = 4;
    /**
     * <code>MODIFY_TABLE_DELETE_FS_LAYOUT = 5;</code>
     */
    public static final int MODIFY_TABLE_DELETE_FS_LAYOUT_VALUE = 5;
    /**
     * <code>MODIFY_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int MODIFY_TABLE_POST_OPERATION_VALUE = 6;
    /**
     * <code>MODIFY_TABLE_REOPEN_ALL_REGIONS = 7;</code>
     */
    public static final int MODIFY_TABLE_REOPEN_ALL_REGIONS_VALUE = 7;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModifyTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ModifyTableState forNumber(int value) {
      switch (value) {
        case 1: return MODIFY_TABLE_PREPARE;
        case 2: return MODIFY_TABLE_PRE_OPERATION;
        case 3: return MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR;
        case 4: return MODIFY_TABLE_REMOVE_REPLICA_COLUMN;
        case 5: return MODIFY_TABLE_DELETE_FS_LAYOUT;
        case 6: return MODIFY_TABLE_POST_OPERATION;
        case 7: return MODIFY_TABLE_REOPEN_ALL_REGIONS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ModifyTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ModifyTableState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ModifyTableState>() {
            public ModifyTableState findValueByNumber(int number) {
              return ModifyTableState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final ModifyTableState[] VALUES = values();

    public static ModifyTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModifyTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.TruncateTableState}
   */
  public enum TruncateTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>TRUNCATE_TABLE_PRE_OPERATION = 1;</code>
     */
    TRUNCATE_TABLE_PRE_OPERATION(1),
    /**
     * <code>TRUNCATE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    TRUNCATE_TABLE_REMOVE_FROM_META(2),
    /**
     * <code>TRUNCATE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    TRUNCATE_TABLE_CLEAR_FS_LAYOUT(3),
    /**
     * <code>TRUNCATE_TABLE_CREATE_FS_LAYOUT = 4;</code>
     */
    TRUNCATE_TABLE_CREATE_FS_LAYOUT(4),
    /**
     * <code>TRUNCATE_TABLE_ADD_TO_META = 5;</code>
     */
    TRUNCATE_TABLE_ADD_TO_META(5),
    /**
     * <code>TRUNCATE_TABLE_ASSIGN_REGIONS = 6;</code>
     */
    TRUNCATE_TABLE_ASSIGN_REGIONS(6),
    /**
     * <code>TRUNCATE_TABLE_POST_OPERATION = 7;</code>
     */
    TRUNCATE_TABLE_POST_OPERATION(7),
    ;

    /**
     * <code>TRUNCATE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int TRUNCATE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>TRUNCATE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    public static final int TRUNCATE_TABLE_REMOVE_FROM_META_VALUE = 2;
    /**
     * <code>TRUNCATE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    public static final int TRUNCATE_TABLE_CLEAR_FS_LAYOUT_VALUE = 3;
    /**
     * <code>TRUNCATE_TABLE_CREATE_FS_LAYOUT = 4;</code>
     */
    public static final int TRUNCATE_TABLE_CREATE_FS_LAYOUT_VALUE = 4;
    /**
     * <code>TRUNCATE_TABLE_ADD_TO_META = 5;</code>
     */
    public static final int TRUNCATE_TABLE_ADD_TO_META_VALUE = 5;
    /**
     * <code>TRUNCATE_TABLE_ASSIGN_REGIONS = 6;</code>
     */
    public static final int TRUNCATE_TABLE_ASSIGN_REGIONS_VALUE = 6;
    /**
     * <code>TRUNCATE_TABLE_POST_OPERATION = 7;</code>
     */
    public static final int TRUNCATE_TABLE_POST_OPERATION_VALUE = 7;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static TruncateTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static TruncateTableState forNumber(int value) {
      switch (value) {
        case 1: return TRUNCATE_TABLE_PRE_OPERATION;
        case 2: return TRUNCATE_TABLE_REMOVE_FROM_META;
        case 3: return TRUNCATE_TABLE_CLEAR_FS_LAYOUT;
        case 4: return TRUNCATE_TABLE_CREATE_FS_LAYOUT;
        case 5: return TRUNCATE_TABLE_ADD_TO_META;
        case 6: return TRUNCATE_TABLE_ASSIGN_REGIONS;
        case 7: return TRUNCATE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<TruncateTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        TruncateTableState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<TruncateTableState>() {
            public TruncateTableState findValueByNumber(int number) {
              return TruncateTableState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(2);
    }

    private static final TruncateTableState[] VALUES = values();

    public static TruncateTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private TruncateTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.TruncateTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteTableState}
   */
  public enum DeleteTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_TABLE_PRE_OPERATION = 1;</code>
     */
    DELETE_TABLE_PRE_OPERATION(1),
    /**
     * <code>DELETE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    DELETE_TABLE_REMOVE_FROM_META(2),
    /**
     * <code>DELETE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    DELETE_TABLE_CLEAR_FS_LAYOUT(3),
    /**
     * <code>DELETE_TABLE_UPDATE_DESC_CACHE = 4;</code>
     */
    DELETE_TABLE_UPDATE_DESC_CACHE(4),
    /**
     * <code>DELETE_TABLE_UNASSIGN_REGIONS = 5;</code>
     */
    DELETE_TABLE_UNASSIGN_REGIONS(5),
    /**
     * <code>DELETE_TABLE_POST_OPERATION = 6;</code>
     */
    DELETE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>DELETE_TABLE_PRE_OPERATION = 1;</code>
     */
    public static final int DELETE_TABLE_PRE_OPERATION_VALUE = 1;
    /**
     * <code>DELETE_TABLE_REMOVE_FROM_META = 2;</code>
     */
    public static final int DELETE_TABLE_REMOVE_FROM_META_VALUE = 2;
    /**
     * <code>DELETE_TABLE_CLEAR_FS_LAYOUT = 3;</code>
     */
    public static final int DELETE_TABLE_CLEAR_FS_LAYOUT_VALUE = 3;
    /**
     * <code>DELETE_TABLE_UPDATE_DESC_CACHE = 4;</code>
     */
    public static final int DELETE_TABLE_UPDATE_DESC_CACHE_VALUE = 4;
    /**
     * <code>DELETE_TABLE_UNASSIGN_REGIONS = 5;</code>
     */
    public static final int DELETE_TABLE_UNASSIGN_REGIONS_VALUE = 5;
    /**
     * <code>DELETE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int DELETE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DeleteTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static DeleteTableState forNumber(int value) {
      switch (value) {
        case 1: return DELETE_TABLE_PRE_OPERATION;
        case 2: return DELETE_TABLE_REMOVE_FROM_META;
        case 3: return DELETE_TABLE_CLEAR_FS_LAYOUT;
        case 4: return DELETE_TABLE_UPDATE_DESC_CACHE;
        case 5: return DELETE_TABLE_UNASSIGN_REGIONS;
        case 6: return DELETE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<DeleteTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        DeleteTableState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<DeleteTableState>() {
            public DeleteTableState findValueByNumber(int number) {
              return DeleteTableState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(3);
    }

    private static final DeleteTableState[] VALUES = values();

    public static DeleteTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DeleteTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.CreateNamespaceState}
   */
  public enum CreateNamespaceState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CREATE_NAMESPACE_PREPARE = 1;</code>
     */
    CREATE_NAMESPACE_PREPARE(1),
    /**
     * <code>CREATE_NAMESPACE_CREATE_DIRECTORY = 2;</code>
     */
    CREATE_NAMESPACE_CREATE_DIRECTORY(2),
    /**
     * <code>CREATE_NAMESPACE_INSERT_INTO_NS_TABLE = 3;</code>
     */
    CREATE_NAMESPACE_INSERT_INTO_NS_TABLE(3),
    /**
     * <code>CREATE_NAMESPACE_UPDATE_ZK = 4;</code>
     */
    CREATE_NAMESPACE_UPDATE_ZK(4),
    /**
     * <code>CREATE_NAMESPACE_SET_NAMESPACE_QUOTA = 5;</code>
     */
    CREATE_NAMESPACE_SET_NAMESPACE_QUOTA(5),
    ;

    /**
     * <code>CREATE_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int CREATE_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>CREATE_NAMESPACE_CREATE_DIRECTORY = 2;</code>
     */
    public static final int CREATE_NAMESPACE_CREATE_DIRECTORY_VALUE = 2;
    /**
     * <code>CREATE_NAMESPACE_INSERT_INTO_NS_TABLE = 3;</code>
     */
    public static final int CREATE_NAMESPACE_INSERT_INTO_NS_TABLE_VALUE = 3;
    /**
     * <code>CREATE_NAMESPACE_UPDATE_ZK = 4;</code>
     */
    public static final int CREATE_NAMESPACE_UPDATE_ZK_VALUE = 4;
    /**
     * <code>CREATE_NAMESPACE_SET_NAMESPACE_QUOTA = 5;</code>
     */
    public static final int CREATE_NAMESPACE_SET_NAMESPACE_QUOTA_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CreateNamespaceState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static CreateNamespaceState forNumber(int value) {
      switch (value) {
        case 1: return CREATE_NAMESPACE_PREPARE;
        case 2: return CREATE_NAMESPACE_CREATE_DIRECTORY;
        case 3: return CREATE_NAMESPACE_INSERT_INTO_NS_TABLE;
        case 4: return CREATE_NAMESPACE_UPDATE_ZK;
        case 5: return CREATE_NAMESPACE_SET_NAMESPACE_QUOTA;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<CreateNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        CreateNamespaceState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<CreateNamespaceState>() {
            public CreateNamespaceState findValueByNumber(int number) {
              return CreateNamespaceState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(4);
    }

    private static final CreateNamespaceState[] VALUES = values();

    public static CreateNamespaceState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CreateNamespaceState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.CreateNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyNamespaceState}
   */
  public enum ModifyNamespaceState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_NAMESPACE_PREPARE = 1;</code>
     */
    MODIFY_NAMESPACE_PREPARE(1),
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_NS_TABLE = 2;</code>
     */
    MODIFY_NAMESPACE_UPDATE_NS_TABLE(2),
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_ZK = 3;</code>
     */
    MODIFY_NAMESPACE_UPDATE_ZK(3),
    ;

    /**
     * <code>MODIFY_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int MODIFY_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_NS_TABLE = 2;</code>
     */
    public static final int MODIFY_NAMESPACE_UPDATE_NS_TABLE_VALUE = 2;
    /**
     * <code>MODIFY_NAMESPACE_UPDATE_ZK = 3;</code>
     */
    public static final int MODIFY_NAMESPACE_UPDATE_ZK_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModifyNamespaceState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ModifyNamespaceState forNumber(int value) {
      switch (value) {
        case 1: return MODIFY_NAMESPACE_PREPARE;
        case 2: return MODIFY_NAMESPACE_UPDATE_NS_TABLE;
        case 3: return MODIFY_NAMESPACE_UPDATE_ZK;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ModifyNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ModifyNamespaceState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ModifyNamespaceState>() {
            public ModifyNamespaceState findValueByNumber(int number) {
              return ModifyNamespaceState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(5);
    }

    private static final ModifyNamespaceState[] VALUES = values();

    public static ModifyNamespaceState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModifyNamespaceState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteNamespaceState}
   */
  public enum DeleteNamespaceState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_NAMESPACE_PREPARE = 1;</code>
     */
    DELETE_NAMESPACE_PREPARE(1),
    /**
     * <code>DELETE_NAMESPACE_DELETE_FROM_NS_TABLE = 2;</code>
     */
    DELETE_NAMESPACE_DELETE_FROM_NS_TABLE(2),
    /**
     * <code>DELETE_NAMESPACE_REMOVE_FROM_ZK = 3;</code>
     */
    DELETE_NAMESPACE_REMOVE_FROM_ZK(3),
    /**
     * <code>DELETE_NAMESPACE_DELETE_DIRECTORIES = 4;</code>
     */
    DELETE_NAMESPACE_DELETE_DIRECTORIES(4),
    /**
     * <code>DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA = 5;</code>
     */
    DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA(5),
    ;

    /**
     * <code>DELETE_NAMESPACE_PREPARE = 1;</code>
     */
    public static final int DELETE_NAMESPACE_PREPARE_VALUE = 1;
    /**
     * <code>DELETE_NAMESPACE_DELETE_FROM_NS_TABLE = 2;</code>
     */
    public static final int DELETE_NAMESPACE_DELETE_FROM_NS_TABLE_VALUE = 2;
    /**
     * <code>DELETE_NAMESPACE_REMOVE_FROM_ZK = 3;</code>
     */
    public static final int DELETE_NAMESPACE_REMOVE_FROM_ZK_VALUE = 3;
    /**
     * <code>DELETE_NAMESPACE_DELETE_DIRECTORIES = 4;</code>
     */
    public static final int DELETE_NAMESPACE_DELETE_DIRECTORIES_VALUE = 4;
    /**
     * <code>DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA = 5;</code>
     */
    public static final int DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DeleteNamespaceState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static DeleteNamespaceState forNumber(int value) {
      switch (value) {
        case 1: return DELETE_NAMESPACE_PREPARE;
        case 2: return DELETE_NAMESPACE_DELETE_FROM_NS_TABLE;
        case 3: return DELETE_NAMESPACE_REMOVE_FROM_ZK;
        case 4: return DELETE_NAMESPACE_DELETE_DIRECTORIES;
        case 5: return DELETE_NAMESPACE_REMOVE_NAMESPACE_QUOTA;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<DeleteNamespaceState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        DeleteNamespaceState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<DeleteNamespaceState>() {
            public DeleteNamespaceState findValueByNumber(int number) {
              return DeleteNamespaceState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(6);
    }

    private static final DeleteNamespaceState[] VALUES = values();

    public static DeleteNamespaceState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DeleteNamespaceState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteNamespaceState)
  }

  /**
   * Protobuf enum {@code hbase.pb.AddColumnFamilyState}
   */
  public enum AddColumnFamilyState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ADD_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    ADD_COLUMN_FAMILY_PREPARE(1),
    /**
     * <code>ADD_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    ADD_COLUMN_FAMILY_PRE_OPERATION(2),
    /**
     * <code>ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR(3),
    /**
     * <code>ADD_COLUMN_FAMILY_POST_OPERATION = 4;</code>
     */
    ADD_COLUMN_FAMILY_POST_OPERATION(4),
    /**
     * <code>ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 5;</code>
     */
    ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS(5),
    ;

    /**
     * <code>ADD_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    public static final int ADD_COLUMN_FAMILY_PREPARE_VALUE = 1;
    /**
     * <code>ADD_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    public static final int ADD_COLUMN_FAMILY_PRE_OPERATION_VALUE = 2;
    /**
     * <code>ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>ADD_COLUMN_FAMILY_POST_OPERATION = 4;</code>
     */
    public static final int ADD_COLUMN_FAMILY_POST_OPERATION_VALUE = 4;
    /**
     * <code>ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 5;</code>
     */
    public static final int ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static AddColumnFamilyState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static AddColumnFamilyState forNumber(int value) {
      switch (value) {
        case 1: return ADD_COLUMN_FAMILY_PREPARE;
        case 2: return ADD_COLUMN_FAMILY_PRE_OPERATION;
        case 3: return ADD_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR;
        case 4: return ADD_COLUMN_FAMILY_POST_OPERATION;
        case 5: return ADD_COLUMN_FAMILY_REOPEN_ALL_REGIONS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<AddColumnFamilyState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        AddColumnFamilyState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<AddColumnFamilyState>() {
            public AddColumnFamilyState findValueByNumber(int number) {
              return AddColumnFamilyState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(7);
    }

    private static final AddColumnFamilyState[] VALUES = values();

    public static AddColumnFamilyState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private AddColumnFamilyState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.AddColumnFamilyState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ModifyColumnFamilyState}
   */
  public enum ModifyColumnFamilyState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MODIFY_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    MODIFY_COLUMN_FAMILY_PREPARE(1),
    /**
     * <code>MODIFY_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    MODIFY_COLUMN_FAMILY_PRE_OPERATION(2),
    /**
     * <code>MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR(3),
    /**
     * <code>MODIFY_COLUMN_FAMILY_POST_OPERATION = 4;</code>
     */
    MODIFY_COLUMN_FAMILY_POST_OPERATION(4),
    /**
     * <code>MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 5;</code>
     */
    MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS(5),
    ;

    /**
     * <code>MODIFY_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_PREPARE_VALUE = 1;
    /**
     * <code>MODIFY_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_PRE_OPERATION_VALUE = 2;
    /**
     * <code>MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>MODIFY_COLUMN_FAMILY_POST_OPERATION = 4;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_POST_OPERATION_VALUE = 4;
    /**
     * <code>MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 5;</code>
     */
    public static final int MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ModifyColumnFamilyState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ModifyColumnFamilyState forNumber(int value) {
      switch (value) {
        case 1: return MODIFY_COLUMN_FAMILY_PREPARE;
        case 2: return MODIFY_COLUMN_FAMILY_PRE_OPERATION;
        case 3: return MODIFY_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR;
        case 4: return MODIFY_COLUMN_FAMILY_POST_OPERATION;
        case 5: return MODIFY_COLUMN_FAMILY_REOPEN_ALL_REGIONS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ModifyColumnFamilyState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ModifyColumnFamilyState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ModifyColumnFamilyState>() {
            public ModifyColumnFamilyState findValueByNumber(int number) {
              return ModifyColumnFamilyState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(8);
    }

    private static final ModifyColumnFamilyState[] VALUES = values();

    public static ModifyColumnFamilyState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ModifyColumnFamilyState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ModifyColumnFamilyState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DeleteColumnFamilyState}
   */
  public enum DeleteColumnFamilyState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DELETE_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    DELETE_COLUMN_FAMILY_PREPARE(1),
    /**
     * <code>DELETE_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    DELETE_COLUMN_FAMILY_PRE_OPERATION(2),
    /**
     * <code>DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR(3),
    /**
     * <code>DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT = 4;</code>
     */
    DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT(4),
    /**
     * <code>DELETE_COLUMN_FAMILY_POST_OPERATION = 5;</code>
     */
    DELETE_COLUMN_FAMILY_POST_OPERATION(5),
    /**
     * <code>DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 6;</code>
     */
    DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS(6),
    ;

    /**
     * <code>DELETE_COLUMN_FAMILY_PREPARE = 1;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_PREPARE_VALUE = 1;
    /**
     * <code>DELETE_COLUMN_FAMILY_PRE_OPERATION = 2;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_PRE_OPERATION_VALUE = 2;
    /**
     * <code>DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR = 3;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR_VALUE = 3;
    /**
     * <code>DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT = 4;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT_VALUE = 4;
    /**
     * <code>DELETE_COLUMN_FAMILY_POST_OPERATION = 5;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_POST_OPERATION_VALUE = 5;
    /**
     * <code>DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS = 6;</code>
     */
    public static final int DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DeleteColumnFamilyState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static DeleteColumnFamilyState forNumber(int value) {
      switch (value) {
        case 1: return DELETE_COLUMN_FAMILY_PREPARE;
        case 2: return DELETE_COLUMN_FAMILY_PRE_OPERATION;
        case 3: return DELETE_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR;
        case 4: return DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT;
        case 5: return DELETE_COLUMN_FAMILY_POST_OPERATION;
        case 6: return DELETE_COLUMN_FAMILY_REOPEN_ALL_REGIONS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<DeleteColumnFamilyState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        DeleteColumnFamilyState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<DeleteColumnFamilyState>() {
            public DeleteColumnFamilyState findValueByNumber(int number) {
              return DeleteColumnFamilyState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(9);
    }

    private static final DeleteColumnFamilyState[] VALUES = values();

    public static DeleteColumnFamilyState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DeleteColumnFamilyState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DeleteColumnFamilyState)
  }

  /**
   * Protobuf enum {@code hbase.pb.EnableTableState}
   */
  public enum EnableTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ENABLE_TABLE_PREPARE = 1;</code>
     */
    ENABLE_TABLE_PREPARE(1),
    /**
     * <code>ENABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    ENABLE_TABLE_PRE_OPERATION(2),
    /**
     * <code>ENABLE_TABLE_SET_ENABLING_TABLE_STATE = 3;</code>
     */
    ENABLE_TABLE_SET_ENABLING_TABLE_STATE(3),
    /**
     * <code>ENABLE_TABLE_MARK_REGIONS_ONLINE = 4;</code>
     */
    ENABLE_TABLE_MARK_REGIONS_ONLINE(4),
    /**
     * <code>ENABLE_TABLE_SET_ENABLED_TABLE_STATE = 5;</code>
     */
    ENABLE_TABLE_SET_ENABLED_TABLE_STATE(5),
    /**
     * <code>ENABLE_TABLE_POST_OPERATION = 6;</code>
     */
    ENABLE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>ENABLE_TABLE_PREPARE = 1;</code>
     */
    public static final int ENABLE_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>ENABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int ENABLE_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>ENABLE_TABLE_SET_ENABLING_TABLE_STATE = 3;</code>
     */
    public static final int ENABLE_TABLE_SET_ENABLING_TABLE_STATE_VALUE = 3;
    /**
     * <code>ENABLE_TABLE_MARK_REGIONS_ONLINE = 4;</code>
     */
    public static final int ENABLE_TABLE_MARK_REGIONS_ONLINE_VALUE = 4;
    /**
     * <code>ENABLE_TABLE_SET_ENABLED_TABLE_STATE = 5;</code>
     */
    public static final int ENABLE_TABLE_SET_ENABLED_TABLE_STATE_VALUE = 5;
    /**
     * <code>ENABLE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int ENABLE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static EnableTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static EnableTableState forNumber(int value) {
      switch (value) {
        case 1: return ENABLE_TABLE_PREPARE;
        case 2: return ENABLE_TABLE_PRE_OPERATION;
        case 3: return ENABLE_TABLE_SET_ENABLING_TABLE_STATE;
        case 4: return ENABLE_TABLE_MARK_REGIONS_ONLINE;
        case 5: return ENABLE_TABLE_SET_ENABLED_TABLE_STATE;
        case 6: return ENABLE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<EnableTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        EnableTableState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<EnableTableState>() {
            public EnableTableState findValueByNumber(int number) {
              return EnableTableState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(10);
    }

    private static final EnableTableState[] VALUES = values();

    public static EnableTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private EnableTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.EnableTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.DisableTableState}
   */
  public enum DisableTableState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DISABLE_TABLE_PREPARE = 1;</code>
     */
    DISABLE_TABLE_PREPARE(1),
    /**
     * <code>DISABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    DISABLE_TABLE_PRE_OPERATION(2),
    /**
     * <code>DISABLE_TABLE_SET_DISABLING_TABLE_STATE = 3;</code>
     */
    DISABLE_TABLE_SET_DISABLING_TABLE_STATE(3),
    /**
     * <code>DISABLE_TABLE_MARK_REGIONS_OFFLINE = 4;</code>
     */
    DISABLE_TABLE_MARK_REGIONS_OFFLINE(4),
    /**
     * <code>DISABLE_TABLE_SET_DISABLED_TABLE_STATE = 5;</code>
     */
    DISABLE_TABLE_SET_DISABLED_TABLE_STATE(5),
    /**
     * <code>DISABLE_TABLE_POST_OPERATION = 6;</code>
     */
    DISABLE_TABLE_POST_OPERATION(6),
    ;

    /**
     * <code>DISABLE_TABLE_PREPARE = 1;</code>
     */
    public static final int DISABLE_TABLE_PREPARE_VALUE = 1;
    /**
     * <code>DISABLE_TABLE_PRE_OPERATION = 2;</code>
     */
    public static final int DISABLE_TABLE_PRE_OPERATION_VALUE = 2;
    /**
     * <code>DISABLE_TABLE_SET_DISABLING_TABLE_STATE = 3;</code>
     */
    public static final int DISABLE_TABLE_SET_DISABLING_TABLE_STATE_VALUE = 3;
    /**
     * <code>DISABLE_TABLE_MARK_REGIONS_OFFLINE = 4;</code>
     */
    public static final int DISABLE_TABLE_MARK_REGIONS_OFFLINE_VALUE = 4;
    /**
     * <code>DISABLE_TABLE_SET_DISABLED_TABLE_STATE = 5;</code>
     */
    public static final int DISABLE_TABLE_SET_DISABLED_TABLE_STATE_VALUE = 5;
    /**
     * <code>DISABLE_TABLE_POST_OPERATION = 6;</code>
     */
    public static final int DISABLE_TABLE_POST_OPERATION_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static DisableTableState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static DisableTableState forNumber(int value) {
      switch (value) {
        case 1: return DISABLE_TABLE_PREPARE;
        case 2: return DISABLE_TABLE_PRE_OPERATION;
        case 3: return DISABLE_TABLE_SET_DISABLING_TABLE_STATE;
        case 4: return DISABLE_TABLE_MARK_REGIONS_OFFLINE;
        case 5: return DISABLE_TABLE_SET_DISABLED_TABLE_STATE;
        case 6: return DISABLE_TABLE_POST_OPERATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<DisableTableState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        DisableTableState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<DisableTableState>() {
            public DisableTableState findValueByNumber(int number) {
              return DisableTableState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(11);
    }

    private static final DisableTableState[] VALUES = values();

    public static DisableTableState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DisableTableState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.DisableTableState)
  }

  /**
   * Protobuf enum {@code hbase.pb.ServerCrashState}
   */
  public enum ServerCrashState
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SERVER_CRASH_START = 1;</code>
     */
    SERVER_CRASH_START(1),
    /**
     * <code>SERVER_CRASH_PROCESS_META = 2;</code>
     */
    SERVER_CRASH_PROCESS_META(2),
    /**
     * <code>SERVER_CRASH_GET_REGIONS = 3;</code>
     */
    SERVER_CRASH_GET_REGIONS(3),
    /**
     * <code>SERVER_CRASH_NO_SPLIT_LOGS = 4;</code>
     */
    SERVER_CRASH_NO_SPLIT_LOGS(4),
    /**
     * <code>SERVER_CRASH_SPLIT_LOGS = 5;</code>
     */
    SERVER_CRASH_SPLIT_LOGS(5),
    /**
     * <code>SERVER_CRASH_PREPARE_LOG_REPLAY = 6;</code>
     */
    SERVER_CRASH_PREPARE_LOG_REPLAY(6),
    /**
     * <pre>
     * Removed SERVER_CRASH_CALC_REGIONS_TO_ASSIGN = 7;
     * </pre>
     *
     * <code>SERVER_CRASH_ASSIGN = 8;</code>
     */
    SERVER_CRASH_ASSIGN(8),
    /**
     * <code>SERVER_CRASH_WAIT_ON_ASSIGN = 9;</code>
     */
    SERVER_CRASH_WAIT_ON_ASSIGN(9),
    /**
     * <code>SERVER_CRASH_FINISH = 100;</code>
     */
    SERVER_CRASH_FINISH(100),
    ;

    /**
     * <code>SERVER_CRASH_START = 1;</code>
     */
    public static final int SERVER_CRASH_START_VALUE = 1;
    /**
     * <code>SERVER_CRASH_PROCESS_META = 2;</code>
     */
    public static final int SERVER_CRASH_PROCESS_META_VALUE = 2;
    /**
     * <code>SERVER_CRASH_GET_REGIONS = 3;</code>
     */
    public static final int SERVER_CRASH_GET_REGIONS_VALUE = 3;
    /**
     * <code>SERVER_CRASH_NO_SPLIT_LOGS = 4;</code>
     */
    public static final int SERVER_CRASH_NO_SPLIT_LOGS_VALUE = 4;
    /**
     * <code>SERVER_CRASH_SPLIT_LOGS = 5;</code>
     */
    public static final int SERVER_CRASH_SPLIT_LOGS_VALUE = 5;
    /**
     * <code>SERVER_CRASH_PREPARE_LOG_REPLAY = 6;</code>
     */
    public static final int SERVER_CRASH_PREPARE_LOG_REPLAY_VALUE = 6;
    /**
     * <pre>
     * Removed SERVER_CRASH_CALC_REGIONS_TO_ASSIGN = 7;
     * </pre>
     *
     * <code>SERVER_CRASH_ASSIGN = 8;</code>
     */
    public static final int SERVER_CRASH_ASSIGN_VALUE = 8;
    /**
     * <code>SERVER_CRASH_WAIT_ON_ASSIGN = 9;</code>
     */
    public static final int SERVER_CRASH_WAIT_ON_ASSIGN_VALUE = 9;
    /**
     * <code>SERVER_CRASH_FINISH = 100;</code>
     */
    public static final int SERVER_CRASH_FINISH_VALUE = 100;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ServerCrashState valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ServerCrashState forNumber(int value) {
      switch (value) {
        case 1: return SERVER_CRASH_START;
        case 2: return SERVER_CRASH_PROCESS_META;
        case 3: return SERVER_CRASH_GET_REGIONS;
        case 4: return SERVER_CRASH_NO_SPLIT_LOGS;
        case 5: return SERVER_CRASH_SPLIT_LOGS;
        case 6: return SERVER_CRASH_PREPARE_LOG_REPLAY;
        case 8: return SERVER_CRASH_ASSIGN;
        case 9: return SERVER_CRASH_WAIT_ON_ASSIGN;
        case 100: return SERVER_CRASH_FINISH;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ServerCrashState>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ServerCrashState> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ServerCrashState>() {
            public ServerCrashState findValueByNumber(int number) {
              return ServerCrashState.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.getDescriptor().getEnumTypes().get(12);
    }

    private static final ServerCrashState[] VALUES = values();

    public static ServerCrashState valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ServerCrashState(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ServerCrashState)
  }

  public interface CreateTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CreateTableStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     * @return Whether the tableSchema field is set.
     */
    boolean hasTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     * @return The tableSchema.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.CreateTableStateData}
   */
  public  static final class CreateTableStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CreateTableStateData)
      CreateTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CreateTableStateData.newBuilder() to construct.
    private CreateTableStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CreateTableStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CreateTableStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CreateTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = tableSchema_.toBuilder();
              }
              tableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableSchema_);
                tableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) != 0)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_SCHEMA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     * @return Whether the tableSchema field is set.
     */
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     * @return The tableSchema.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableSchema() != other.hasTableSchema()) return false;
      if (hasTableSchema()) {
        if (!getTableSchema()
            .equals(other.getTableSchema())) return false;
      }
      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CreateTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CreateTableStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (userInfoBuilder_ == null) {
            result.userInfo_ = userInfo_;
          } else {
            result.userInfo_ = userInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (tableSchemaBuilder_ == null) {
            result.tableSchema_ = tableSchema_;
          } else {
            result.tableSchema_ = tableSchemaBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableSchema()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableSchema().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       * @return Whether the tableSchema field is set.
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       * @return The tableSchema.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              tableSchema_ != null &&
              tableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            tableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(tableSchema_).mergeFrom(value).buildPartial();
          } else {
            tableSchema_ = value;
          }
          onChanged();
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public Builder clearTableSchema() {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
          onChanged();
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema table_schema = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getTableSchema(),
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CreateTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CreateTableStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<CreateTableStateData>
        PARSER = new com.google.protobuf.AbstractParser<CreateTableStateData>() {
      @java.lang.Override
      public CreateTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CreateTableStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<CreateTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<CreateTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyTableStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     * @return The unmodifiedTableSchema.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();

    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return Whether the modifiedTableSchema field is set.
     */
    boolean hasModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return The modifiedTableSchema.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema();
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder();

    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     * @return Whether the deleteColumnFamilyInModify field is set.
     */
    boolean hasDeleteColumnFamilyInModify();
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     * @return The deleteColumnFamilyInModify.
     */
    boolean getDeleteColumnFamilyInModify();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyTableStateData}
   */
  public  static final class ModifyTableStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyTableStateData)
      ModifyTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyTableStateData.newBuilder() to construct.
    private ModifyTableStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyTableStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ModifyTableStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModifyTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = unmodifiedTableSchema_.toBuilder();
              }
              unmodifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedTableSchema_);
                unmodifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) != 0)) {
                subBuilder = modifiedTableSchema_.toBuilder();
              }
              modifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(modifiedTableSchema_);
                modifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              deleteColumnFamilyInModify_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     * @return The unmodifiedTableSchema.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }

    public static final int MODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return Whether the modifiedTableSchema field is set.
     */
    public boolean hasModifiedTableSchema() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     * @return The modifiedTableSchema.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }
    /**
     * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
      return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
    }

    public static final int DELETE_COLUMN_FAMILY_IN_MODIFY_FIELD_NUMBER = 4;
    private boolean deleteColumnFamilyInModify_;
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     * @return Whether the deleteColumnFamilyInModify field is set.
     */
    public boolean hasDeleteColumnFamilyInModify() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>required bool delete_column_family_in_modify = 4;</code>
     * @return The deleteColumnFamilyInModify.
     */
    public boolean getDeleteColumnFamilyInModify() {
      return deleteColumnFamilyInModify_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasModifiedTableSchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasDeleteColumnFamilyInModify()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (!getModifiedTableSchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getUnmodifiedTableSchema());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getModifiedTableSchema());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(4, deleteColumnFamilyInModify_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getUnmodifiedTableSchema());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getModifiedTableSchema());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, deleteColumnFamilyInModify_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasUnmodifiedTableSchema() != other.hasUnmodifiedTableSchema()) return false;
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema())) return false;
      }
      if (hasModifiedTableSchema() != other.hasModifiedTableSchema()) return false;
      if (hasModifiedTableSchema()) {
        if (!getModifiedTableSchema()
            .equals(other.getModifiedTableSchema())) return false;
      }
      if (hasDeleteColumnFamilyInModify() != other.hasDeleteColumnFamilyInModify()) return false;
      if (hasDeleteColumnFamilyInModify()) {
        if (getDeleteColumnFamilyInModify()
            != other.getDeleteColumnFamilyInModify()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      if (hasModifiedTableSchema()) {
        hash = (37 * hash) + MODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getModifiedTableSchema().hashCode();
      }
      if (hasDeleteColumnFamilyInModify()) {
        hash = (37 * hash) + DELETE_COLUMN_FAMILY_IN_MODIFY_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getDeleteColumnFamilyInModify());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyTableStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
          getModifiedTableSchemaFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = null;
        } else {
          modifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        deleteColumnFamilyInModify_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (userInfoBuilder_ == null) {
            result.userInfo_ = userInfo_;
          } else {
            result.userInfo_ = userInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (unmodifiedTableSchemaBuilder_ == null) {
            result.unmodifiedTableSchema_ = unmodifiedTableSchema_;
          } else {
            result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          if (modifiedTableSchemaBuilder_ == null) {
            result.modifiedTableSchema_ = modifiedTableSchema_;
          } else {
            result.modifiedTableSchema_ = modifiedTableSchemaBuilder_.build();
          }
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.deleteColumnFamilyInModify_ = deleteColumnFamilyInModify_;
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        if (other.hasModifiedTableSchema()) {
          mergeModifiedTableSchema(other.getModifiedTableSchema());
        }
        if (other.hasDeleteColumnFamilyInModify()) {
          setDeleteColumnFamilyInModify(other.getDeleteColumnFamilyInModify());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasModifiedTableSchema()) {
          return false;
        }
        if (!hasDeleteColumnFamilyInModify()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            return false;
          }
        }
        if (!getModifiedTableSchema().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       * @return Whether the unmodifiedTableSchema field is set.
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       * @return The unmodifiedTableSchema.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              unmodifiedTableSchema_ != null &&
              unmodifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            unmodifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(unmodifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getUnmodifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema modifiedTableSchema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> modifiedTableSchemaBuilder_;
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       * @return Whether the modifiedTableSchema field is set.
       */
      public boolean hasModifiedTableSchema() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       * @return The modifiedTableSchema.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          return modifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        } else {
          return modifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modifiedTableSchema_ = value;
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder setModifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder mergeModifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (modifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
              modifiedTableSchema_ != null &&
              modifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            modifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(modifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            modifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public Builder clearModifiedTableSchema() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchema_ = null;
          onChanged();
        } else {
          modifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getModifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getModifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getModifiedTableSchemaOrBuilder() {
        if (modifiedTableSchemaBuilder_ != null) {
          return modifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return modifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : modifiedTableSchema_;
        }
      }
      /**
       * <code>required .hbase.pb.TableSchema modified_table_schema = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getModifiedTableSchemaFieldBuilder() {
        if (modifiedTableSchemaBuilder_ == null) {
          modifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getModifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          modifiedTableSchema_ = null;
        }
        return modifiedTableSchemaBuilder_;
      }

      private boolean deleteColumnFamilyInModify_ ;
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       * @return Whether the deleteColumnFamilyInModify field is set.
       */
      public boolean hasDeleteColumnFamilyInModify() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       * @return The deleteColumnFamilyInModify.
       */
      public boolean getDeleteColumnFamilyInModify() {
        return deleteColumnFamilyInModify_;
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       * @param value The deleteColumnFamilyInModify to set.
       * @return This builder for chaining.
       */
      public Builder setDeleteColumnFamilyInModify(boolean value) {
        bitField0_ |= 0x00000008;
        deleteColumnFamilyInModify_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool delete_column_family_in_modify = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearDeleteColumnFamilyInModify() {
        bitField0_ = (bitField0_ & ~0x00000008);
        deleteColumnFamilyInModify_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyTableStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ModifyTableStateData>
        PARSER = new com.google.protobuf.AbstractParser<ModifyTableStateData>() {
      @java.lang.Override
      public ModifyTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModifyTableStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModifyTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ModifyTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TruncateTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.TruncateTableStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required bool preserve_splits = 2;</code>
     * @return Whether the preserveSplits field is set.
     */
    boolean hasPreserveSplits();
    /**
     * <code>required bool preserve_splits = 2;</code>
     * @return The preserveSplits.
     */
    boolean getPreserveSplits();

    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     * @return Whether the tableSchema field is set.
     */
    boolean hasTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     * @return The tableSchema.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.TruncateTableStateData}
   */
  public  static final class TruncateTableStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.TruncateTableStateData)
      TruncateTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TruncateTableStateData.newBuilder() to construct.
    private TruncateTableStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TruncateTableStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new TruncateTableStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private TruncateTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              preserveSplits_ = input.readBool();
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) != 0)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) != 0)) {
                subBuilder = tableSchema_.toBuilder();
              }
              tableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableSchema_);
                tableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) != 0)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000010;
              }
              regionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000010) != 0)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int PRESERVE_SPLITS_FIELD_NUMBER = 2;
    private boolean preserveSplits_;
    /**
     * <code>required bool preserve_splits = 2;</code>
     * @return Whether the preserveSplits field is set.
     */
    public boolean hasPreserveSplits() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required bool preserve_splits = 2;</code>
     * @return The preserveSplits.
     */
    public boolean getPreserveSplits() {
      return preserveSplits_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     * @return Whether the tableName field is set.
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     * @return The tableName.
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     * @return Whether the tableSchema field is set.
     */
    public boolean hasTableSchema() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     * @return The tableSchema.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
      return tableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasPreserveSplits()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasTableName()) {
        if (!getTableName().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasTableSchema()) {
        if (!getTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, preserveSplits_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getTableName());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(5, regionInfo_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, preserveSplits_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getTableName());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getTableSchema());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, regionInfo_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasPreserveSplits() != other.hasPreserveSplits()) return false;
      if (hasPreserveSplits()) {
        if (getPreserveSplits()
            != other.getPreserveSplits()) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasTableSchema() != other.hasTableSchema()) return false;
      if (hasTableSchema()) {
        if (!getTableSchema()
            .equals(other.getTableSchema())) return false;
      }
      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasPreserveSplits()) {
        hash = (37 * hash) + PRESERVE_SPLITS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getPreserveSplits());
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasTableSchema()) {
        hash = (37 * hash) + TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getTableSchema().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.TruncateTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.TruncateTableStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getTableSchemaFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        preserveSplits_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_TruncateTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (userInfoBuilder_ == null) {
            result.userInfo_ = userInfo_;
          } else {
            result.userInfo_ = userInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.preserveSplits_ = preserveSplits_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          if (tableNameBuilder_ == null) {
            result.tableName_ = tableName_;
          } else {
            result.tableName_ = tableNameBuilder_.build();
          }
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          if (tableSchemaBuilder_ == null) {
            result.tableSchema_ = tableSchema_;
          } else {
            result.tableSchema_ = tableSchemaBuilder_.build();
          }
          to_bitField0_ |= 0x00000008;
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasPreserveSplits()) {
          setPreserveSplits(other.getPreserveSplits());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasTableSchema()) {
          mergeTableSchema(other.getTableSchema());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000010);
              regionInfoBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasPreserveSplits()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (hasTableName()) {
          if (!getTableName().isInitialized()) {
            return false;
          }
        }
        if (hasTableSchema()) {
          if (!getTableSchema().isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private boolean preserveSplits_ ;
      /**
       * <code>required bool preserve_splits = 2;</code>
       * @return Whether the preserveSplits field is set.
       */
      public boolean hasPreserveSplits() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       * @return The preserveSplits.
       */
      public boolean getPreserveSplits() {
        return preserveSplits_;
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       * @param value The preserveSplits to set.
       * @return This builder for chaining.
       */
      public Builder setPreserveSplits(boolean value) {
        bitField0_ |= 0x00000002;
        preserveSplits_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool preserve_splits = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearPreserveSplits() {
        bitField0_ = (bitField0_ & ~0x00000002);
        preserveSplits_ = false;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema tableSchema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> tableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       * @return Whether the tableSchema field is set.
       */
      public boolean hasTableSchema() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       * @return The tableSchema.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getTableSchema() {
        if (tableSchemaBuilder_ == null) {
          return tableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        } else {
          return tableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder setTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableSchema_ = value;
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder setTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = builderForValue.build();
          onChanged();
        } else {
          tableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder mergeTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (tableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
              tableSchema_ != null &&
              tableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            tableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(tableSchema_).mergeFrom(value).buildPartial();
          } else {
            tableSchema_ = value;
          }
          onChanged();
        } else {
          tableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public Builder clearTableSchema() {
        if (tableSchemaBuilder_ == null) {
          tableSchema_ = null;
          onChanged();
        } else {
          tableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getTableSchemaOrBuilder() {
        if (tableSchemaBuilder_ != null) {
          return tableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return tableSchema_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : tableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema table_schema = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getTableSchemaFieldBuilder() {
        if (tableSchemaBuilder_ == null) {
          tableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getTableSchema(),
                  getParentForChildren(),
                  isClean());
          tableSchema_ = null;
        }
        return tableSchemaBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000010) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000010) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.TruncateTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.TruncateTableStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<TruncateTableStateData>
        PARSER = new com.google.protobuf.AbstractParser<TruncateTableStateData>() {
      @java.lang.Override
      public TruncateTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TruncateTableStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<TruncateTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<TruncateTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.TruncateTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DeleteTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DeleteTableStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionInfoList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    int getRegionInfoCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteTableStateData}
   */
  public  static final class DeleteTableStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DeleteTableStateData)
      DeleteTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DeleteTableStateData.newBuilder() to construct.
    private DeleteTableStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DeleteTableStateData() {
      regionInfo_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DeleteTableStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DeleteTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionInfo_.add(
                  input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) != 0)) {
          regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int REGION_INFO_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_;
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionInfoOrBuilderList() {
      return regionInfo_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public int getRegionInfoCount() {
      return regionInfo_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
      return regionInfo_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
        int index) {
      return regionInfo_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionInfoCount(); i++) {
        if (!getRegionInfo(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        output.writeMessage(3, regionInfo_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      for (int i = 0; i < regionInfo_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionInfo_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (!getRegionInfoList()
          .equals(other.getRegionInfoList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (getRegionInfoCount() > 0) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfoList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DeleteTableStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getRegionInfoFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (userInfoBuilder_ == null) {
            result.userInfo_ = userInfo_;
          } else {
            result.userInfo_ = userInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (tableNameBuilder_ == null) {
            result.tableName_ = tableName_;
          } else {
            result.tableName_ = tableNameBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            regionInfo_ = java.util.Collections.unmodifiableList(regionInfo_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (regionInfoBuilder_ == null) {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfo_.isEmpty()) {
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionInfoIsMutable();
              regionInfo_.addAll(other.regionInfo_);
            }
            onChanged();
          }
        } else {
          if (!other.regionInfo_.isEmpty()) {
            if (regionInfoBuilder_.isEmpty()) {
              regionInfoBuilder_.dispose();
              regionInfoBuilder_ = null;
              regionInfo_ = other.regionInfo_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionInfoBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionInfoFieldBuilder() : null;
            } else {
              regionInfoBuilder_.addAllMessages(other.regionInfo_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionInfoCount(); i++) {
          if (!getRegionInfo(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionInfo_ =
        java.util.Collections.emptyList();
      private void ensureRegionInfoIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          regionInfo_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionInfo_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionInfoList() {
        if (regionInfoBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionInfo_);
        } else {
          return regionInfoBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public int getRegionInfoCount() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.size();
        } else {
          return regionInfoBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);
        } else {
          return regionInfoBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder setRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, value);
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addRegionInfo(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionInfoBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder addAllRegionInfo(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionInfo_);
          onChanged();
        } else {
          regionInfoBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public Builder removeRegionInfo(int index) {
        if (regionInfoBuilder_ == null) {
          ensureRegionInfoIsMutable();
          regionInfo_.remove(index);
          onChanged();
        } else {
          regionInfoBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder(
          int index) {
        if (regionInfoBuilder_ == null) {
          return regionInfo_.get(index);  } else {
          return regionInfoBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionInfoOrBuilderList() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionInfo_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder() {
        return getRegionInfoFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionInfoBuilder(
          int index) {
        return getRegionInfoFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo region_info = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionInfoBuilderList() {
        return getRegionInfoFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteTableStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DeleteTableStateData>
        PARSER = new com.google.protobuf.AbstractParser<DeleteTableStateData>() {
      @java.lang.Override
      public DeleteTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DeleteTableStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DeleteTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DeleteTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CreateNamespaceStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.CreateNamespaceStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return The namespaceDescriptor.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.CreateNamespaceStateData}
   */
  public  static final class CreateNamespaceStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.CreateNamespaceStateData)
      CreateNamespaceStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CreateNamespaceStateData.newBuilder() to construct.
    private CreateNamespaceStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CreateNamespaceStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CreateNamespaceStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CreateNamespaceStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = namespaceDescriptor_.toBuilder();
              }
              namespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespaceDescriptor_);
                namespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.Builder.class);
    }

    private int bitField0_;
    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return The namespaceDescriptor.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasNamespaceDescriptor()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getNamespaceDescriptor().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getNamespaceDescriptor());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNamespaceDescriptor());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) obj;

      if (hasNamespaceDescriptor() != other.hasNamespaceDescriptor()) return false;
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CreateNamespaceStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.CreateNamespaceStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (namespaceDescriptorBuilder_ == null) {
            result.namespaceDescriptor_ = namespaceDescriptor_;
          } else {
            result.namespaceDescriptor_ = namespaceDescriptorBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasNamespaceDescriptor()) {
          return false;
        }
        if (!getNamespaceDescriptor().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       * @return Whether the namespaceDescriptor field is set.
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       * @return The namespaceDescriptor.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              namespaceDescriptor_ != null &&
              namespaceDescriptor_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            namespaceDescriptor_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(namespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            namespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder clearNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.CreateNamespaceStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CreateNamespaceStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<CreateNamespaceStateData>
        PARSER = new com.google.protobuf.AbstractParser<CreateNamespaceStateData>() {
      @java.lang.Override
      public CreateNamespaceStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CreateNamespaceStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<CreateNamespaceStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<CreateNamespaceStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.CreateNamespaceStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyNamespaceStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyNamespaceStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return The namespaceDescriptor.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();

    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     * @return Whether the unmodifiedNamespaceDescriptor field is set.
     */
    boolean hasUnmodifiedNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     * @return The unmodifiedNamespaceDescriptor.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyNamespaceStateData}
   */
  public  static final class ModifyNamespaceStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyNamespaceStateData)
      ModifyNamespaceStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyNamespaceStateData.newBuilder() to construct.
    private ModifyNamespaceStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyNamespaceStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ModifyNamespaceStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModifyNamespaceStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = namespaceDescriptor_.toBuilder();
              }
              namespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespaceDescriptor_);
                namespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = unmodifiedNamespaceDescriptor_.toBuilder();
              }
              unmodifiedNamespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedNamespaceDescriptor_);
                unmodifiedNamespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.Builder.class);
    }

    private int bitField0_;
    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     * @return The namespaceDescriptor.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }
    /**
     * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }

    public static final int UNMODIFIED_NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor unmodifiedNamespaceDescriptor_;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     * @return Whether the unmodifiedNamespaceDescriptor field is set.
     */
    public boolean hasUnmodifiedNamespaceDescriptor() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     * @return The unmodifiedNamespaceDescriptor.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor() {
      return unmodifiedNamespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder() {
      return unmodifiedNamespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasNamespaceDescriptor()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getNamespaceDescriptor().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedNamespaceDescriptor()) {
        if (!getUnmodifiedNamespaceDescriptor().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getNamespaceDescriptor());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getUnmodifiedNamespaceDescriptor());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNamespaceDescriptor());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getUnmodifiedNamespaceDescriptor());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) obj;

      if (hasNamespaceDescriptor() != other.hasNamespaceDescriptor()) return false;
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor())) return false;
      }
      if (hasUnmodifiedNamespaceDescriptor() != other.hasUnmodifiedNamespaceDescriptor()) return false;
      if (hasUnmodifiedNamespaceDescriptor()) {
        if (!getUnmodifiedNamespaceDescriptor()
            .equals(other.getUnmodifiedNamespaceDescriptor())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      if (hasUnmodifiedNamespaceDescriptor()) {
        hash = (37 * hash) + UNMODIFIED_NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyNamespaceStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyNamespaceStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
          getUnmodifiedNamespaceDescriptorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = null;
        } else {
          unmodifiedNamespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (namespaceDescriptorBuilder_ == null) {
            result.namespaceDescriptor_ = namespaceDescriptor_;
          } else {
            result.namespaceDescriptor_ = namespaceDescriptorBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (unmodifiedNamespaceDescriptorBuilder_ == null) {
            result.unmodifiedNamespaceDescriptor_ = unmodifiedNamespaceDescriptor_;
          } else {
            result.unmodifiedNamespaceDescriptor_ = unmodifiedNamespaceDescriptorBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        if (other.hasUnmodifiedNamespaceDescriptor()) {
          mergeUnmodifiedNamespaceDescriptor(other.getUnmodifiedNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasNamespaceDescriptor()) {
          return false;
        }
        if (!getNamespaceDescriptor().isInitialized()) {
          return false;
        }
        if (hasUnmodifiedNamespaceDescriptor()) {
          if (!getUnmodifiedNamespaceDescriptor().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       * @return Whether the namespaceDescriptor field is set.
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       * @return The namespaceDescriptor.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              namespaceDescriptor_ != null &&
              namespaceDescriptor_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            namespaceDescriptor_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(namespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            namespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public Builder clearNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        }
      }
      /**
       * <code>required .hbase.pb.NamespaceDescriptor namespace_descriptor = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor unmodifiedNamespaceDescriptor_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> unmodifiedNamespaceDescriptorBuilder_;
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       * @return Whether the unmodifiedNamespaceDescriptor field is set.
       */
      public boolean hasUnmodifiedNamespaceDescriptor() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       * @return The unmodifiedNamespaceDescriptor.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getUnmodifiedNamespaceDescriptor() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          return unmodifiedNamespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
        } else {
          return unmodifiedNamespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder setUnmodifiedNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedNamespaceDescriptor_ = value;
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder setUnmodifiedNamespaceDescriptor(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder mergeUnmodifiedNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              unmodifiedNamespaceDescriptor_ != null &&
              unmodifiedNamespaceDescriptor_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            unmodifiedNamespaceDescriptor_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(unmodifiedNamespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedNamespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public Builder clearUnmodifiedNamespaceDescriptor() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptor_ = null;
          onChanged();
        } else {
          unmodifiedNamespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getUnmodifiedNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getUnmodifiedNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getUnmodifiedNamespaceDescriptorOrBuilder() {
        if (unmodifiedNamespaceDescriptorBuilder_ != null) {
          return unmodifiedNamespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedNamespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : unmodifiedNamespaceDescriptor_;
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor unmodified_namespace_descriptor = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getUnmodifiedNamespaceDescriptorFieldBuilder() {
        if (unmodifiedNamespaceDescriptorBuilder_ == null) {
          unmodifiedNamespaceDescriptorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getUnmodifiedNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          unmodifiedNamespaceDescriptor_ = null;
        }
        return unmodifiedNamespaceDescriptorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyNamespaceStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyNamespaceStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ModifyNamespaceStateData>
        PARSER = new com.google.protobuf.AbstractParser<ModifyNamespaceStateData>() {
      @java.lang.Override
      public ModifyNamespaceStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModifyNamespaceStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModifyNamespaceStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ModifyNamespaceStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyNamespaceStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DeleteNamespaceStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DeleteNamespaceStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required string namespace_name = 1;</code>
     * @return Whether the namespaceName field is set.
     */
    boolean hasNamespaceName();
    /**
     * <code>required string namespace_name = 1;</code>
     * @return The namespaceName.
     */
    java.lang.String getNamespaceName();
    /**
     * <code>required string namespace_name = 1;</code>
     * @return The bytes for namespaceName.
     */
    com.google.protobuf.ByteString
        getNamespaceNameBytes();

    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    boolean hasNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     * @return The namespaceDescriptor.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor();
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteNamespaceStateData}
   */
  public  static final class DeleteNamespaceStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DeleteNamespaceStateData)
      DeleteNamespaceStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DeleteNamespaceStateData.newBuilder() to construct.
    private DeleteNamespaceStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DeleteNamespaceStateData() {
      namespaceName_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DeleteNamespaceStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DeleteNamespaceStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              namespaceName_ = bs;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = namespaceDescriptor_.toBuilder();
              }
              namespaceDescriptor_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespaceDescriptor_);
                namespaceDescriptor_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.Builder.class);
    }

    private int bitField0_;
    public static final int NAMESPACE_NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object namespaceName_;
    /**
     * <code>required string namespace_name = 1;</code>
     * @return Whether the namespaceName field is set.
     */
    public boolean hasNamespaceName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required string namespace_name = 1;</code>
     * @return The namespaceName.
     */
    public java.lang.String getNamespaceName() {
      java.lang.Object ref = namespaceName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          namespaceName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string namespace_name = 1;</code>
     * @return The bytes for namespaceName.
     */
    public com.google.protobuf.ByteString
        getNamespaceNameBytes() {
      java.lang.Object ref = namespaceName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        namespaceName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int NAMESPACE_DESCRIPTOR_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     * @return Whether the namespaceDescriptor field is set.
     */
    public boolean hasNamespaceDescriptor() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     * @return The namespaceDescriptor.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }
    /**
     * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
      return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasNamespaceName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, namespaceName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getNamespaceDescriptor());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, namespaceName_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getNamespaceDescriptor());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) obj;

      if (hasNamespaceName() != other.hasNamespaceName()) return false;
      if (hasNamespaceName()) {
        if (!getNamespaceName()
            .equals(other.getNamespaceName())) return false;
      }
      if (hasNamespaceDescriptor() != other.hasNamespaceDescriptor()) return false;
      if (hasNamespaceDescriptor()) {
        if (!getNamespaceDescriptor()
            .equals(other.getNamespaceDescriptor())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNamespaceName()) {
        hash = (37 * hash) + NAMESPACE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceName().hashCode();
      }
      if (hasNamespaceDescriptor()) {
        hash = (37 * hash) + NAMESPACE_DESCRIPTOR_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceDescriptor().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteNamespaceStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DeleteNamespaceStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNamespaceDescriptorFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        namespaceName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.namespaceName_ = namespaceName_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (namespaceDescriptorBuilder_ == null) {
            result.namespaceDescriptor_ = namespaceDescriptor_;
          } else {
            result.namespaceDescriptor_ = namespaceDescriptorBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData.getDefaultInstance()) return this;
        if (other.hasNamespaceName()) {
          bitField0_ |= 0x00000001;
          namespaceName_ = other.namespaceName_;
          onChanged();
        }
        if (other.hasNamespaceDescriptor()) {
          mergeNamespaceDescriptor(other.getNamespaceDescriptor());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasNamespaceName()) {
          return false;
        }
        if (hasNamespaceDescriptor()) {
          if (!getNamespaceDescriptor().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object namespaceName_ = "";
      /**
       * <code>required string namespace_name = 1;</code>
       * @return Whether the namespaceName field is set.
       */
      public boolean hasNamespaceName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @return The namespaceName.
       */
      public java.lang.String getNamespaceName() {
        java.lang.Object ref = namespaceName_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            namespaceName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @return The bytes for namespaceName.
       */
      public com.google.protobuf.ByteString
          getNamespaceNameBytes() {
        java.lang.Object ref = namespaceName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          namespaceName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @param value The namespaceName to set.
       * @return This builder for chaining.
       */
      public Builder setNamespaceName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        namespaceName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearNamespaceName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        namespaceName_ = getDefaultInstance().getNamespaceName();
        onChanged();
        return this;
      }
      /**
       * <code>required string namespace_name = 1;</code>
       * @param value The bytes for namespaceName to set.
       * @return This builder for chaining.
       */
      public Builder setNamespaceNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        namespaceName_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor namespaceDescriptor_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> namespaceDescriptorBuilder_;
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       * @return Whether the namespaceDescriptor field is set.
       */
      public boolean hasNamespaceDescriptor() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       * @return The namespaceDescriptor.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor getNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          return namespaceDescriptor_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        } else {
          return namespaceDescriptorBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder setNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespaceDescriptor_ = value;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder setNamespaceDescriptor(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder builderForValue) {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = builderForValue.build();
          onChanged();
        } else {
          namespaceDescriptorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder mergeNamespaceDescriptor(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor value) {
        if (namespaceDescriptorBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              namespaceDescriptor_ != null &&
              namespaceDescriptor_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance()) {
            namespaceDescriptor_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.newBuilder(namespaceDescriptor_).mergeFrom(value).buildPartial();
          } else {
            namespaceDescriptor_ = value;
          }
          onChanged();
        } else {
          namespaceDescriptorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public Builder clearNamespaceDescriptor() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptor_ = null;
          onChanged();
        } else {
          namespaceDescriptorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder getNamespaceDescriptorBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getNamespaceDescriptorFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder getNamespaceDescriptorOrBuilder() {
        if (namespaceDescriptorBuilder_ != null) {
          return namespaceDescriptorBuilder_.getMessageOrBuilder();
        } else {
          return namespaceDescriptor_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.getDefaultInstance() : namespaceDescriptor_;
        }
      }
      /**
       * <code>optional .hbase.pb.NamespaceDescriptor namespace_descriptor = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder> 
          getNamespaceDescriptorFieldBuilder() {
        if (namespaceDescriptorBuilder_ == null) {
          namespaceDescriptorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NamespaceDescriptorOrBuilder>(
                  getNamespaceDescriptor(),
                  getParentForChildren(),
                  isClean());
          namespaceDescriptor_ = null;
        }
        return namespaceDescriptorBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteNamespaceStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteNamespaceStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DeleteNamespaceStateData>
        PARSER = new com.google.protobuf.AbstractParser<DeleteNamespaceStateData>() {
      @java.lang.Override
      public DeleteNamespaceStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DeleteNamespaceStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DeleteNamespaceStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DeleteNamespaceStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteNamespaceStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AddColumnFamilyStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.AddColumnFamilyStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     * @return Whether the columnfamilySchema field is set.
     */
    boolean hasColumnfamilySchema();
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     * @return The columnfamilySchema.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema();
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder();

    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return The unmodifiedTableSchema.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.AddColumnFamilyStateData}
   */
  public  static final class AddColumnFamilyStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.AddColumnFamilyStateData)
      AddColumnFamilyStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use AddColumnFamilyStateData.newBuilder() to construct.
    private AddColumnFamilyStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AddColumnFamilyStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new AddColumnFamilyStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private AddColumnFamilyStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) != 0)) {
                subBuilder = columnfamilySchema_.toBuilder();
              }
              columnfamilySchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(columnfamilySchema_);
                columnfamilySchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) != 0)) {
                subBuilder = unmodifiedTableSchema_.toBuilder();
              }
              unmodifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedTableSchema_);
                unmodifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int COLUMNFAMILY_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema columnfamilySchema_;
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     * @return Whether the columnfamilySchema field is set.
     */
    public boolean hasColumnfamilySchema() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     * @return The columnfamilySchema.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema() {
      return columnfamilySchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance() : columnfamilySchema_;
    }
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder() {
      return columnfamilySchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance() : columnfamilySchema_;
    }

    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return The unmodifiedTableSchema.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasColumnfamilySchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getColumnfamilySchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getColumnfamilySchema());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getUnmodifiedTableSchema());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getColumnfamilySchema());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getUnmodifiedTableSchema());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasColumnfamilySchema() != other.hasColumnfamilySchema()) return false;
      if (hasColumnfamilySchema()) {
        if (!getColumnfamilySchema()
            .equals(other.getColumnfamilySchema())) return false;
      }
      if (hasUnmodifiedTableSchema() != other.hasUnmodifiedTableSchema()) return false;
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasColumnfamilySchema()) {
        hash = (37 * hash) + COLUMNFAMILY_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getColumnfamilySchema().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.AddColumnFamilyStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.AddColumnFamilyStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getColumnfamilySchemaFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = null;
        } else {
          columnfamilySchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_AddColumnFamilyStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (userInfoBuilder_ == null) {
            result.userInfo_ = userInfo_;
          } else {
            result.userInfo_ = userInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (tableNameBuilder_ == null) {
            result.tableName_ = tableName_;
          } else {
            result.tableName_ = tableNameBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          if (columnfamilySchemaBuilder_ == null) {
            result.columnfamilySchema_ = columnfamilySchema_;
          } else {
            result.columnfamilySchema_ = columnfamilySchemaBuilder_.build();
          }
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          if (unmodifiedTableSchemaBuilder_ == null) {
            result.unmodifiedTableSchema_ = unmodifiedTableSchema_;
          } else {
            result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_.build();
          }
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasColumnfamilySchema()) {
          mergeColumnfamilySchema(other.getColumnfamilySchema());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasColumnfamilySchema()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        if (!getColumnfamilySchema().isInitialized()) {
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema columnfamilySchema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> columnfamilySchemaBuilder_;
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       * @return Whether the columnfamilySchema field is set.
       */
      public boolean hasColumnfamilySchema() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       * @return The columnfamilySchema.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema() {
        if (columnfamilySchemaBuilder_ == null) {
          return columnfamilySchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance() : columnfamilySchema_;
        } else {
          return columnfamilySchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder setColumnfamilySchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnfamilySchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          columnfamilySchema_ = value;
          onChanged();
        } else {
          columnfamilySchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder setColumnfamilySchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder builderForValue) {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = builderForValue.build();
          onChanged();
        } else {
          columnfamilySchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder mergeColumnfamilySchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnfamilySchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
              columnfamilySchema_ != null &&
              columnfamilySchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance()) {
            columnfamilySchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.newBuilder(columnfamilySchema_).mergeFrom(value).buildPartial();
          } else {
            columnfamilySchema_ = value;
          }
          onChanged();
        } else {
          columnfamilySchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder clearColumnfamilySchema() {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = null;
          onChanged();
        } else {
          columnfamilySchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder getColumnfamilySchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getColumnfamilySchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder() {
        if (columnfamilySchemaBuilder_ != null) {
          return columnfamilySchemaBuilder_.getMessageOrBuilder();
        } else {
          return columnfamilySchema_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance() : columnfamilySchema_;
        }
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> 
          getColumnfamilySchemaFieldBuilder() {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder>(
                  getColumnfamilySchema(),
                  getParentForChildren(),
                  isClean());
          columnfamilySchema_ = null;
        }
        return columnfamilySchemaBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       * @return Whether the unmodifiedTableSchema field is set.
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       * @return The unmodifiedTableSchema.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
              unmodifiedTableSchema_ != null &&
              unmodifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            unmodifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(unmodifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getUnmodifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.AddColumnFamilyStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.AddColumnFamilyStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<AddColumnFamilyStateData>
        PARSER = new com.google.protobuf.AbstractParser<AddColumnFamilyStateData>() {
      @java.lang.Override
      public AddColumnFamilyStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new AddColumnFamilyStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<AddColumnFamilyStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<AddColumnFamilyStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.AddColumnFamilyStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModifyColumnFamilyStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ModifyColumnFamilyStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     * @return Whether the columnfamilySchema field is set.
     */
    boolean hasColumnfamilySchema();
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     * @return The columnfamilySchema.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema();
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder();

    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return The unmodifiedTableSchema.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ModifyColumnFamilyStateData}
   */
  public  static final class ModifyColumnFamilyStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ModifyColumnFamilyStateData)
      ModifyColumnFamilyStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ModifyColumnFamilyStateData.newBuilder() to construct.
    private ModifyColumnFamilyStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModifyColumnFamilyStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ModifyColumnFamilyStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ModifyColumnFamilyStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) != 0)) {
                subBuilder = columnfamilySchema_.toBuilder();
              }
              columnfamilySchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(columnfamilySchema_);
                columnfamilySchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) != 0)) {
                subBuilder = unmodifiedTableSchema_.toBuilder();
              }
              unmodifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedTableSchema_);
                unmodifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int COLUMNFAMILY_SCHEMA_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema columnfamilySchema_;
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     * @return Whether the columnfamilySchema field is set.
     */
    public boolean hasColumnfamilySchema() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     * @return The columnfamilySchema.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema() {
      return columnfamilySchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance() : columnfamilySchema_;
    }
    /**
     * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder() {
      return columnfamilySchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance() : columnfamilySchema_;
    }

    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return The unmodifiedTableSchema.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasColumnfamilySchema()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getColumnfamilySchema().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getColumnfamilySchema());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getUnmodifiedTableSchema());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getColumnfamilySchema());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getUnmodifiedTableSchema());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasColumnfamilySchema() != other.hasColumnfamilySchema()) return false;
      if (hasColumnfamilySchema()) {
        if (!getColumnfamilySchema()
            .equals(other.getColumnfamilySchema())) return false;
      }
      if (hasUnmodifiedTableSchema() != other.hasUnmodifiedTableSchema()) return false;
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasColumnfamilySchema()) {
        hash = (37 * hash) + COLUMNFAMILY_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getColumnfamilySchema().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ModifyColumnFamilyStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ModifyColumnFamilyStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getColumnfamilySchemaFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = null;
        } else {
          columnfamilySchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (userInfoBuilder_ == null) {
            result.userInfo_ = userInfo_;
          } else {
            result.userInfo_ = userInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (tableNameBuilder_ == null) {
            result.tableName_ = tableName_;
          } else {
            result.tableName_ = tableNameBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          if (columnfamilySchemaBuilder_ == null) {
            result.columnfamilySchema_ = columnfamilySchema_;
          } else {
            result.columnfamilySchema_ = columnfamilySchemaBuilder_.build();
          }
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          if (unmodifiedTableSchemaBuilder_ == null) {
            result.unmodifiedTableSchema_ = unmodifiedTableSchema_;
          } else {
            result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_.build();
          }
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasColumnfamilySchema()) {
          mergeColumnfamilySchema(other.getColumnfamilySchema());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasColumnfamilySchema()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        if (!getColumnfamilySchema().isInitialized()) {
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema columnfamilySchema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> columnfamilySchemaBuilder_;
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       * @return Whether the columnfamilySchema field is set.
       */
      public boolean hasColumnfamilySchema() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       * @return The columnfamilySchema.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnfamilySchema() {
        if (columnfamilySchemaBuilder_ == null) {
          return columnfamilySchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance() : columnfamilySchema_;
        } else {
          return columnfamilySchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder setColumnfamilySchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnfamilySchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          columnfamilySchema_ = value;
          onChanged();
        } else {
          columnfamilySchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder setColumnfamilySchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder builderForValue) {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = builderForValue.build();
          onChanged();
        } else {
          columnfamilySchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder mergeColumnfamilySchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnfamilySchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
              columnfamilySchema_ != null &&
              columnfamilySchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance()) {
            columnfamilySchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.newBuilder(columnfamilySchema_).mergeFrom(value).buildPartial();
          } else {
            columnfamilySchema_ = value;
          }
          onChanged();
        } else {
          columnfamilySchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public Builder clearColumnfamilySchema() {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchema_ = null;
          onChanged();
        } else {
          columnfamilySchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder getColumnfamilySchemaBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getColumnfamilySchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnfamilySchemaOrBuilder() {
        if (columnfamilySchemaBuilder_ != null) {
          return columnfamilySchemaBuilder_.getMessageOrBuilder();
        } else {
          return columnfamilySchema_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance() : columnfamilySchema_;
        }
      }
      /**
       * <code>required .hbase.pb.ColumnFamilySchema columnfamily_schema = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> 
          getColumnfamilySchemaFieldBuilder() {
        if (columnfamilySchemaBuilder_ == null) {
          columnfamilySchemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder>(
                  getColumnfamilySchema(),
                  getParentForChildren(),
                  isClean());
          columnfamilySchema_ = null;
        }
        return columnfamilySchemaBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       * @return Whether the unmodifiedTableSchema field is set.
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       * @return The unmodifiedTableSchema.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
              unmodifiedTableSchema_ != null &&
              unmodifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            unmodifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(unmodifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getUnmodifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ModifyColumnFamilyStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ModifyColumnFamilyStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ModifyColumnFamilyStateData>
        PARSER = new com.google.protobuf.AbstractParser<ModifyColumnFamilyStateData>() {
      @java.lang.Override
      public ModifyColumnFamilyStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ModifyColumnFamilyStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModifyColumnFamilyStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ModifyColumnFamilyStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ModifyColumnFamilyStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DeleteColumnFamilyStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DeleteColumnFamilyStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required bytes columnfamily_name = 3;</code>
     * @return Whether the columnfamilyName field is set.
     */
    boolean hasColumnfamilyName();
    /**
     * <code>required bytes columnfamily_name = 3;</code>
     * @return The columnfamilyName.
     */
    com.google.protobuf.ByteString getColumnfamilyName();

    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    boolean hasUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return The unmodifiedTableSchema.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema();
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.DeleteColumnFamilyStateData}
   */
  public  static final class DeleteColumnFamilyStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DeleteColumnFamilyStateData)
      DeleteColumnFamilyStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DeleteColumnFamilyStateData.newBuilder() to construct.
    private DeleteColumnFamilyStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DeleteColumnFamilyStateData() {
      columnfamilyName_ = com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DeleteColumnFamilyStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DeleteColumnFamilyStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              columnfamilyName_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) != 0)) {
                subBuilder = unmodifiedTableSchema_.toBuilder();
              }
              unmodifiedTableSchema_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(unmodifiedTableSchema_);
                unmodifiedTableSchema_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int COLUMNFAMILY_NAME_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString columnfamilyName_;
    /**
     * <code>required bytes columnfamily_name = 3;</code>
     * @return Whether the columnfamilyName field is set.
     */
    public boolean hasColumnfamilyName() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required bytes columnfamily_name = 3;</code>
     * @return The columnfamilyName.
     */
    public com.google.protobuf.ByteString getColumnfamilyName() {
      return columnfamilyName_;
    }

    public static final int UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return Whether the unmodifiedTableSchema field is set.
     */
    public boolean hasUnmodifiedTableSchema() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     * @return The unmodifiedTableSchema.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }
    /**
     * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
      return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasColumnfamilyName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBytes(3, columnfamilyName_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getUnmodifiedTableSchema());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, columnfamilyName_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getUnmodifiedTableSchema());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasColumnfamilyName() != other.hasColumnfamilyName()) return false;
      if (hasColumnfamilyName()) {
        if (!getColumnfamilyName()
            .equals(other.getColumnfamilyName())) return false;
      }
      if (hasUnmodifiedTableSchema() != other.hasUnmodifiedTableSchema()) return false;
      if (hasUnmodifiedTableSchema()) {
        if (!getUnmodifiedTableSchema()
            .equals(other.getUnmodifiedTableSchema())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasColumnfamilyName()) {
        hash = (37 * hash) + COLUMNFAMILY_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getColumnfamilyName().hashCode();
      }
      if (hasUnmodifiedTableSchema()) {
        hash = (37 * hash) + UNMODIFIED_TABLE_SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getUnmodifiedTableSchema().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DeleteColumnFamilyStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DeleteColumnFamilyStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
          getUnmodifiedTableSchemaFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        columnfamilyName_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (userInfoBuilder_ == null) {
            result.userInfo_ = userInfo_;
          } else {
            result.userInfo_ = userInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (tableNameBuilder_ == null) {
            result.tableName_ = tableName_;
          } else {
            result.tableName_ = tableNameBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          to_bitField0_ |= 0x00000004;
        }
        result.columnfamilyName_ = columnfamilyName_;
        if (((from_bitField0_ & 0x00000008) != 0)) {
          if (unmodifiedTableSchemaBuilder_ == null) {
            result.unmodifiedTableSchema_ = unmodifiedTableSchema_;
          } else {
            result.unmodifiedTableSchema_ = unmodifiedTableSchemaBuilder_.build();
          }
          to_bitField0_ |= 0x00000008;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasColumnfamilyName()) {
          setColumnfamilyName(other.getColumnfamilyName());
        }
        if (other.hasUnmodifiedTableSchema()) {
          mergeUnmodifiedTableSchema(other.getUnmodifiedTableSchema());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasColumnfamilyName()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        if (hasUnmodifiedTableSchema()) {
          if (!getUnmodifiedTableSchema().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private com.google.protobuf.ByteString columnfamilyName_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes columnfamily_name = 3;</code>
       * @return Whether the columnfamilyName field is set.
       */
      public boolean hasColumnfamilyName() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required bytes columnfamily_name = 3;</code>
       * @return The columnfamilyName.
       */
      public com.google.protobuf.ByteString getColumnfamilyName() {
        return columnfamilyName_;
      }
      /**
       * <code>required bytes columnfamily_name = 3;</code>
       * @param value The columnfamilyName to set.
       * @return This builder for chaining.
       */
      public Builder setColumnfamilyName(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        columnfamilyName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes columnfamily_name = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearColumnfamilyName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        columnfamilyName_ = getDefaultInstance().getColumnfamilyName();
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema unmodifiedTableSchema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> unmodifiedTableSchemaBuilder_;
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       * @return Whether the unmodifiedTableSchema field is set.
       */
      public boolean hasUnmodifiedTableSchema() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       * @return The unmodifiedTableSchema.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          return unmodifiedTableSchema_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        } else {
          return unmodifiedTableSchemaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          unmodifiedTableSchema_ = value;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder setUnmodifiedTableSchema(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder builderForValue) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = builderForValue.build();
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder mergeUnmodifiedTableSchema(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema value) {
        if (unmodifiedTableSchemaBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
              unmodifiedTableSchema_ != null &&
              unmodifiedTableSchema_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) {
            unmodifiedTableSchema_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder(unmodifiedTableSchema_).mergeFrom(value).buildPartial();
          } else {
            unmodifiedTableSchema_ = value;
          }
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public Builder clearUnmodifiedTableSchema() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchema_ = null;
          onChanged();
        } else {
          unmodifiedTableSchemaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder getUnmodifiedTableSchemaBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUnmodifiedTableSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder getUnmodifiedTableSchemaOrBuilder() {
        if (unmodifiedTableSchemaBuilder_ != null) {
          return unmodifiedTableSchemaBuilder_.getMessageOrBuilder();
        } else {
          return unmodifiedTableSchema_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance() : unmodifiedTableSchema_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableSchema unmodified_table_schema = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder> 
          getUnmodifiedTableSchemaFieldBuilder() {
        if (unmodifiedTableSchemaBuilder_ == null) {
          unmodifiedTableSchemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder>(
                  getUnmodifiedTableSchema(),
                  getParentForChildren(),
                  isClean());
          unmodifiedTableSchema_ = null;
        }
        return unmodifiedTableSchemaBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DeleteColumnFamilyStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DeleteColumnFamilyStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DeleteColumnFamilyStateData>
        PARSER = new com.google.protobuf.AbstractParser<DeleteColumnFamilyStateData>() {
      @java.lang.Override
      public DeleteColumnFamilyStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DeleteColumnFamilyStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DeleteColumnFamilyStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DeleteColumnFamilyStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DeleteColumnFamilyStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface EnableTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.EnableTableStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return Whether the skipTableStateCheck field is set.
     */
    boolean hasSkipTableStateCheck();
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return The skipTableStateCheck.
     */
    boolean getSkipTableStateCheck();
  }
  /**
   * Protobuf type {@code hbase.pb.EnableTableStateData}
   */
  public  static final class EnableTableStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.EnableTableStateData)
      EnableTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use EnableTableStateData.newBuilder() to construct.
    private EnableTableStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private EnableTableStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new EnableTableStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private EnableTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              skipTableStateCheck_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int SKIP_TABLE_STATE_CHECK_FIELD_NUMBER = 3;
    private boolean skipTableStateCheck_;
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return Whether the skipTableStateCheck field is set.
     */
    public boolean hasSkipTableStateCheck() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return The skipTableStateCheck.
     */
    public boolean getSkipTableStateCheck() {
      return skipTableStateCheck_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSkipTableStateCheck()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, skipTableStateCheck_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, skipTableStateCheck_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasSkipTableStateCheck() != other.hasSkipTableStateCheck()) return false;
      if (hasSkipTableStateCheck()) {
        if (getSkipTableStateCheck()
            != other.getSkipTableStateCheck()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasSkipTableStateCheck()) {
        hash = (37 * hash) + SKIP_TABLE_STATE_CHECK_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getSkipTableStateCheck());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.EnableTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.EnableTableStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        skipTableStateCheck_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_EnableTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (userInfoBuilder_ == null) {
            result.userInfo_ = userInfo_;
          } else {
            result.userInfo_ = userInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (tableNameBuilder_ == null) {
            result.tableName_ = tableName_;
          } else {
            result.tableName_ = tableNameBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.skipTableStateCheck_ = skipTableStateCheck_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasSkipTableStateCheck()) {
          setSkipTableStateCheck(other.getSkipTableStateCheck());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasSkipTableStateCheck()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private boolean skipTableStateCheck_ ;
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @return Whether the skipTableStateCheck field is set.
       */
      public boolean hasSkipTableStateCheck() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @return The skipTableStateCheck.
       */
      public boolean getSkipTableStateCheck() {
        return skipTableStateCheck_;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @param value The skipTableStateCheck to set.
       * @return This builder for chaining.
       */
      public Builder setSkipTableStateCheck(boolean value) {
        bitField0_ |= 0x00000004;
        skipTableStateCheck_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearSkipTableStateCheck() {
        bitField0_ = (bitField0_ & ~0x00000004);
        skipTableStateCheck_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.EnableTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.EnableTableStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<EnableTableStateData>
        PARSER = new com.google.protobuf.AbstractParser<EnableTableStateData>() {
      @java.lang.Override
      public EnableTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new EnableTableStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<EnableTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<EnableTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.EnableTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DisableTableStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.DisableTableStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    boolean hasUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo();
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder();

    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    boolean hasTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName();
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder();

    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return Whether the skipTableStateCheck field is set.
     */
    boolean hasSkipTableStateCheck();
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return The skipTableStateCheck.
     */
    boolean getSkipTableStateCheck();
  }
  /**
   * Protobuf type {@code hbase.pb.DisableTableStateData}
   */
  public  static final class DisableTableStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.DisableTableStateData)
      DisableTableStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DisableTableStateData.newBuilder() to construct.
    private DisableTableStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DisableTableStateData() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DisableTableStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private DisableTableStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = userInfo_.toBuilder();
              }
              userInfo_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userInfo_);
                userInfo_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              skipTableStateCheck_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.Builder.class);
    }

    private int bitField0_;
    public static final int USER_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return Whether the userInfo field is set.
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     * @return The userInfo.
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }
    /**
     * <code>required .hbase.pb.UserInformation user_info = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
      return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
    }

    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return Whether the tableName field is set.
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     * @return The tableName.
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }
    /**
     * <code>required .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
    }

    public static final int SKIP_TABLE_STATE_CHECK_FIELD_NUMBER = 3;
    private boolean skipTableStateCheck_;
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return Whether the skipTableStateCheck field is set.
     */
    public boolean hasSkipTableStateCheck() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>required bool skip_table_state_check = 3;</code>
     * @return The skipTableStateCheck.
     */
    public boolean getSkipTableStateCheck() {
      return skipTableStateCheck_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasUserInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSkipTableStateCheck()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getTableName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(3, skipTableStateCheck_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getUserInfo());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTableName());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, skipTableStateCheck_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData) obj;

      if (hasUserInfo() != other.hasUserInfo()) return false;
      if (hasUserInfo()) {
        if (!getUserInfo()
            .equals(other.getUserInfo())) return false;
      }
      if (hasTableName() != other.hasTableName()) return false;
      if (hasTableName()) {
        if (!getTableName()
            .equals(other.getTableName())) return false;
      }
      if (hasSkipTableStateCheck() != other.hasSkipTableStateCheck()) return false;
      if (hasSkipTableStateCheck()) {
        if (getSkipTableStateCheck()
            != other.getSkipTableStateCheck()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasUserInfo()) {
        hash = (37 * hash) + USER_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasSkipTableStateCheck()) {
        hash = (37 * hash) + SKIP_TABLE_STATE_CHECK_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getSkipTableStateCheck());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.DisableTableStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.DisableTableStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUserInfoFieldBuilder();
          getTableNameFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = null;
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        skipTableStateCheck_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_DisableTableStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (userInfoBuilder_ == null) {
            result.userInfo_ = userInfo_;
          } else {
            result.userInfo_ = userInfoBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (tableNameBuilder_ == null) {
            result.tableName_ = tableName_;
          } else {
            result.tableName_ = tableNameBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.skipTableStateCheck_ = skipTableStateCheck_;
          to_bitField0_ |= 0x00000004;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData.getDefaultInstance()) return this;
        if (other.hasUserInfo()) {
          mergeUserInfo(other.getUserInfo());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasSkipTableStateCheck()) {
          setSkipTableStateCheck(other.getSkipTableStateCheck());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasUserInfo()) {
          return false;
        }
        if (!hasTableName()) {
          return false;
        }
        if (!hasSkipTableStateCheck()) {
          return false;
        }
        if (!getUserInfo().isInitialized()) {
          return false;
        }
        if (!getTableName().isInitialized()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation userInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> userInfoBuilder_;
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return Whether the userInfo field is set.
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       * @return The userInfo.
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation getUserInfo() {
        if (userInfoBuilder_ == null) {
          return userInfo_ == null ? org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        } else {
          return userInfoBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userInfo_ = value;
          onChanged();
        } else {
          userInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder setUserInfo(
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder builderForValue) {
        if (userInfoBuilder_ == null) {
          userInfo_ = builderForValue.build();
          onChanged();
        } else {
          userInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder mergeUserInfo(org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation value) {
        if (userInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              userInfo_ != null &&
              userInfo_ != org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance()) {
            userInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.newBuilder(userInfo_).mergeFrom(value).buildPartial();
          } else {
            userInfo_ = value;
          }
          onChanged();
        } else {
          userInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public Builder clearUserInfo() {
        if (userInfoBuilder_ == null) {
          userInfo_ = null;
          onChanged();
        } else {
          userInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder getUserInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserInfoFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder getUserInfoOrBuilder() {
        if (userInfoBuilder_ != null) {
          return userInfoBuilder_.getMessageOrBuilder();
        } else {
          return userInfo_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.getDefaultInstance() : userInfo_;
        }
      }
      /**
       * <code>required .hbase.pb.UserInformation user_info = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder> 
          getUserInfoFieldBuilder() {
        if (userInfoBuilder_ == null) {
          userInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformation.Builder, org.apache.hadoop.hbase.protobuf.generated.RPCProtos.UserInformationOrBuilder>(
                  getUserInfo(),
                  getParentForChildren(),
                  isClean());
          userInfo_ = null;
        }
        return userInfoBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName tableName_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return Whether the tableName field is set.
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       * @return The tableName.
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_ == null ? org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              tableName_ != null &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = null;
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.getDefaultInstance() : tableName_;
        }
      }
      /**
       * <code>required .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.TableProtos.TableNameOrBuilder>(
                  getTableName(),
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      private boolean skipTableStateCheck_ ;
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @return Whether the skipTableStateCheck field is set.
       */
      public boolean hasSkipTableStateCheck() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @return The skipTableStateCheck.
       */
      public boolean getSkipTableStateCheck() {
        return skipTableStateCheck_;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @param value The skipTableStateCheck to set.
       * @return This builder for chaining.
       */
      public Builder setSkipTableStateCheck(boolean value) {
        bitField0_ |= 0x00000004;
        skipTableStateCheck_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool skip_table_state_check = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearSkipTableStateCheck() {
        bitField0_ = (bitField0_ & ~0x00000004);
        skipTableStateCheck_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.DisableTableStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.DisableTableStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<DisableTableStateData>
        PARSER = new com.google.protobuf.AbstractParser<DisableTableStateData>() {
      @java.lang.Override
      public DisableTableStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DisableTableStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<DisableTableStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DisableTableStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.DisableTableStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ServerCrashStateDataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ServerCrashStateData)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    boolean hasServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getServerName();
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder();

    /**
     * <code>optional bool distributed_log_replay = 2;</code>
     * @return Whether the distributedLogReplay field is set.
     */
    boolean hasDistributedLogReplay();
    /**
     * <code>optional bool distributed_log_replay = 2;</code>
     * @return The distributedLogReplay.
     */
    boolean getDistributedLogReplay();

    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionsOnCrashedServerList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    int getRegionsOnCrashedServerCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsOnCrashedServerOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
        int index);

    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> 
        getRegionsAssignedList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index);
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    int getRegionsAssignedCount();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsAssignedOrBuilderList();
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
        int index);

    /**
     * <code>optional bool carrying_meta = 5;</code>
     * @return Whether the carryingMeta field is set.
     */
    boolean hasCarryingMeta();
    /**
     * <code>optional bool carrying_meta = 5;</code>
     * @return The carryingMeta.
     */
    boolean getCarryingMeta();

    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     * @return Whether the shouldSplitWal field is set.
     */
    boolean hasShouldSplitWal();
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     * @return The shouldSplitWal.
     */
    boolean getShouldSplitWal();
  }
  /**
   * Protobuf type {@code hbase.pb.ServerCrashStateData}
   */
  public  static final class ServerCrashStateData extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ServerCrashStateData)
      ServerCrashStateDataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ServerCrashStateData.newBuilder() to construct.
    private ServerCrashStateData(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ServerCrashStateData() {
      regionsOnCrashedServer_ = java.util.Collections.emptyList();
      regionsAssigned_ = java.util.Collections.emptyList();
      shouldSplitWal_ = true;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ServerCrashStateData();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ServerCrashStateData(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = serverName_.toBuilder();
              }
              serverName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(serverName_);
                serverName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              distributedLogReplay_ = input.readBool();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                regionsOnCrashedServer_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              regionsOnCrashedServer_.add(
                  input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) != 0)) {
                regionsAssigned_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>();
                mutable_bitField0_ |= 0x00000008;
              }
              regionsAssigned_.add(
                  input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.PARSER, extensionRegistry));
              break;
            }
            case 40: {
              bitField0_ |= 0x00000004;
              carryingMeta_ = input.readBool();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000008;
              shouldSplitWal_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) != 0)) {
          regionsOnCrashedServer_ = java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        }
        if (((mutable_bitField0_ & 0x00000008) != 0)) {
          regionsAssigned_ = java.util.Collections.unmodifiableList(regionsAssigned_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.Builder.class);
    }

    private int bitField0_;
    public static final int SERVER_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName serverName_;
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return Whether the serverName field is set.
     */
    public boolean hasServerName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     * @return The serverName.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getServerName() {
      return serverName_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }
    /**
     * <code>required .hbase.pb.ServerName server_name = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
      return serverName_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
    }

    public static final int DISTRIBUTED_LOG_REPLAY_FIELD_NUMBER = 2;
    private boolean distributedLogReplay_;
    /**
     * <code>optional bool distributed_log_replay = 2;</code>
     * @return Whether the distributedLogReplay field is set.
     */
    public boolean hasDistributedLogReplay() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional bool distributed_log_replay = 2;</code>
     * @return The distributedLogReplay.
     */
    public boolean getDistributedLogReplay() {
      return distributedLogReplay_;
    }

    public static final int REGIONS_ON_CRASHED_SERVER_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionsOnCrashedServer_;
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionsOnCrashedServerList() {
      return regionsOnCrashedServer_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsOnCrashedServerOrBuilderList() {
      return regionsOnCrashedServer_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public int getRegionsOnCrashedServerCount() {
      return regionsOnCrashedServer_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index) {
      return regionsOnCrashedServer_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
        int index) {
      return regionsOnCrashedServer_.get(index);
    }

    public static final int REGIONS_ASSIGNED_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionsAssigned_;
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionsAssignedList() {
      return regionsAssigned_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
        getRegionsAssignedOrBuilderList() {
      return regionsAssigned_;
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public int getRegionsAssignedCount() {
      return regionsAssigned_.size();
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index) {
      return regionsAssigned_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
        int index) {
      return regionsAssigned_.get(index);
    }

    public static final int CARRYING_META_FIELD_NUMBER = 5;
    private boolean carryingMeta_;
    /**
     * <code>optional bool carrying_meta = 5;</code>
     * @return Whether the carryingMeta field is set.
     */
    public boolean hasCarryingMeta() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional bool carrying_meta = 5;</code>
     * @return The carryingMeta.
     */
    public boolean getCarryingMeta() {
      return carryingMeta_;
    }

    public static final int SHOULD_SPLIT_WAL_FIELD_NUMBER = 6;
    private boolean shouldSplitWal_;
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     * @return Whether the shouldSplitWal field is set.
     */
    public boolean hasShouldSplitWal() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional bool should_split_wal = 6 [default = true];</code>
     * @return The shouldSplitWal.
     */
    public boolean getShouldSplitWal() {
      return shouldSplitWal_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasServerName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getServerName().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getRegionsOnCrashedServerCount(); i++) {
        if (!getRegionsOnCrashedServer(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionsAssignedCount(); i++) {
        if (!getRegionsAssigned(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getServerName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeBool(2, distributedLogReplay_);
      }
      for (int i = 0; i < regionsOnCrashedServer_.size(); i++) {
        output.writeMessage(3, regionsOnCrashedServer_.get(i));
      }
      for (int i = 0; i < regionsAssigned_.size(); i++) {
        output.writeMessage(4, regionsAssigned_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeBool(5, carryingMeta_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeBool(6, shouldSplitWal_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getServerName());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, distributedLogReplay_);
      }
      for (int i = 0; i < regionsOnCrashedServer_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, regionsOnCrashedServer_.get(i));
      }
      for (int i = 0; i < regionsAssigned_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, regionsAssigned_.get(i));
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, carryingMeta_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, shouldSplitWal_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData other = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) obj;

      if (hasServerName() != other.hasServerName()) return false;
      if (hasServerName()) {
        if (!getServerName()
            .equals(other.getServerName())) return false;
      }
      if (hasDistributedLogReplay() != other.hasDistributedLogReplay()) return false;
      if (hasDistributedLogReplay()) {
        if (getDistributedLogReplay()
            != other.getDistributedLogReplay()) return false;
      }
      if (!getRegionsOnCrashedServerList()
          .equals(other.getRegionsOnCrashedServerList())) return false;
      if (!getRegionsAssignedList()
          .equals(other.getRegionsAssignedList())) return false;
      if (hasCarryingMeta() != other.hasCarryingMeta()) return false;
      if (hasCarryingMeta()) {
        if (getCarryingMeta()
            != other.getCarryingMeta()) return false;
      }
      if (hasShouldSplitWal() != other.hasShouldSplitWal()) return false;
      if (hasShouldSplitWal()) {
        if (getShouldSplitWal()
            != other.getShouldSplitWal()) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasServerName()) {
        hash = (37 * hash) + SERVER_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServerName().hashCode();
      }
      if (hasDistributedLogReplay()) {
        hash = (37 * hash) + DISTRIBUTED_LOG_REPLAY_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getDistributedLogReplay());
      }
      if (getRegionsOnCrashedServerCount() > 0) {
        hash = (37 * hash) + REGIONS_ON_CRASHED_SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getRegionsOnCrashedServerList().hashCode();
      }
      if (getRegionsAssignedCount() > 0) {
        hash = (37 * hash) + REGIONS_ASSIGNED_FIELD_NUMBER;
        hash = (53 * hash) + getRegionsAssignedList().hashCode();
      }
      if (hasCarryingMeta()) {
        hash = (37 * hash) + CARRYING_META_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getCarryingMeta());
      }
      if (hasShouldSplitWal()) {
        hash = (37 * hash) + SHOULD_SPLIT_WAL_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getShouldSplitWal());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ServerCrashStateData}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ServerCrashStateData)
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateDataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.class, org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getServerNameFieldBuilder();
          getRegionsOnCrashedServerFieldBuilder();
          getRegionsAssignedFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (serverNameBuilder_ == null) {
          serverName_ = null;
        } else {
          serverNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        distributedLogReplay_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServer_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          regionsOnCrashedServerBuilder_.clear();
        }
        if (regionsAssignedBuilder_ == null) {
          regionsAssigned_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          regionsAssignedBuilder_.clear();
        }
        carryingMeta_ = false;
        bitField0_ = (bitField0_ & ~0x00000010);
        shouldSplitWal_ = true;
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.internal_static_hbase_pb_ServerCrashStateData_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData build() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData result = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (serverNameBuilder_ == null) {
            result.serverName_ = serverName_;
          } else {
            result.serverName_ = serverNameBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.distributedLogReplay_ = distributedLogReplay_;
          to_bitField0_ |= 0x00000002;
        }
        if (regionsOnCrashedServerBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            regionsOnCrashedServer_ = java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.regionsOnCrashedServer_ = regionsOnCrashedServer_;
        } else {
          result.regionsOnCrashedServer_ = regionsOnCrashedServerBuilder_.build();
        }
        if (regionsAssignedBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0)) {
            regionsAssigned_ = java.util.Collections.unmodifiableList(regionsAssigned_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.regionsAssigned_ = regionsAssigned_;
        } else {
          result.regionsAssigned_ = regionsAssignedBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.carryingMeta_ = carryingMeta_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          to_bitField0_ |= 0x00000008;
        }
        result.shouldSplitWal_ = shouldSplitWal_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData.getDefaultInstance()) return this;
        if (other.hasServerName()) {
          mergeServerName(other.getServerName());
        }
        if (other.hasDistributedLogReplay()) {
          setDistributedLogReplay(other.getDistributedLogReplay());
        }
        if (regionsOnCrashedServerBuilder_ == null) {
          if (!other.regionsOnCrashedServer_.isEmpty()) {
            if (regionsOnCrashedServer_.isEmpty()) {
              regionsOnCrashedServer_ = other.regionsOnCrashedServer_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureRegionsOnCrashedServerIsMutable();
              regionsOnCrashedServer_.addAll(other.regionsOnCrashedServer_);
            }
            onChanged();
          }
        } else {
          if (!other.regionsOnCrashedServer_.isEmpty()) {
            if (regionsOnCrashedServerBuilder_.isEmpty()) {
              regionsOnCrashedServerBuilder_.dispose();
              regionsOnCrashedServerBuilder_ = null;
              regionsOnCrashedServer_ = other.regionsOnCrashedServer_;
              bitField0_ = (bitField0_ & ~0x00000004);
              regionsOnCrashedServerBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionsOnCrashedServerFieldBuilder() : null;
            } else {
              regionsOnCrashedServerBuilder_.addAllMessages(other.regionsOnCrashedServer_);
            }
          }
        }
        if (regionsAssignedBuilder_ == null) {
          if (!other.regionsAssigned_.isEmpty()) {
            if (regionsAssigned_.isEmpty()) {
              regionsAssigned_ = other.regionsAssigned_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureRegionsAssignedIsMutable();
              regionsAssigned_.addAll(other.regionsAssigned_);
            }
            onChanged();
          }
        } else {
          if (!other.regionsAssigned_.isEmpty()) {
            if (regionsAssignedBuilder_.isEmpty()) {
              regionsAssignedBuilder_.dispose();
              regionsAssignedBuilder_ = null;
              regionsAssigned_ = other.regionsAssigned_;
              bitField0_ = (bitField0_ & ~0x00000008);
              regionsAssignedBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getRegionsAssignedFieldBuilder() : null;
            } else {
              regionsAssignedBuilder_.addAllMessages(other.regionsAssigned_);
            }
          }
        }
        if (other.hasCarryingMeta()) {
          setCarryingMeta(other.getCarryingMeta());
        }
        if (other.hasShouldSplitWal()) {
          setShouldSplitWal(other.getShouldSplitWal());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasServerName()) {
          return false;
        }
        if (!getServerName().isInitialized()) {
          return false;
        }
        for (int i = 0; i < getRegionsOnCrashedServerCount(); i++) {
          if (!getRegionsOnCrashedServer(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getRegionsAssignedCount(); i++) {
          if (!getRegionsAssigned(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName serverName_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverNameBuilder_;
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       * @return Whether the serverName field is set.
       */
      public boolean hasServerName() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       * @return The serverName.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getServerName() {
        if (serverNameBuilder_ == null) {
          return serverName_ == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        } else {
          return serverNameBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serverName_ = value;
          onChanged();
        } else {
          serverNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder setServerName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverNameBuilder_ == null) {
          serverName_ = builderForValue.build();
          onChanged();
        } else {
          serverNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder mergeServerName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              serverName_ != null &&
              serverName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            serverName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder(serverName_).mergeFrom(value).buildPartial();
          } else {
            serverName_ = value;
          }
          onChanged();
        } else {
          serverNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public Builder clearServerName() {
        if (serverNameBuilder_ == null) {
          serverName_ = null;
          onChanged();
        } else {
          serverNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder getServerNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getServerNameFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerNameOrBuilder() {
        if (serverNameBuilder_ != null) {
          return serverNameBuilder_.getMessageOrBuilder();
        } else {
          return serverName_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance() : serverName_;
        }
      }
      /**
       * <code>required .hbase.pb.ServerName server_name = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerNameFieldBuilder() {
        if (serverNameBuilder_ == null) {
          serverNameBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  getServerName(),
                  getParentForChildren(),
                  isClean());
          serverName_ = null;
        }
        return serverNameBuilder_;
      }

      private boolean distributedLogReplay_ ;
      /**
       * <code>optional bool distributed_log_replay = 2;</code>
       * @return Whether the distributedLogReplay field is set.
       */
      public boolean hasDistributedLogReplay() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional bool distributed_log_replay = 2;</code>
       * @return The distributedLogReplay.
       */
      public boolean getDistributedLogReplay() {
        return distributedLogReplay_;
      }
      /**
       * <code>optional bool distributed_log_replay = 2;</code>
       * @param value The distributedLogReplay to set.
       * @return This builder for chaining.
       */
      public Builder setDistributedLogReplay(boolean value) {
        bitField0_ |= 0x00000002;
        distributedLogReplay_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool distributed_log_replay = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearDistributedLogReplay() {
        bitField0_ = (bitField0_ & ~0x00000002);
        distributedLogReplay_ = false;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionsOnCrashedServer_ =
        java.util.Collections.emptyList();
      private void ensureRegionsOnCrashedServerIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          regionsOnCrashedServer_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionsOnCrashedServer_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionsOnCrashedServerBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionsOnCrashedServerList() {
        if (regionsOnCrashedServerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        } else {
          return regionsOnCrashedServerBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public int getRegionsOnCrashedServerCount() {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.size();
        } else {
          return regionsOnCrashedServerBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsOnCrashedServer(int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.get(index);
        } else {
          return regionsOnCrashedServerBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder setRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.set(index, value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder setRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsOnCrashedServerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(index, value);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addRegionsOnCrashedServer(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder addAllRegionsOnCrashedServer(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionsOnCrashedServer_);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder clearRegionsOnCrashedServer() {
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServer_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public Builder removeRegionsOnCrashedServer(int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          ensureRegionsOnCrashedServerIsMutable();
          regionsOnCrashedServer_.remove(index);
          onChanged();
        } else {
          regionsOnCrashedServerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionsOnCrashedServerBuilder(
          int index) {
        return getRegionsOnCrashedServerFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsOnCrashedServerOrBuilder(
          int index) {
        if (regionsOnCrashedServerBuilder_ == null) {
          return regionsOnCrashedServer_.get(index);  } else {
          return regionsOnCrashedServerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionsOnCrashedServerOrBuilderList() {
        if (regionsOnCrashedServerBuilder_ != null) {
          return regionsOnCrashedServerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionsOnCrashedServer_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsOnCrashedServerBuilder() {
        return getRegionsOnCrashedServerFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsOnCrashedServerBuilder(
          int index) {
        return getRegionsOnCrashedServerFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_on_crashed_server = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionsOnCrashedServerBuilderList() {
        return getRegionsOnCrashedServerFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionsOnCrashedServerFieldBuilder() {
        if (regionsOnCrashedServerBuilder_ == null) {
          regionsOnCrashedServerBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionsOnCrashedServer_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          regionsOnCrashedServer_ = null;
        }
        return regionsOnCrashedServerBuilder_;
      }

      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> regionsAssigned_ =
        java.util.Collections.emptyList();
      private void ensureRegionsAssignedIsMutable() {
        if (!((bitField0_ & 0x00000008) != 0)) {
          regionsAssigned_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo>(regionsAssigned_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionsAssignedBuilder_;

      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> getRegionsAssignedList() {
        if (regionsAssignedBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionsAssigned_);
        } else {
          return regionsAssignedBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public int getRegionsAssignedCount() {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.size();
        } else {
          return regionsAssignedBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionsAssigned(int index) {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.get(index);
        } else {
          return regionsAssignedBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder setRegionsAssigned(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.set(index, value);
          onChanged();
        } else {
          regionsAssignedBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder setRegionsAssigned(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(value);
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionsAssignedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(index, value);
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addRegionsAssigned(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionsAssignedBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder addAllRegionsAssigned(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo> values) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, regionsAssigned_);
          onChanged();
        } else {
          regionsAssignedBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder clearRegionsAssigned() {
        if (regionsAssignedBuilder_ == null) {
          regionsAssigned_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          regionsAssignedBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public Builder removeRegionsAssigned(int index) {
        if (regionsAssignedBuilder_ == null) {
          ensureRegionsAssignedIsMutable();
          regionsAssigned_.remove(index);
          onChanged();
        } else {
          regionsAssignedBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionsAssignedBuilder(
          int index) {
        return getRegionsAssignedFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionsAssignedOrBuilder(
          int index) {
        if (regionsAssignedBuilder_ == null) {
          return regionsAssigned_.get(index);  } else {
          return regionsAssignedBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
           getRegionsAssignedOrBuilderList() {
        if (regionsAssignedBuilder_ != null) {
          return regionsAssignedBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionsAssigned_);
        }
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsAssignedBuilder() {
        return getRegionsAssignedFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder addRegionsAssignedBuilder(
          int index) {
        return getRegionsAssignedFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.RegionInfo regions_assigned = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder> 
           getRegionsAssignedBuilderList() {
        return getRegionsAssignedFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionsAssignedFieldBuilder() {
        if (regionsAssignedBuilder_ == null) {
          regionsAssignedBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionsAssigned_,
                  ((bitField0_ & 0x00000008) != 0),
                  getParentForChildren(),
                  isClean());
          regionsAssigned_ = null;
        }
        return regionsAssignedBuilder_;
      }

      private boolean carryingMeta_ ;
      /**
       * <code>optional bool carrying_meta = 5;</code>
       * @return Whether the carryingMeta field is set.
       */
      public boolean hasCarryingMeta() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       * @return The carryingMeta.
       */
      public boolean getCarryingMeta() {
        return carryingMeta_;
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       * @param value The carryingMeta to set.
       * @return This builder for chaining.
       */
      public Builder setCarryingMeta(boolean value) {
        bitField0_ |= 0x00000010;
        carryingMeta_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool carrying_meta = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearCarryingMeta() {
        bitField0_ = (bitField0_ & ~0x00000010);
        carryingMeta_ = false;
        onChanged();
        return this;
      }

      private boolean shouldSplitWal_ = true;
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       * @return Whether the shouldSplitWal field is set.
       */
      public boolean hasShouldSplitWal() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       * @return The shouldSplitWal.
       */
      public boolean getShouldSplitWal() {
        return shouldSplitWal_;
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       * @param value The shouldSplitWal to set.
       * @return This builder for chaining.
       */
      public Builder setShouldSplitWal(boolean value) {
        bitField0_ |= 0x00000020;
        shouldSplitWal_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool should_split_wal = 6 [default = true];</code>
       * @return This builder for chaining.
       */
      public Builder clearShouldSplitWal() {
        bitField0_ = (bitField0_ & ~0x00000020);
        shouldSplitWal_ = true;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ServerCrashStateData)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ServerCrashStateData)
    private static final org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ServerCrashStateData>
        PARSER = new com.google.protobuf.AbstractParser<ServerCrashStateData>() {
      @java.lang.Override
      public ServerCrashStateData parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ServerCrashStateData(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ServerCrashStateData> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ServerCrashStateData> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.MasterProcedureProtos.ServerCrashStateData getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CreateTableStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyTableStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_TruncateTableStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteTableStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CreateNamespaceStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyNamespaceStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteNamespaceStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_AddColumnFamilyStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_AddColumnFamilyStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ModifyColumnFamilyStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DeleteColumnFamilyStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_EnableTableStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_DisableTableStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ServerCrashStateData_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\025MasterProcedure.proto\022\010hbase.pb\032\013Table" +
      ".proto\032\013HBase.proto\032\tRPC.proto\"\234\001\n\024Creat" +
      "eTableStateData\022,\n\tuser_info\030\001 \002(\0132\031.hba" +
      "se.pb.UserInformation\022+\n\014table_schema\030\002 " +
      "\002(\0132\025.hbase.pb.TableSchema\022)\n\013region_inf" +
      "o\030\003 \003(\0132\024.hbase.pb.RegionInfo\"\332\001\n\024Modify" +
      "TableStateData\022,\n\tuser_info\030\001 \002(\0132\031.hbas" +
      "e.pb.UserInformation\0226\n\027unmodified_table" +
      "_schema\030\002 \001(\0132\025.hbase.pb.TableSchema\0224\n\025" +
      "modified_table_schema\030\003 \002(\0132\025.hbase.pb.T" +
      "ableSchema\022&\n\036delete_column_family_in_mo" +
      "dify\030\004 \002(\010\"\340\001\n\026TruncateTableStateData\022,\n" +
      "\tuser_info\030\001 \002(\0132\031.hbase.pb.UserInformat" +
      "ion\022\027\n\017preserve_splits\030\002 \002(\010\022\'\n\ntable_na" +
      "me\030\003 \001(\0132\023.hbase.pb.TableName\022+\n\014table_s" +
      "chema\030\004 \001(\0132\025.hbase.pb.TableSchema\022)\n\013re" +
      "gion_info\030\005 \003(\0132\024.hbase.pb.RegionInfo\"\230\001" +
      "\n\024DeleteTableStateData\022,\n\tuser_info\030\001 \002(" +
      "\0132\031.hbase.pb.UserInformation\022\'\n\ntable_na" +
      "me\030\002 \002(\0132\023.hbase.pb.TableName\022)\n\013region_" +
      "info\030\003 \003(\0132\024.hbase.pb.RegionInfo\"W\n\030Crea" +
      "teNamespaceStateData\022;\n\024namespace_descri" +
      "ptor\030\001 \002(\0132\035.hbase.pb.NamespaceDescripto" +
      "r\"\237\001\n\030ModifyNamespaceStateData\022;\n\024namesp" +
      "ace_descriptor\030\001 \002(\0132\035.hbase.pb.Namespac" +
      "eDescriptor\022F\n\037unmodified_namespace_desc" +
      "riptor\030\002 \001(\0132\035.hbase.pb.NamespaceDescrip" +
      "tor\"o\n\030DeleteNamespaceStateData\022\026\n\016names" +
      "pace_name\030\001 \002(\t\022;\n\024namespace_descriptor\030" +
      "\002 \001(\0132\035.hbase.pb.NamespaceDescriptor\"\344\001\n" +
      "\030AddColumnFamilyStateData\022,\n\tuser_info\030\001" +
      " \002(\0132\031.hbase.pb.UserInformation\022\'\n\ntable" +
      "_name\030\002 \002(\0132\023.hbase.pb.TableName\0229\n\023colu" +
      "mnfamily_schema\030\003 \002(\0132\034.hbase.pb.ColumnF" +
      "amilySchema\0226\n\027unmodified_table_schema\030\004" +
      " \001(\0132\025.hbase.pb.TableSchema\"\347\001\n\033ModifyCo" +
      "lumnFamilyStateData\022,\n\tuser_info\030\001 \002(\0132\031" +
      ".hbase.pb.UserInformation\022\'\n\ntable_name\030" +
      "\002 \002(\0132\023.hbase.pb.TableName\0229\n\023columnfami" +
      "ly_schema\030\003 \002(\0132\034.hbase.pb.ColumnFamilyS" +
      "chema\0226\n\027unmodified_table_schema\030\004 \001(\0132\025" +
      ".hbase.pb.TableSchema\"\307\001\n\033DeleteColumnFa" +
      "milyStateData\022,\n\tuser_info\030\001 \002(\0132\031.hbase" +
      ".pb.UserInformation\022\'\n\ntable_name\030\002 \002(\0132" +
      "\023.hbase.pb.TableName\022\031\n\021columnfamily_nam" +
      "e\030\003 \002(\014\0226\n\027unmodified_table_schema\030\004 \001(\013" +
      "2\025.hbase.pb.TableSchema\"\215\001\n\024EnableTableS" +
      "tateData\022,\n\tuser_info\030\001 \002(\0132\031.hbase.pb.U" +
      "serInformation\022\'\n\ntable_name\030\002 \002(\0132\023.hba" +
      "se.pb.TableName\022\036\n\026skip_table_state_chec" +
      "k\030\003 \002(\010\"\216\001\n\025DisableTableStateData\022,\n\tuse" +
      "r_info\030\001 \002(\0132\031.hbase.pb.UserInformation\022" +
      "\'\n\ntable_name\030\002 \002(\0132\023.hbase.pb.TableName" +
      "\022\036\n\026skip_table_state_check\030\003 \002(\010\"\201\002\n\024Ser" +
      "verCrashStateData\022)\n\013server_name\030\001 \002(\0132\024" +
      ".hbase.pb.ServerName\022\036\n\026distributed_log_" +
      "replay\030\002 \001(\010\0227\n\031regions_on_crashed_serve" +
      "r\030\003 \003(\0132\024.hbase.pb.RegionInfo\022.\n\020regions" +
      "_assigned\030\004 \003(\0132\024.hbase.pb.RegionInfo\022\025\n" +
      "\rcarrying_meta\030\005 \001(\010\022\036\n\020should_split_wal" +
      "\030\006 \001(\010:\004true*\330\001\n\020CreateTableState\022\036\n\032CRE" +
      "ATE_TABLE_PRE_OPERATION\020\001\022 \n\034CREATE_TABL" +
      "E_WRITE_FS_LAYOUT\020\002\022\034\n\030CREATE_TABLE_ADD_" +
      "TO_META\020\003\022\037\n\033CREATE_TABLE_ASSIGN_REGIONS" +
      "\020\004\022\"\n\036CREATE_TABLE_UPDATE_DESC_CACHE\020\005\022\037" +
      "\n\033CREATE_TABLE_POST_OPERATION\020\006*\207\002\n\020Modi" +
      "fyTableState\022\030\n\024MODIFY_TABLE_PREPARE\020\001\022\036" +
      "\n\032MODIFY_TABLE_PRE_OPERATION\020\002\022(\n$MODIFY" +
      "_TABLE_UPDATE_TABLE_DESCRIPTOR\020\003\022&\n\"MODI" +
      "FY_TABLE_REMOVE_REPLICA_COLUMN\020\004\022!\n\035MODI" +
      "FY_TABLE_DELETE_FS_LAYOUT\020\005\022\037\n\033MODIFY_TA" +
      "BLE_POST_OPERATION\020\006\022#\n\037MODIFY_TABLE_REO" +
      "PEN_ALL_REGIONS\020\007*\212\002\n\022TruncateTableState" +
      "\022 \n\034TRUNCATE_TABLE_PRE_OPERATION\020\001\022#\n\037TR" +
      "UNCATE_TABLE_REMOVE_FROM_META\020\002\022\"\n\036TRUNC" +
      "ATE_TABLE_CLEAR_FS_LAYOUT\020\003\022#\n\037TRUNCATE_" +
      "TABLE_CREATE_FS_LAYOUT\020\004\022\036\n\032TRUNCATE_TAB" +
      "LE_ADD_TO_META\020\005\022!\n\035TRUNCATE_TABLE_ASSIG" +
      "N_REGIONS\020\006\022!\n\035TRUNCATE_TABLE_POST_OPERA" +
      "TION\020\007*\337\001\n\020DeleteTableState\022\036\n\032DELETE_TA" +
      "BLE_PRE_OPERATION\020\001\022!\n\035DELETE_TABLE_REMO" +
      "VE_FROM_META\020\002\022 \n\034DELETE_TABLE_CLEAR_FS_" +
      "LAYOUT\020\003\022\"\n\036DELETE_TABLE_UPDATE_DESC_CAC" +
      "HE\020\004\022!\n\035DELETE_TABLE_UNASSIGN_REGIONS\020\005\022" +
      "\037\n\033DELETE_TABLE_POST_OPERATION\020\006*\320\001\n\024Cre" +
      "ateNamespaceState\022\034\n\030CREATE_NAMESPACE_PR" +
      "EPARE\020\001\022%\n!CREATE_NAMESPACE_CREATE_DIREC" +
      "TORY\020\002\022)\n%CREATE_NAMESPACE_INSERT_INTO_N" +
      "S_TABLE\020\003\022\036\n\032CREATE_NAMESPACE_UPDATE_ZK\020" +
      "\004\022(\n$CREATE_NAMESPACE_SET_NAMESPACE_QUOT" +
      "A\020\005*z\n\024ModifyNamespaceState\022\034\n\030MODIFY_NA" +
      "MESPACE_PREPARE\020\001\022$\n MODIFY_NAMESPACE_UP" +
      "DATE_NS_TABLE\020\002\022\036\n\032MODIFY_NAMESPACE_UPDA" +
      "TE_ZK\020\003*\332\001\n\024DeleteNamespaceState\022\034\n\030DELE" +
      "TE_NAMESPACE_PREPARE\020\001\022)\n%DELETE_NAMESPA" +
      "CE_DELETE_FROM_NS_TABLE\020\002\022#\n\037DELETE_NAME" +
      "SPACE_REMOVE_FROM_ZK\020\003\022\'\n#DELETE_NAMESPA" +
      "CE_DELETE_DIRECTORIES\020\004\022+\n\'DELETE_NAMESP" +
      "ACE_REMOVE_NAMESPACE_QUOTA\020\005*\331\001\n\024AddColu" +
      "mnFamilyState\022\035\n\031ADD_COLUMN_FAMILY_PREPA" +
      "RE\020\001\022#\n\037ADD_COLUMN_FAMILY_PRE_OPERATION\020" +
      "\002\022-\n)ADD_COLUMN_FAMILY_UPDATE_TABLE_DESC" +
      "RIPTOR\020\003\022$\n ADD_COLUMN_FAMILY_POST_OPERA" +
      "TION\020\004\022(\n$ADD_COLUMN_FAMILY_REOPEN_ALL_R" +
      "EGIONS\020\005*\353\001\n\027ModifyColumnFamilyState\022 \n\034" +
      "MODIFY_COLUMN_FAMILY_PREPARE\020\001\022&\n\"MODIFY" +
      "_COLUMN_FAMILY_PRE_OPERATION\020\002\0220\n,MODIFY" +
      "_COLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR\020\003" +
      "\022\'\n#MODIFY_COLUMN_FAMILY_POST_OPERATION\020" +
      "\004\022+\n\'MODIFY_COLUMN_FAMILY_REOPEN_ALL_REG" +
      "IONS\020\005*\226\002\n\027DeleteColumnFamilyState\022 \n\034DE" +
      "LETE_COLUMN_FAMILY_PREPARE\020\001\022&\n\"DELETE_C" +
      "OLUMN_FAMILY_PRE_OPERATION\020\002\0220\n,DELETE_C" +
      "OLUMN_FAMILY_UPDATE_TABLE_DESCRIPTOR\020\003\022)" +
      "\n%DELETE_COLUMN_FAMILY_DELETE_FS_LAYOUT\020" +
      "\004\022\'\n#DELETE_COLUMN_FAMILY_POST_OPERATION" +
      "\020\005\022+\n\'DELETE_COLUMN_FAMILY_REOPEN_ALL_RE" +
      "GIONS\020\006*\350\001\n\020EnableTableState\022\030\n\024ENABLE_T" +
      "ABLE_PREPARE\020\001\022\036\n\032ENABLE_TABLE_PRE_OPERA" +
      "TION\020\002\022)\n%ENABLE_TABLE_SET_ENABLING_TABL" +
      "E_STATE\020\003\022$\n ENABLE_TABLE_MARK_REGIONS_O" +
      "NLINE\020\004\022(\n$ENABLE_TABLE_SET_ENABLED_TABL" +
      "E_STATE\020\005\022\037\n\033ENABLE_TABLE_POST_OPERATION" +
      "\020\006*\362\001\n\021DisableTableState\022\031\n\025DISABLE_TABL" +
      "E_PREPARE\020\001\022\037\n\033DISABLE_TABLE_PRE_OPERATI" +
      "ON\020\002\022+\n\'DISABLE_TABLE_SET_DISABLING_TABL" +
      "E_STATE\020\003\022&\n\"DISABLE_TABLE_MARK_REGIONS_" +
      "OFFLINE\020\004\022*\n&DISABLE_TABLE_SET_DISABLED_" +
      "TABLE_STATE\020\005\022 \n\034DISABLE_TABLE_POST_OPER" +
      "ATION\020\006*\234\002\n\020ServerCrashState\022\026\n\022SERVER_C" +
      "RASH_START\020\001\022\035\n\031SERVER_CRASH_PROCESS_MET" +
      "A\020\002\022\034\n\030SERVER_CRASH_GET_REGIONS\020\003\022\036\n\032SER" +
      "VER_CRASH_NO_SPLIT_LOGS\020\004\022\033\n\027SERVER_CRAS" +
      "H_SPLIT_LOGS\020\005\022#\n\037SERVER_CRASH_PREPARE_L" +
      "OG_REPLAY\020\006\022\027\n\023SERVER_CRASH_ASSIGN\020\010\022\037\n\033" +
      "SERVER_CRASH_WAIT_ON_ASSIGN\020\t\022\027\n\023SERVER_" +
      "CRASH_FINISH\020dBK\n*org.apache.hadoop.hbas" +
      "e.protobuf.generatedB\025MasterProcedurePro" +
      "tosH\001\210\001\001\240\001\001"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.protobuf.generated.TableProtos.getDescriptor(),
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.protobuf.generated.RPCProtos.getDescriptor(),
        });
    internal_static_hbase_pb_CreateTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_CreateTableStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CreateTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableSchema", "RegionInfo", });
    internal_static_hbase_pb_ModifyTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_ModifyTableStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "UnmodifiedTableSchema", "ModifiedTableSchema", "DeleteColumnFamilyInModify", });
    internal_static_hbase_pb_TruncateTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_TruncateTableStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_TruncateTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "PreserveSplits", "TableName", "TableSchema", "RegionInfo", });
    internal_static_hbase_pb_DeleteTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_DeleteTableStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DeleteTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "RegionInfo", });
    internal_static_hbase_pb_CreateNamespaceStateData_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_CreateNamespaceStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_CreateNamespaceStateData_descriptor,
        new java.lang.String[] { "NamespaceDescriptor", });
    internal_static_hbase_pb_ModifyNamespaceStateData_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hbase_pb_ModifyNamespaceStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyNamespaceStateData_descriptor,
        new java.lang.String[] { "NamespaceDescriptor", "UnmodifiedNamespaceDescriptor", });
    internal_static_hbase_pb_DeleteNamespaceStateData_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hbase_pb_DeleteNamespaceStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DeleteNamespaceStateData_descriptor,
        new java.lang.String[] { "NamespaceName", "NamespaceDescriptor", });
    internal_static_hbase_pb_AddColumnFamilyStateData_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hbase_pb_AddColumnFamilyStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_AddColumnFamilyStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "ColumnfamilySchema", "UnmodifiedTableSchema", });
    internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hbase_pb_ModifyColumnFamilyStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ModifyColumnFamilyStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "ColumnfamilySchema", "UnmodifiedTableSchema", });
    internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hbase_pb_DeleteColumnFamilyStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DeleteColumnFamilyStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "ColumnfamilyName", "UnmodifiedTableSchema", });
    internal_static_hbase_pb_EnableTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hbase_pb_EnableTableStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_EnableTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "SkipTableStateCheck", });
    internal_static_hbase_pb_DisableTableStateData_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_hbase_pb_DisableTableStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_DisableTableStateData_descriptor,
        new java.lang.String[] { "UserInfo", "TableName", "SkipTableStateCheck", });
    internal_static_hbase_pb_ServerCrashStateData_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_hbase_pb_ServerCrashStateData_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ServerCrashStateData_descriptor,
        new java.lang.String[] { "ServerName", "DistributedLogReplay", "RegionsOnCrashedServer", "RegionsAssigned", "CarryingMeta", "ShouldSplitWal", });
    org.apache.hadoop.hbase.protobuf.generated.TableProtos.getDescriptor();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor();
    org.apache.hadoop.hbase.protobuf.generated.RPCProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
