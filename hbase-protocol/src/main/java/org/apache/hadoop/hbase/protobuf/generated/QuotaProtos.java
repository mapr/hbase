// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: Quota.proto

package org.apache.hadoop.hbase.protobuf.generated;

public final class QuotaProtos {
  private QuotaProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * Protobuf enum {@code hbase.pb.QuotaScope}
   */
  public enum QuotaScope
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>CLUSTER = 1;</code>
     */
    CLUSTER(1),
    /**
     * <code>MACHINE = 2;</code>
     */
    MACHINE(2),
    ;

    /**
     * <code>CLUSTER = 1;</code>
     */
    public static final int CLUSTER_VALUE = 1;
    /**
     * <code>MACHINE = 2;</code>
     */
    public static final int MACHINE_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static QuotaScope valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static QuotaScope forNumber(int value) {
      switch (value) {
        case 1: return CLUSTER;
        case 2: return MACHINE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QuotaScope>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        QuotaScope> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QuotaScope>() {
            public QuotaScope findValueByNumber(int number) {
              return QuotaScope.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final QuotaScope[] VALUES = values();

    public static QuotaScope valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private QuotaScope(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.QuotaScope)
  }

  /**
   * Protobuf enum {@code hbase.pb.ThrottleType}
   */
  public enum ThrottleType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>REQUEST_NUMBER = 1;</code>
     */
    REQUEST_NUMBER(1),
    /**
     * <code>REQUEST_SIZE = 2;</code>
     */
    REQUEST_SIZE(2),
    /**
     * <code>WRITE_NUMBER = 3;</code>
     */
    WRITE_NUMBER(3),
    /**
     * <code>WRITE_SIZE = 4;</code>
     */
    WRITE_SIZE(4),
    /**
     * <code>READ_NUMBER = 5;</code>
     */
    READ_NUMBER(5),
    /**
     * <code>READ_SIZE = 6;</code>
     */
    READ_SIZE(6),
    ;

    /**
     * <code>REQUEST_NUMBER = 1;</code>
     */
    public static final int REQUEST_NUMBER_VALUE = 1;
    /**
     * <code>REQUEST_SIZE = 2;</code>
     */
    public static final int REQUEST_SIZE_VALUE = 2;
    /**
     * <code>WRITE_NUMBER = 3;</code>
     */
    public static final int WRITE_NUMBER_VALUE = 3;
    /**
     * <code>WRITE_SIZE = 4;</code>
     */
    public static final int WRITE_SIZE_VALUE = 4;
    /**
     * <code>READ_NUMBER = 5;</code>
     */
    public static final int READ_NUMBER_VALUE = 5;
    /**
     * <code>READ_SIZE = 6;</code>
     */
    public static final int READ_SIZE_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ThrottleType valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static ThrottleType forNumber(int value) {
      switch (value) {
        case 1: return REQUEST_NUMBER;
        case 2: return REQUEST_SIZE;
        case 3: return WRITE_NUMBER;
        case 4: return WRITE_SIZE;
        case 5: return READ_NUMBER;
        case 6: return READ_SIZE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ThrottleType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ThrottleType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ThrottleType>() {
            public ThrottleType findValueByNumber(int number) {
              return ThrottleType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final ThrottleType[] VALUES = values();

    public static ThrottleType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ThrottleType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.ThrottleType)
  }

  /**
   * Protobuf enum {@code hbase.pb.QuotaType}
   */
  public enum QuotaType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>THROTTLE = 1;</code>
     */
    THROTTLE(1),
    ;

    /**
     * <code>THROTTLE = 1;</code>
     */
    public static final int THROTTLE_VALUE = 1;


    public final int getNumber() {
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static QuotaType valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static QuotaType forNumber(int value) {
      switch (value) {
        case 1: return THROTTLE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QuotaType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        QuotaType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QuotaType>() {
            public QuotaType findValueByNumber(int number) {
              return QuotaType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.getDescriptor().getEnumTypes().get(2);
    }

    private static final QuotaType[] VALUES = values();

    public static QuotaType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private QuotaType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hbase.pb.QuotaType)
  }

  public interface TimedQuotaOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.TimedQuota)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
     * @return Whether the timeUnit field is set.
     */
    boolean hasTimeUnit();
    /**
     * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
     * @return The timeUnit.
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit getTimeUnit();

    /**
     * <code>optional uint64 soft_limit = 2;</code>
     * @return Whether the softLimit field is set.
     */
    boolean hasSoftLimit();
    /**
     * <code>optional uint64 soft_limit = 2;</code>
     * @return The softLimit.
     */
    long getSoftLimit();

    /**
     * <code>optional float share = 3;</code>
     * @return Whether the share field is set.
     */
    boolean hasShare();
    /**
     * <code>optional float share = 3;</code>
     * @return The share.
     */
    float getShare();

    /**
     * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
     * @return Whether the scope field is set.
     */
    boolean hasScope();
    /**
     * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
     * @return The scope.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope getScope();
  }
  /**
   * Protobuf type {@code hbase.pb.TimedQuota}
   */
  public  static final class TimedQuota extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.TimedQuota)
      TimedQuotaOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TimedQuota.newBuilder() to construct.
    private TimedQuota(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TimedQuota() {
      timeUnit_ = 1;
      scope_ = 2;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new TimedQuota();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private TimedQuota(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit value = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                timeUnit_ = rawValue;
              }
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              softLimit_ = input.readUInt64();
              break;
            }
            case 29: {
              bitField0_ |= 0x00000004;
              share_ = input.readFloat();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope value = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                scope_ = rawValue;
              }
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder.class);
    }

    private int bitField0_;
    public static final int TIME_UNIT_FIELD_NUMBER = 1;
    private int timeUnit_;
    /**
     * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
     * @return Whether the timeUnit field is set.
     */
    public boolean hasTimeUnit() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
     * @return The timeUnit.
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit getTimeUnit() {
      @SuppressWarnings("deprecation")
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit result = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.valueOf(timeUnit_);
      return result == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.NANOSECONDS : result;
    }

    public static final int SOFT_LIMIT_FIELD_NUMBER = 2;
    private long softLimit_;
    /**
     * <code>optional uint64 soft_limit = 2;</code>
     * @return Whether the softLimit field is set.
     */
    public boolean hasSoftLimit() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional uint64 soft_limit = 2;</code>
     * @return The softLimit.
     */
    public long getSoftLimit() {
      return softLimit_;
    }

    public static final int SHARE_FIELD_NUMBER = 3;
    private float share_;
    /**
     * <code>optional float share = 3;</code>
     * @return Whether the share field is set.
     */
    public boolean hasShare() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional float share = 3;</code>
     * @return The share.
     */
    public float getShare() {
      return share_;
    }

    public static final int SCOPE_FIELD_NUMBER = 4;
    private int scope_;
    /**
     * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
     * @return Whether the scope field is set.
     */
    public boolean hasScope() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
     * @return The scope.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope getScope() {
      @SuppressWarnings("deprecation")
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope result = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.valueOf(scope_);
      return result == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.MACHINE : result;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (!hasTimeUnit()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, timeUnit_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeUInt64(2, softLimit_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeFloat(3, share_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeEnum(4, scope_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, timeUnit_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, softLimit_);
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, share_);
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, scope_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota) obj;

      if (hasTimeUnit() != other.hasTimeUnit()) return false;
      if (hasTimeUnit()) {
        if (timeUnit_ != other.timeUnit_) return false;
      }
      if (hasSoftLimit() != other.hasSoftLimit()) return false;
      if (hasSoftLimit()) {
        if (getSoftLimit()
            != other.getSoftLimit()) return false;
      }
      if (hasShare() != other.hasShare()) return false;
      if (hasShare()) {
        if (java.lang.Float.floatToIntBits(getShare())
            != java.lang.Float.floatToIntBits(
                other.getShare())) return false;
      }
      if (hasScope() != other.hasScope()) return false;
      if (hasScope()) {
        if (scope_ != other.scope_) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasTimeUnit()) {
        hash = (37 * hash) + TIME_UNIT_FIELD_NUMBER;
        hash = (53 * hash) + timeUnit_;
      }
      if (hasSoftLimit()) {
        hash = (37 * hash) + SOFT_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getSoftLimit());
      }
      if (hasShare()) {
        hash = (37 * hash) + SHARE_FIELD_NUMBER;
        hash = (53 * hash) + java.lang.Float.floatToIntBits(
            getShare());
      }
      if (hasScope()) {
        hash = (37 * hash) + SCOPE_FIELD_NUMBER;
        hash = (53 * hash) + scope_;
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.TimedQuota}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.TimedQuota)
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        timeUnit_ = 1;
        bitField0_ = (bitField0_ & ~0x00000001);
        softLimit_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        share_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000004);
        scope_ = 2;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_TimedQuota_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.timeUnit_ = timeUnit_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.softLimit_ = softLimit_;
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.share_ = share_;
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          to_bitField0_ |= 0x00000008;
        }
        result.scope_ = scope_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) return this;
        if (other.hasTimeUnit()) {
          setTimeUnit(other.getTimeUnit());
        }
        if (other.hasSoftLimit()) {
          setSoftLimit(other.getSoftLimit());
        }
        if (other.hasShare()) {
          setShare(other.getShare());
        }
        if (other.hasScope()) {
          setScope(other.getScope());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (!hasTimeUnit()) {
          return false;
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int timeUnit_ = 1;
      /**
       * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
       * @return Whether the timeUnit field is set.
       */
      public boolean hasTimeUnit() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
       * @return The timeUnit.
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit getTimeUnit() {
        @SuppressWarnings("deprecation")
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit result = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.valueOf(timeUnit_);
        return result == null ? org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit.NANOSECONDS : result;
      }
      /**
       * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
       * @param value The timeUnit to set.
       * @return This builder for chaining.
       */
      public Builder setTimeUnit(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeUnit value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        timeUnit_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.TimeUnit time_unit = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearTimeUnit() {
        bitField0_ = (bitField0_ & ~0x00000001);
        timeUnit_ = 1;
        onChanged();
        return this;
      }

      private long softLimit_ ;
      /**
       * <code>optional uint64 soft_limit = 2;</code>
       * @return Whether the softLimit field is set.
       */
      public boolean hasSoftLimit() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional uint64 soft_limit = 2;</code>
       * @return The softLimit.
       */
      public long getSoftLimit() {
        return softLimit_;
      }
      /**
       * <code>optional uint64 soft_limit = 2;</code>
       * @param value The softLimit to set.
       * @return This builder for chaining.
       */
      public Builder setSoftLimit(long value) {
        bitField0_ |= 0x00000002;
        softLimit_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 soft_limit = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearSoftLimit() {
        bitField0_ = (bitField0_ & ~0x00000002);
        softLimit_ = 0L;
        onChanged();
        return this;
      }

      private float share_ ;
      /**
       * <code>optional float share = 3;</code>
       * @return Whether the share field is set.
       */
      public boolean hasShare() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional float share = 3;</code>
       * @return The share.
       */
      public float getShare() {
        return share_;
      }
      /**
       * <code>optional float share = 3;</code>
       * @param value The share to set.
       * @return This builder for chaining.
       */
      public Builder setShare(float value) {
        bitField0_ |= 0x00000004;
        share_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float share = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearShare() {
        bitField0_ = (bitField0_ & ~0x00000004);
        share_ = 0F;
        onChanged();
        return this;
      }

      private int scope_ = 2;
      /**
       * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
       * @return Whether the scope field is set.
       */
      public boolean hasScope() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
       * @return The scope.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope getScope() {
        @SuppressWarnings("deprecation")
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope result = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.valueOf(scope_);
        return result == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope.MACHINE : result;
      }
      /**
       * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
       * @param value The scope to set.
       * @return This builder for chaining.
       */
      public Builder setScope(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaScope value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        scope_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.QuotaScope scope = 4 [default = MACHINE];</code>
       * @return This builder for chaining.
       */
      public Builder clearScope() {
        bitField0_ = (bitField0_ & ~0x00000008);
        scope_ = 2;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.TimedQuota)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.TimedQuota)
    private static final org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<TimedQuota>
        PARSER = new com.google.protobuf.AbstractParser<TimedQuota>() {
      @java.lang.Override
      public TimedQuota parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TimedQuota(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<TimedQuota> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<TimedQuota> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ThrottleOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Throttle)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     * @return Whether the reqNum field is set.
     */
    boolean hasReqNum();
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     * @return The reqNum.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqNum();
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqNumOrBuilder();

    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     * @return Whether the reqSize field is set.
     */
    boolean hasReqSize();
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     * @return The reqSize.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqSize();
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqSizeOrBuilder();

    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     * @return Whether the writeNum field is set.
     */
    boolean hasWriteNum();
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     * @return The writeNum.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteNum();
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteNumOrBuilder();

    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     * @return Whether the writeSize field is set.
     */
    boolean hasWriteSize();
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     * @return The writeSize.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteSize();
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteSizeOrBuilder();

    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     * @return Whether the readNum field is set.
     */
    boolean hasReadNum();
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     * @return The readNum.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadNum();
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadNumOrBuilder();

    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     * @return Whether the readSize field is set.
     */
    boolean hasReadSize();
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     * @return The readSize.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadSize();
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadSizeOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.Throttle}
   */
  public  static final class Throttle extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Throttle)
      ThrottleOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Throttle.newBuilder() to construct.
    private Throttle(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Throttle() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Throttle();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Throttle(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) != 0)) {
                subBuilder = reqNum_.toBuilder();
              }
              reqNum_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reqNum_);
                reqNum_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = reqSize_.toBuilder();
              }
              reqSize_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reqSize_);
                reqSize_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) != 0)) {
                subBuilder = writeNum_.toBuilder();
              }
              writeNum_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(writeNum_);
                writeNum_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) != 0)) {
                subBuilder = writeSize_.toBuilder();
              }
              writeSize_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(writeSize_);
                writeSize_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) != 0)) {
                subBuilder = readNum_.toBuilder();
              }
              readNum_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(readNum_);
                readNum_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 50: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000020) != 0)) {
                subBuilder = readSize_.toBuilder();
              }
              readSize_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(readSize_);
                readSize_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000020;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder.class);
    }

    private int bitField0_;
    public static final int REQ_NUM_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota reqNum_;
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     * @return Whether the reqNum field is set.
     */
    public boolean hasReqNum() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     * @return The reqNum.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqNum() {
      return reqNum_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : reqNum_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqNumOrBuilder() {
      return reqNum_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : reqNum_;
    }

    public static final int REQ_SIZE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota reqSize_;
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     * @return Whether the reqSize field is set.
     */
    public boolean hasReqSize() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     * @return The reqSize.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqSize() {
      return reqSize_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : reqSize_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqSizeOrBuilder() {
      return reqSize_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : reqSize_;
    }

    public static final int WRITE_NUM_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota writeNum_;
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     * @return Whether the writeNum field is set.
     */
    public boolean hasWriteNum() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     * @return The writeNum.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteNum() {
      return writeNum_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : writeNum_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteNumOrBuilder() {
      return writeNum_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : writeNum_;
    }

    public static final int WRITE_SIZE_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota writeSize_;
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     * @return Whether the writeSize field is set.
     */
    public boolean hasWriteSize() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     * @return The writeSize.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteSize() {
      return writeSize_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : writeSize_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteSizeOrBuilder() {
      return writeSize_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : writeSize_;
    }

    public static final int READ_NUM_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota readNum_;
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     * @return Whether the readNum field is set.
     */
    public boolean hasReadNum() {
      return ((bitField0_ & 0x00000010) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     * @return The readNum.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadNum() {
      return readNum_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : readNum_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadNumOrBuilder() {
      return readNum_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : readNum_;
    }

    public static final int READ_SIZE_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota readSize_;
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     * @return Whether the readSize field is set.
     */
    public boolean hasReadSize() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     * @return The readSize.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadSize() {
      return readSize_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : readSize_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadSizeOrBuilder() {
      return readSize_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : readSize_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasReqNum()) {
        if (!getReqNum().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasReqSize()) {
        if (!getReqSize().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasWriteNum()) {
        if (!getWriteNum().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasWriteSize()) {
        if (!getWriteSize().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasReadNum()) {
        if (!getReadNum().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasReadSize()) {
        if (!getReadSize().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(1, getReqNum());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getReqSize());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        output.writeMessage(3, getWriteNum());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        output.writeMessage(4, getWriteSize());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        output.writeMessage(5, getReadNum());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        output.writeMessage(6, getReadSize());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getReqNum());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getReqSize());
      }
      if (((bitField0_ & 0x00000004) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getWriteNum());
      }
      if (((bitField0_ & 0x00000008) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getWriteSize());
      }
      if (((bitField0_ & 0x00000010) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getReadNum());
      }
      if (((bitField0_ & 0x00000020) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getReadSize());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle) obj;

      if (hasReqNum() != other.hasReqNum()) return false;
      if (hasReqNum()) {
        if (!getReqNum()
            .equals(other.getReqNum())) return false;
      }
      if (hasReqSize() != other.hasReqSize()) return false;
      if (hasReqSize()) {
        if (!getReqSize()
            .equals(other.getReqSize())) return false;
      }
      if (hasWriteNum() != other.hasWriteNum()) return false;
      if (hasWriteNum()) {
        if (!getWriteNum()
            .equals(other.getWriteNum())) return false;
      }
      if (hasWriteSize() != other.hasWriteSize()) return false;
      if (hasWriteSize()) {
        if (!getWriteSize()
            .equals(other.getWriteSize())) return false;
      }
      if (hasReadNum() != other.hasReadNum()) return false;
      if (hasReadNum()) {
        if (!getReadNum()
            .equals(other.getReadNum())) return false;
      }
      if (hasReadSize() != other.hasReadSize()) return false;
      if (hasReadSize()) {
        if (!getReadSize()
            .equals(other.getReadSize())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasReqNum()) {
        hash = (37 * hash) + REQ_NUM_FIELD_NUMBER;
        hash = (53 * hash) + getReqNum().hashCode();
      }
      if (hasReqSize()) {
        hash = (37 * hash) + REQ_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getReqSize().hashCode();
      }
      if (hasWriteNum()) {
        hash = (37 * hash) + WRITE_NUM_FIELD_NUMBER;
        hash = (53 * hash) + getWriteNum().hashCode();
      }
      if (hasWriteSize()) {
        hash = (37 * hash) + WRITE_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getWriteSize().hashCode();
      }
      if (hasReadNum()) {
        hash = (37 * hash) + READ_NUM_FIELD_NUMBER;
        hash = (53 * hash) + getReadNum().hashCode();
      }
      if (hasReadSize()) {
        hash = (37 * hash) + READ_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getReadSize().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.Throttle}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Throttle)
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getReqNumFieldBuilder();
          getReqSizeFieldBuilder();
          getWriteNumFieldBuilder();
          getWriteSizeFieldBuilder();
          getReadNumFieldBuilder();
          getReadSizeFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (reqNumBuilder_ == null) {
          reqNum_ = null;
        } else {
          reqNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (reqSizeBuilder_ == null) {
          reqSize_ = null;
        } else {
          reqSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (writeNumBuilder_ == null) {
          writeNum_ = null;
        } else {
          writeNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (writeSizeBuilder_ == null) {
          writeSize_ = null;
        } else {
          writeSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (readNumBuilder_ == null) {
          readNum_ = null;
        } else {
          readNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (readSizeBuilder_ == null) {
          readSize_ = null;
        } else {
          readSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Throttle_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          if (reqNumBuilder_ == null) {
            result.reqNum_ = reqNum_;
          } else {
            result.reqNum_ = reqNumBuilder_.build();
          }
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (reqSizeBuilder_ == null) {
            result.reqSize_ = reqSize_;
          } else {
            result.reqSize_ = reqSizeBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          if (writeNumBuilder_ == null) {
            result.writeNum_ = writeNum_;
          } else {
            result.writeNum_ = writeNumBuilder_.build();
          }
          to_bitField0_ |= 0x00000004;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          if (writeSizeBuilder_ == null) {
            result.writeSize_ = writeSize_;
          } else {
            result.writeSize_ = writeSizeBuilder_.build();
          }
          to_bitField0_ |= 0x00000008;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          if (readNumBuilder_ == null) {
            result.readNum_ = readNum_;
          } else {
            result.readNum_ = readNumBuilder_.build();
          }
          to_bitField0_ |= 0x00000010;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          if (readSizeBuilder_ == null) {
            result.readSize_ = readSize_;
          } else {
            result.readSize_ = readSizeBuilder_.build();
          }
          to_bitField0_ |= 0x00000020;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance()) return this;
        if (other.hasReqNum()) {
          mergeReqNum(other.getReqNum());
        }
        if (other.hasReqSize()) {
          mergeReqSize(other.getReqSize());
        }
        if (other.hasWriteNum()) {
          mergeWriteNum(other.getWriteNum());
        }
        if (other.hasWriteSize()) {
          mergeWriteSize(other.getWriteSize());
        }
        if (other.hasReadNum()) {
          mergeReadNum(other.getReadNum());
        }
        if (other.hasReadSize()) {
          mergeReadSize(other.getReadSize());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasReqNum()) {
          if (!getReqNum().isInitialized()) {
            return false;
          }
        }
        if (hasReqSize()) {
          if (!getReqSize().isInitialized()) {
            return false;
          }
        }
        if (hasWriteNum()) {
          if (!getWriteNum().isInitialized()) {
            return false;
          }
        }
        if (hasWriteSize()) {
          if (!getWriteSize().isInitialized()) {
            return false;
          }
        }
        if (hasReadNum()) {
          if (!getReadNum().isInitialized()) {
            return false;
          }
        }
        if (hasReadSize()) {
          if (!getReadSize().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota reqNum_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> reqNumBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       * @return Whether the reqNum field is set.
       */
      public boolean hasReqNum() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       * @return The reqNum.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqNum() {
        if (reqNumBuilder_ == null) {
          return reqNum_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : reqNum_;
        } else {
          return reqNumBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public Builder setReqNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (reqNumBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reqNum_ = value;
          onChanged();
        } else {
          reqNumBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public Builder setReqNum(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (reqNumBuilder_ == null) {
          reqNum_ = builderForValue.build();
          onChanged();
        } else {
          reqNumBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public Builder mergeReqNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (reqNumBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
              reqNum_ != null &&
              reqNum_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            reqNum_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(reqNum_).mergeFrom(value).buildPartial();
          } else {
            reqNum_ = value;
          }
          onChanged();
        } else {
          reqNumBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public Builder clearReqNum() {
        if (reqNumBuilder_ == null) {
          reqNum_ = null;
          onChanged();
        } else {
          reqNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getReqNumBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getReqNumFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqNumOrBuilder() {
        if (reqNumBuilder_ != null) {
          return reqNumBuilder_.getMessageOrBuilder();
        } else {
          return reqNum_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : reqNum_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_num = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> 
          getReqNumFieldBuilder() {
        if (reqNumBuilder_ == null) {
          reqNumBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  getReqNum(),
                  getParentForChildren(),
                  isClean());
          reqNum_ = null;
        }
        return reqNumBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota reqSize_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> reqSizeBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       * @return Whether the reqSize field is set.
       */
      public boolean hasReqSize() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       * @return The reqSize.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReqSize() {
        if (reqSizeBuilder_ == null) {
          return reqSize_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : reqSize_;
        } else {
          return reqSizeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public Builder setReqSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (reqSizeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reqSize_ = value;
          onChanged();
        } else {
          reqSizeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public Builder setReqSize(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (reqSizeBuilder_ == null) {
          reqSize_ = builderForValue.build();
          onChanged();
        } else {
          reqSizeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public Builder mergeReqSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (reqSizeBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              reqSize_ != null &&
              reqSize_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            reqSize_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(reqSize_).mergeFrom(value).buildPartial();
          } else {
            reqSize_ = value;
          }
          onChanged();
        } else {
          reqSizeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public Builder clearReqSize() {
        if (reqSizeBuilder_ == null) {
          reqSize_ = null;
          onChanged();
        } else {
          reqSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getReqSizeBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getReqSizeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReqSizeOrBuilder() {
        if (reqSizeBuilder_ != null) {
          return reqSizeBuilder_.getMessageOrBuilder();
        } else {
          return reqSize_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : reqSize_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota req_size = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> 
          getReqSizeFieldBuilder() {
        if (reqSizeBuilder_ == null) {
          reqSizeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  getReqSize(),
                  getParentForChildren(),
                  isClean());
          reqSize_ = null;
        }
        return reqSizeBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota writeNum_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> writeNumBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       * @return Whether the writeNum field is set.
       */
      public boolean hasWriteNum() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       * @return The writeNum.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteNum() {
        if (writeNumBuilder_ == null) {
          return writeNum_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : writeNum_;
        } else {
          return writeNumBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public Builder setWriteNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (writeNumBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          writeNum_ = value;
          onChanged();
        } else {
          writeNumBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public Builder setWriteNum(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (writeNumBuilder_ == null) {
          writeNum_ = builderForValue.build();
          onChanged();
        } else {
          writeNumBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public Builder mergeWriteNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (writeNumBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0) &&
              writeNum_ != null &&
              writeNum_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            writeNum_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(writeNum_).mergeFrom(value).buildPartial();
          } else {
            writeNum_ = value;
          }
          onChanged();
        } else {
          writeNumBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public Builder clearWriteNum() {
        if (writeNumBuilder_ == null) {
          writeNum_ = null;
          onChanged();
        } else {
          writeNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getWriteNumBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getWriteNumFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteNumOrBuilder() {
        if (writeNumBuilder_ != null) {
          return writeNumBuilder_.getMessageOrBuilder();
        } else {
          return writeNum_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : writeNum_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_num = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> 
          getWriteNumFieldBuilder() {
        if (writeNumBuilder_ == null) {
          writeNumBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  getWriteNum(),
                  getParentForChildren(),
                  isClean());
          writeNum_ = null;
        }
        return writeNumBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota writeSize_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> writeSizeBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       * @return Whether the writeSize field is set.
       */
      public boolean hasWriteSize() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       * @return The writeSize.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getWriteSize() {
        if (writeSizeBuilder_ == null) {
          return writeSize_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : writeSize_;
        } else {
          return writeSizeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public Builder setWriteSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (writeSizeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          writeSize_ = value;
          onChanged();
        } else {
          writeSizeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public Builder setWriteSize(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (writeSizeBuilder_ == null) {
          writeSize_ = builderForValue.build();
          onChanged();
        } else {
          writeSizeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public Builder mergeWriteSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (writeSizeBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0) &&
              writeSize_ != null &&
              writeSize_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            writeSize_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(writeSize_).mergeFrom(value).buildPartial();
          } else {
            writeSize_ = value;
          }
          onChanged();
        } else {
          writeSizeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public Builder clearWriteSize() {
        if (writeSizeBuilder_ == null) {
          writeSize_ = null;
          onChanged();
        } else {
          writeSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getWriteSizeBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getWriteSizeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getWriteSizeOrBuilder() {
        if (writeSizeBuilder_ != null) {
          return writeSizeBuilder_.getMessageOrBuilder();
        } else {
          return writeSize_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : writeSize_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota write_size = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> 
          getWriteSizeFieldBuilder() {
        if (writeSizeBuilder_ == null) {
          writeSizeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  getWriteSize(),
                  getParentForChildren(),
                  isClean());
          writeSize_ = null;
        }
        return writeSizeBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota readNum_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> readNumBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       * @return Whether the readNum field is set.
       */
      public boolean hasReadNum() {
        return ((bitField0_ & 0x00000010) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       * @return The readNum.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadNum() {
        if (readNumBuilder_ == null) {
          return readNum_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : readNum_;
        } else {
          return readNumBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public Builder setReadNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (readNumBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          readNum_ = value;
          onChanged();
        } else {
          readNumBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public Builder setReadNum(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (readNumBuilder_ == null) {
          readNum_ = builderForValue.build();
          onChanged();
        } else {
          readNumBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public Builder mergeReadNum(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (readNumBuilder_ == null) {
          if (((bitField0_ & 0x00000010) != 0) &&
              readNum_ != null &&
              readNum_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            readNum_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(readNum_).mergeFrom(value).buildPartial();
          } else {
            readNum_ = value;
          }
          onChanged();
        } else {
          readNumBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public Builder clearReadNum() {
        if (readNumBuilder_ == null) {
          readNum_ = null;
          onChanged();
        } else {
          readNumBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getReadNumBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getReadNumFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadNumOrBuilder() {
        if (readNumBuilder_ != null) {
          return readNumBuilder_.getMessageOrBuilder();
        } else {
          return readNum_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : readNum_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_num = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> 
          getReadNumFieldBuilder() {
        if (readNumBuilder_ == null) {
          readNumBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  getReadNum(),
                  getParentForChildren(),
                  isClean());
          readNum_ = null;
        }
        return readNumBuilder_;
      }

      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota readSize_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> readSizeBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       * @return Whether the readSize field is set.
       */
      public boolean hasReadSize() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       * @return The readSize.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getReadSize() {
        if (readSizeBuilder_ == null) {
          return readSize_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : readSize_;
        } else {
          return readSizeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public Builder setReadSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (readSizeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          readSize_ = value;
          onChanged();
        } else {
          readSizeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public Builder setReadSize(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (readSizeBuilder_ == null) {
          readSize_ = builderForValue.build();
          onChanged();
        } else {
          readSizeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public Builder mergeReadSize(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (readSizeBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0) &&
              readSize_ != null &&
              readSize_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            readSize_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(readSize_).mergeFrom(value).buildPartial();
          } else {
            readSize_ = value;
          }
          onChanged();
        } else {
          readSizeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public Builder clearReadSize() {
        if (readSizeBuilder_ == null) {
          readSize_ = null;
          onChanged();
        } else {
          readSizeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getReadSizeBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getReadSizeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getReadSizeOrBuilder() {
        if (readSizeBuilder_ != null) {
          return readSizeBuilder_.getMessageOrBuilder();
        } else {
          return readSize_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : readSize_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota read_size = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> 
          getReadSizeFieldBuilder() {
        if (readSizeBuilder_ == null) {
          readSizeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  getReadSize(),
                  getParentForChildren(),
                  isClean());
          readSize_ = null;
        }
        return readSizeBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Throttle)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Throttle)
    private static final org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<Throttle>
        PARSER = new com.google.protobuf.AbstractParser<Throttle>() {
      @java.lang.Override
      public Throttle parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Throttle(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Throttle> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Throttle> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ThrottleRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.ThrottleRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hbase.pb.ThrottleType type = 1;</code>
     * @return Whether the type field is set.
     */
    boolean hasType();
    /**
     * <code>optional .hbase.pb.ThrottleType type = 1;</code>
     * @return The type.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType getType();

    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     * @return Whether the timedQuota field is set.
     */
    boolean hasTimedQuota();
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     * @return The timedQuota.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getTimedQuota();
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getTimedQuotaOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.ThrottleRequest}
   */
  public  static final class ThrottleRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.ThrottleRequest)
      ThrottleRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ThrottleRequest.newBuilder() to construct.
    private ThrottleRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ThrottleRequest() {
      type_ = 1;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ThrottleRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ThrottleRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();
                @SuppressWarnings("deprecation")
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType value = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                type_ = rawValue;
              }
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = timedQuota_.toBuilder();
              }
              timedQuota_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(timedQuota_);
                timedQuota_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.Builder.class);
    }

    private int bitField0_;
    public static final int TYPE_FIELD_NUMBER = 1;
    private int type_;
    /**
     * <code>optional .hbase.pb.ThrottleType type = 1;</code>
     * @return Whether the type field is set.
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional .hbase.pb.ThrottleType type = 1;</code>
     * @return The type.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType getType() {
      @SuppressWarnings("deprecation")
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType result = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.valueOf(type_);
      return result == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.REQUEST_NUMBER : result;
    }

    public static final int TIMED_QUOTA_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota timedQuota_;
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     * @return Whether the timedQuota field is set.
     */
    public boolean hasTimedQuota() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     * @return The timedQuota.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getTimedQuota() {
      return timedQuota_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : timedQuota_;
    }
    /**
     * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getTimedQuotaOrBuilder() {
      return timedQuota_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : timedQuota_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasTimedQuota()) {
        if (!getTimedQuota().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeEnum(1, type_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getTimedQuota());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, type_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getTimedQuota());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest) obj;

      if (hasType() != other.hasType()) return false;
      if (hasType()) {
        if (type_ != other.type_) return false;
      }
      if (hasTimedQuota() != other.hasTimedQuota()) return false;
      if (hasTimedQuota()) {
        if (!getTimedQuota()
            .equals(other.getTimedQuota())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + type_;
      }
      if (hasTimedQuota()) {
        hash = (37 * hash) + TIMED_QUOTA_FIELD_NUMBER;
        hash = (53 * hash) + getTimedQuota().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.ThrottleRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.ThrottleRequest)
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getTimedQuotaFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        type_ = 1;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (timedQuotaBuilder_ == null) {
          timedQuota_ = null;
        } else {
          timedQuotaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_ThrottleRequest_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          to_bitField0_ |= 0x00000001;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (timedQuotaBuilder_ == null) {
            result.timedQuota_ = timedQuota_;
          } else {
            result.timedQuota_ = timedQuotaBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest.getDefaultInstance()) return this;
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasTimedQuota()) {
          mergeTimedQuota(other.getTimedQuota());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasTimedQuota()) {
          if (!getTimedQuota().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int type_ = 1;
      /**
       * <code>optional .hbase.pb.ThrottleType type = 1;</code>
       * @return Whether the type field is set.
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional .hbase.pb.ThrottleType type = 1;</code>
       * @return The type.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType getType() {
        @SuppressWarnings("deprecation")
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType result = org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.valueOf(type_);
        return result == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType.REQUEST_NUMBER : result;
      }
      /**
       * <code>optional .hbase.pb.ThrottleType type = 1;</code>
       * @param value The type to set.
       * @return This builder for chaining.
       */
      public Builder setType(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        type_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.ThrottleType type = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota timedQuota_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> timedQuotaBuilder_;
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       * @return Whether the timedQuota field is set.
       */
      public boolean hasTimedQuota() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       * @return The timedQuota.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota getTimedQuota() {
        if (timedQuotaBuilder_ == null) {
          return timedQuota_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : timedQuota_;
        } else {
          return timedQuotaBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public Builder setTimedQuota(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (timedQuotaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timedQuota_ = value;
          onChanged();
        } else {
          timedQuotaBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public Builder setTimedQuota(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder builderForValue) {
        if (timedQuotaBuilder_ == null) {
          timedQuota_ = builderForValue.build();
          onChanged();
        } else {
          timedQuotaBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public Builder mergeTimedQuota(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota value) {
        if (timedQuotaBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              timedQuota_ != null &&
              timedQuota_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance()) {
            timedQuota_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.newBuilder(timedQuota_).mergeFrom(value).buildPartial();
          } else {
            timedQuota_ = value;
          }
          onChanged();
        } else {
          timedQuotaBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public Builder clearTimedQuota() {
        if (timedQuotaBuilder_ == null) {
          timedQuota_ = null;
          onChanged();
        } else {
          timedQuotaBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder getTimedQuotaBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTimedQuotaFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder getTimedQuotaOrBuilder() {
        if (timedQuotaBuilder_ != null) {
          return timedQuotaBuilder_.getMessageOrBuilder();
        } else {
          return timedQuota_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.getDefaultInstance() : timedQuota_;
        }
      }
      /**
       * <code>optional .hbase.pb.TimedQuota timed_quota = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder> 
          getTimedQuotaFieldBuilder() {
        if (timedQuotaBuilder_ == null) {
          timedQuotaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuota.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.TimedQuotaOrBuilder>(
                  getTimedQuota(),
                  getParentForChildren(),
                  isClean());
          timedQuota_ = null;
        }
        return timedQuotaBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.ThrottleRequest)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.ThrottleRequest)
    private static final org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ThrottleRequest>
        PARSER = new com.google.protobuf.AbstractParser<ThrottleRequest>() {
      @java.lang.Override
      public ThrottleRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ThrottleRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ThrottleRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ThrottleRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface QuotasOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.Quotas)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional bool bypass_globals = 1 [default = false];</code>
     * @return Whether the bypassGlobals field is set.
     */
    boolean hasBypassGlobals();
    /**
     * <code>optional bool bypass_globals = 1 [default = false];</code>
     * @return The bypassGlobals.
     */
    boolean getBypassGlobals();

    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     * @return Whether the throttle field is set.
     */
    boolean hasThrottle();
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     * @return The throttle.
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getThrottle();
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder getThrottleOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.Quotas}
   */
  public  static final class Quotas extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.Quotas)
      QuotasOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Quotas.newBuilder() to construct.
    private Quotas(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Quotas() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Quotas();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Quotas(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              bitField0_ |= 0x00000001;
              bypassGlobals_ = input.readBool();
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) != 0)) {
                subBuilder = throttle_.toBuilder();
              }
              throttle_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(throttle_);
                throttle_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.Builder.class);
    }

    private int bitField0_;
    public static final int BYPASS_GLOBALS_FIELD_NUMBER = 1;
    private boolean bypassGlobals_;
    /**
     * <code>optional bool bypass_globals = 1 [default = false];</code>
     * @return Whether the bypassGlobals field is set.
     */
    public boolean hasBypassGlobals() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <code>optional bool bypass_globals = 1 [default = false];</code>
     * @return The bypassGlobals.
     */
    public boolean getBypassGlobals() {
      return bypassGlobals_;
    }

    public static final int THROTTLE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle throttle_;
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     * @return Whether the throttle field is set.
     */
    public boolean hasThrottle() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     * @return The throttle.
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getThrottle() {
      return throttle_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance() : throttle_;
    }
    /**
     * <code>optional .hbase.pb.Throttle throttle = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder getThrottleOrBuilder() {
      return throttle_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance() : throttle_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasThrottle()) {
        if (!getThrottle().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeBool(1, bypassGlobals_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getThrottle());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, bypassGlobals_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getThrottle());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas) obj;

      if (hasBypassGlobals() != other.hasBypassGlobals()) return false;
      if (hasBypassGlobals()) {
        if (getBypassGlobals()
            != other.getBypassGlobals()) return false;
      }
      if (hasThrottle() != other.hasThrottle()) return false;
      if (hasThrottle()) {
        if (!getThrottle()
            .equals(other.getThrottle())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasBypassGlobals()) {
        hash = (37 * hash) + BYPASS_GLOBALS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getBypassGlobals());
      }
      if (hasThrottle()) {
        hash = (37 * hash) + THROTTLE_FIELD_NUMBER;
        hash = (53 * hash) + getThrottle().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.Quotas}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.Quotas)
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotasOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getThrottleFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        bypassGlobals_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (throttleBuilder_ == null) {
          throttle_ = null;
        } else {
          throttleBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_Quotas_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.bypassGlobals_ = bypassGlobals_;
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          if (throttleBuilder_ == null) {
            result.throttle_ = throttle_;
          } else {
            result.throttle_ = throttleBuilder_.build();
          }
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas.getDefaultInstance()) return this;
        if (other.hasBypassGlobals()) {
          setBypassGlobals(other.getBypassGlobals());
        }
        if (other.hasThrottle()) {
          mergeThrottle(other.getThrottle());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        if (hasThrottle()) {
          if (!getThrottle().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private boolean bypassGlobals_ ;
      /**
       * <code>optional bool bypass_globals = 1 [default = false];</code>
       * @return Whether the bypassGlobals field is set.
       */
      public boolean hasBypassGlobals() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <code>optional bool bypass_globals = 1 [default = false];</code>
       * @return The bypassGlobals.
       */
      public boolean getBypassGlobals() {
        return bypassGlobals_;
      }
      /**
       * <code>optional bool bypass_globals = 1 [default = false];</code>
       * @param value The bypassGlobals to set.
       * @return This builder for chaining.
       */
      public Builder setBypassGlobals(boolean value) {
        bitField0_ |= 0x00000001;
        bypassGlobals_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool bypass_globals = 1 [default = false];</code>
       * @return This builder for chaining.
       */
      public Builder clearBypassGlobals() {
        bitField0_ = (bitField0_ & ~0x00000001);
        bypassGlobals_ = false;
        onChanged();
        return this;
      }

      private org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle throttle_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder> throttleBuilder_;
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       * @return Whether the throttle field is set.
       */
      public boolean hasThrottle() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       * @return The throttle.
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle getThrottle() {
        if (throttleBuilder_ == null) {
          return throttle_ == null ? org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance() : throttle_;
        } else {
          return throttleBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public Builder setThrottle(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle value) {
        if (throttleBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          throttle_ = value;
          onChanged();
        } else {
          throttleBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public Builder setThrottle(
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder builderForValue) {
        if (throttleBuilder_ == null) {
          throttle_ = builderForValue.build();
          onChanged();
        } else {
          throttleBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public Builder mergeThrottle(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle value) {
        if (throttleBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0) &&
              throttle_ != null &&
              throttle_ != org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance()) {
            throttle_ =
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.newBuilder(throttle_).mergeFrom(value).buildPartial();
          } else {
            throttle_ = value;
          }
          onChanged();
        } else {
          throttleBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public Builder clearThrottle() {
        if (throttleBuilder_ == null) {
          throttle_ = null;
          onChanged();
        } else {
          throttleBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder getThrottleBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getThrottleFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder getThrottleOrBuilder() {
        if (throttleBuilder_ != null) {
          return throttleBuilder_.getMessageOrBuilder();
        } else {
          return throttle_ == null ?
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.getDefaultInstance() : throttle_;
        }
      }
      /**
       * <code>optional .hbase.pb.Throttle throttle = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder> 
          getThrottleFieldBuilder() {
        if (throttleBuilder_ == null) {
          throttleBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Throttle.Builder, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.ThrottleOrBuilder>(
                  getThrottle(),
                  getParentForChildren(),
                  isClean());
          throttle_ = null;
        }
        return throttleBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.Quotas)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Quotas)
    private static final org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<Quotas>
        PARSER = new com.google.protobuf.AbstractParser<Quotas>() {
      @java.lang.Override
      public Quotas parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Quotas(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Quotas> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Quotas> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.Quotas getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface QuotaUsageOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hbase.pb.QuotaUsage)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.QuotaUsage}
   */
  public  static final class QuotaUsage extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hbase.pb.QuotaUsage)
      QuotaUsageOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use QuotaUsage.newBuilder() to construct.
    private QuotaUsage(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private QuotaUsage() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new QuotaUsage();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private QuotaUsage(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage other = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage) obj;

      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.QuotaUsage}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hbase.pb.QuotaUsage)
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsageOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.class, org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.internal_static_hbase_pb_QuotaUsage_descriptor;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage build() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage result = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hbase.pb.QuotaUsage)
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.QuotaUsage)
    private static final org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage();
    }

    public static org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<QuotaUsage>
        PARSER = new com.google.protobuf.AbstractParser<QuotaUsage>() {
      @java.lang.Override
      public QuotaUsage parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new QuotaUsage(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<QuotaUsage> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<QuotaUsage> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.hadoop.hbase.protobuf.generated.QuotaProtos.QuotaUsage getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_TimedQuota_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_TimedQuota_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Throttle_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Throttle_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_ThrottleRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_ThrottleRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Quotas_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_Quotas_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_QuotaUsage_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hbase_pb_QuotaUsage_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\013Quota.proto\022\010hbase.pb\032\013HBase.proto\"\204\001\n" +
      "\nTimedQuota\022%\n\ttime_unit\030\001 \002(\0162\022.hbase.p" +
      "b.TimeUnit\022\022\n\nsoft_limit\030\002 \001(\004\022\r\n\005share\030" +
      "\003 \001(\002\022,\n\005scope\030\004 \001(\0162\024.hbase.pb.QuotaSco" +
      "pe:\007MACHINE\"\375\001\n\010Throttle\022%\n\007req_num\030\001 \001(" +
      "\0132\024.hbase.pb.TimedQuota\022&\n\010req_size\030\002 \001(" +
      "\0132\024.hbase.pb.TimedQuota\022\'\n\twrite_num\030\003 \001" +
      "(\0132\024.hbase.pb.TimedQuota\022(\n\nwrite_size\030\004" +
      " \001(\0132\024.hbase.pb.TimedQuota\022&\n\010read_num\030\005" +
      " \001(\0132\024.hbase.pb.TimedQuota\022\'\n\tread_size\030" +
      "\006 \001(\0132\024.hbase.pb.TimedQuota\"b\n\017ThrottleR" +
      "equest\022$\n\004type\030\001 \001(\0162\026.hbase.pb.Throttle" +
      "Type\022)\n\013timed_quota\030\002 \001(\0132\024.hbase.pb.Tim" +
      "edQuota\"M\n\006Quotas\022\035\n\016bypass_globals\030\001 \001(" +
      "\010:\005false\022$\n\010throttle\030\002 \001(\0132\022.hbase.pb.Th" +
      "rottle\"\014\n\nQuotaUsage*&\n\nQuotaScope\022\013\n\007CL" +
      "USTER\020\001\022\013\n\007MACHINE\020\002*v\n\014ThrottleType\022\022\n\016" +
      "REQUEST_NUMBER\020\001\022\020\n\014REQUEST_SIZE\020\002\022\020\n\014WR" +
      "ITE_NUMBER\020\003\022\016\n\nWRITE_SIZE\020\004\022\017\n\013READ_NUM" +
      "BER\020\005\022\r\n\tREAD_SIZE\020\006*\031\n\tQuotaType\022\014\n\010THR" +
      "OTTLE\020\001BA\n*org.apache.hadoop.hbase.proto" +
      "buf.generatedB\013QuotaProtosH\001\210\001\001\240\001\001"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor(),
        });
    internal_static_hbase_pb_TimedQuota_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hbase_pb_TimedQuota_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_TimedQuota_descriptor,
        new java.lang.String[] { "TimeUnit", "SoftLimit", "Share", "Scope", });
    internal_static_hbase_pb_Throttle_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hbase_pb_Throttle_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Throttle_descriptor,
        new java.lang.String[] { "ReqNum", "ReqSize", "WriteNum", "WriteSize", "ReadNum", "ReadSize", });
    internal_static_hbase_pb_ThrottleRequest_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hbase_pb_ThrottleRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_ThrottleRequest_descriptor,
        new java.lang.String[] { "Type", "TimedQuota", });
    internal_static_hbase_pb_Quotas_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hbase_pb_Quotas_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_Quotas_descriptor,
        new java.lang.String[] { "BypassGlobals", "Throttle", });
    internal_static_hbase_pb_QuotaUsage_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hbase_pb_QuotaUsage_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hbase_pb_QuotaUsage_descriptor,
        new java.lang.String[] { });
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
